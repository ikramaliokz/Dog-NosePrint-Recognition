{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 03:26:31.791336: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-23 03:26:31.828038: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-23 03:26:31.828076: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-23 03:26:31.829229: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-23 03:26:31.835689: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-23 03:26:32.467284: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import nobuco\n",
    "from nobuco import ChannelOrder, ChannelOrderingStrategy\n",
    "from nobuco.layers.weight import WeightLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet152\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class ResNetBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetBackbone, self).__init__()\n",
    "        # Load a pre-trained ResNet-152 and remove the last GAP and FC\n",
    "        base_model = resnet152(pretrained=True)\n",
    "        self.features = nn.Sequential(*list(base_model.children())[:-2])\n",
    "\n",
    "        # Additional blocks to reduce channel dimensions\n",
    "        self.reduce_channels = nn.Sequential(\n",
    "            nn.Conv2d(2048, 1024, kernel_size=3),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(1024, 512, kernel_size=3),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.reduce_channels(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: input feature map with shape (batch_size, C, H, W)\n",
    "        batch_size, C, H, W = x.size()\n",
    "        \n",
    "        # Reshape x to (batch_size, C, H*W)\n",
    "        x_reshaped = x.view(batch_size, C, -1)\n",
    "        \n",
    "        # Compute the channel attention map\n",
    "        channel_attention_map = torch.bmm(x_reshaped, x_reshaped.transpose(1, 2))\n",
    "        channel_attention_map = F.softmax(channel_attention_map, dim=1)\n",
    "        \n",
    "        # Multiply the attention map by the input feature map\n",
    "        x_weighted = torch.bmm(channel_attention_map, x_reshaped)\n",
    "        \n",
    "        # Reshape back to (batch_size, C, H, W)\n",
    "        x_weighted = x_weighted.view(batch_size, C, H, W)\n",
    "        \n",
    "        # Apply scale parameter and element-wise summation\n",
    "        # beta = torch.nn.Parameter(torch.zeros(1), requires_grad=False)\n",
    "        beta = torch.zeros(1)\n",
    "        out = beta * x_weighted + x\n",
    "        \n",
    "        return out\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: input feature map with shape (batch_size, C, H, W)\n",
    "        batch_size, Ch, H, W = x.size()\n",
    "        \n",
    "        # Obtain new feature maps B and C\n",
    "        B = self.conv1(x)\n",
    "        C = self.conv2(x)\n",
    "        \n",
    "        # Reshape B and C to (batch_size, C, H*W)\n",
    "        B_reshaped = B.view(batch_size, Ch, -1)\n",
    "        C_reshaped = C.view(batch_size, Ch, -1)\n",
    "        \n",
    "        # Compute the spatial attention map\n",
    "        spatial_attention_map = torch.bmm(B_reshaped.transpose(1, 2), C_reshaped)\n",
    "        spatial_attention_map = F.softmax(spatial_attention_map, dim=1)\n",
    "        \n",
    "        # Multiply the attention map by the input feature map\n",
    "        D = self.conv3(x)\n",
    "        D_reshaped = D.view(batch_size, Ch, -1)\n",
    "        x_weighted = torch.bmm(spatial_attention_map, D_reshaped.transpose(1, 2))\n",
    "        \n",
    "        # Reshape back to (batch_size, C, H, W)\n",
    "        x_weighted = x_weighted.view(batch_size, Ch, H, W)\n",
    "        \n",
    "        # Apply scale parameter and element-wise summation\n",
    "        # alpha = torch.nn.Parameter(torch.zeros(1), requires_grad=False)\n",
    "        alpha = torch.zeros(1)\n",
    "        out = alpha * x_weighted + x\n",
    "        \n",
    "        return out\n",
    "\n",
    "class DualAttentionNetwork(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(DualAttentionNetwork, self).__init__()\n",
    "        self.channel_attention = ChannelAttention(in_channels)\n",
    "        self.spatial_attention = SpatialAttention(in_channels)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(in_channels * 3, 1024)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply channel attention\n",
    "        channel_attention_map = self.channel_attention(x)\n",
    "        \n",
    "        # Apply spatial attention\n",
    "        spatial_attention_map = self.spatial_attention(x)\n",
    "        \n",
    "        # Concatenate the input feature map with channel and spatial attention maps\n",
    "        concatenated = torch.cat([x, channel_attention_map, spatial_attention_map], dim=1)\n",
    "        \n",
    "        # Global average pooling\n",
    "        gap = self.global_avg_pool(concatenated)\n",
    "        gap = gap.view(gap.size(0), -1)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        out = self.fc(gap)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetworkX(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetworkX, self).__init__()\n",
    "        self.backbone = ResNetBackbone()\n",
    "        self.attention = DualAttentionNetwork(512)\n",
    "        # self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        # self.fc = nn.Linear(512, 1024)  # Output 1024-dimensional embedding\n",
    "\n",
    "    def forward(self, x1):\n",
    "        out1 = self.backbone(x1)\n",
    "        out1 = self.attention(out1)\n",
    "        # out1 = self.pooling(out1)\n",
    "        # out1 = out1.view(out1.size(0), -1)\n",
    "        # out1 = self.fc(out1)\n",
    "\n",
    "\n",
    "        # out2 = self.fc(out2)\n",
    "\n",
    "        return out1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/athena/anaconda3/envs/nobuCon/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/athena/anaconda3/envs/nobuCon/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = SiameseNetworkX()\n",
    "model.load_state_dict(torch.load('/home/athena/Documents/GitHub/Dog-NosePrint-Recognition/best_acc_400.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "# Set the model to evaluation mode\n",
    "# Change the device to CPU\n",
    "# device = torch.device('cpu')\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize the image to 256x256\n",
    "    transforms.ToTensor(),          # Convert the image to a tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(size=(1, 3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nobuco] Tracing (DONE): 911 ops [00:01]\n",
      "[Nobuco] Converting: |          | 3/544 ops [00:00]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 03:26:51.755506: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-23 03:26:51.758351: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nobuco] Converting (DONE): |████████▏ | 444/544 ops [00:07]\n",
      "Legend:\n",
      "    \u001b[32mGreen\u001b[0m — conversion successful\n",
      "    \u001b[33mYellow\u001b[0m — conversion imprecise\n",
      "    \u001b[31mRed\u001b[0m — conversion failed\n",
      "    \u001b[31m\u001b[7mRed\u001b[0m — no converter found\n",
      "    \u001b[0m\u001b[1mBold\u001b[0m — conversion applied directly\n",
      "    * — subgraph reused\n",
      "    \u001b[7mTensor\u001b[0m — this output is not dependent on any of subgraph's input tensors\n",
      "    \u001b[4mTensor\u001b[0m — this input is a parameter / constant\n",
      "    \u001b[90mTensor\u001b[0m — this tensor is useless\n",
      "\n",
      "\u001b[32mSiameseNetworkX[__main__]\u001b[0m(float32_0<1,3,256,256>\u001b[0m) -> float32_1140<1,1024>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mResNetBackbone[__main__]\u001b[0m(float32_0<1,3,256,256>\u001b[0m) -> float32_1104<1,512,4,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_0<1,3,256,256>\u001b[0m) -> float32_1086<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_0<1,3,256,256>\u001b[0m) -> float32_2<1,64,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_0<1,3,256,256>\u001b[0m, float32_1<64,3,7,7>\u001b[0m, None, (2, 2), (3, 3), (1, 1), 1) -> float32_2<1,64,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_2<1,64,128,128>\u001b[0m) -> float32_7<1,64,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_2<1,64,128,128>\u001b[0m, float32_3<64>\u001b[0m, float32_4<64>\u001b[0m, float32_5<64>\u001b[0m, float32_6<64>\u001b[0m, False, 0.1, 1e-05) -> float32_7<1,64,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_2<1,64,128,128>\u001b[0m, float32_5<64>\u001b[0m, float32_6<64>\u001b[0m, float32_3<64>\u001b[0m, float32_4<64>\u001b[0m, False, 0.1, 1e-05, True) -> float32_7<1,64,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_7<1,64,128,128>\u001b[0m) -> float32_7<1,64,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_7<1,64,128,128>\u001b[0m, inplace=True) -> float32_7<1,64,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_7<1,64,128,128>\u001b[0m) -> float32_7<1,64,128,128>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mMaxPool2d[torch.nn.modules.pooling]\u001b[0m(float32_7<1,64,128,128>\u001b[0m) -> float32_8<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mmax_pool2d[torch.nn.functional]\u001b[0m(float32_7<1,64,128,128>\u001b[0m, 3, 2, 1, 1, ceil_mode=False, return_indices=False) -> float32_8<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmax_pool2d[torch]\u001b[0m(float32_7<1,64,128,128>\u001b[0m, 3, 2, 1, 1, False) -> float32_8<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_8<1,64,64,64>\u001b[0m) -> float32_78<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_8<1,64,64,64>\u001b[0m) -> float32_29<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_8<1,64,64,64>\u001b[0m) -> float32_10<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_8<1,64,64,64>\u001b[0m, float32_9<64,64,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_10<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_10<1,64,64,64>\u001b[0m) -> float32_15<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_10<1,64,64,64>\u001b[0m, float32_11<64>\u001b[0m, float32_12<64>\u001b[0m, float32_13<64>\u001b[0m, float32_14<64>\u001b[0m, False, 0.1, 1e-05) -> float32_15<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_10<1,64,64,64>\u001b[0m, float32_13<64>\u001b[0m, float32_14<64>\u001b[0m, float32_11<64>\u001b[0m, float32_12<64>\u001b[0m, False, 0.1, 1e-05, True) -> float32_15<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_15<1,64,64,64>\u001b[0m) -> float32_15<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_15<1,64,64,64>\u001b[0m, inplace=True) -> float32_15<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_15<1,64,64,64>\u001b[0m) -> float32_15<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_15<1,64,64,64>\u001b[0m) -> float32_17<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_15<1,64,64,64>\u001b[0m, float32_16<64,64,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_17<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_17<1,64,64,64>\u001b[0m) -> float32_22<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_17<1,64,64,64>\u001b[0m, float32_18<64>\u001b[0m, float32_19<64>\u001b[0m, float32_20<64>\u001b[0m, float32_21<64>\u001b[0m, False, 0.1, 1e-05) -> float32_22<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_17<1,64,64,64>\u001b[0m, float32_20<64>\u001b[0m, float32_21<64>\u001b[0m, float32_18<64>\u001b[0m, float32_19<64>\u001b[0m, False, 0.1, 1e-05, True) -> float32_22<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_22<1,64,64,64>\u001b[0m) -> float32_22<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_22<1,64,64,64>\u001b[0m) -> float32_24<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_22<1,64,64,64>\u001b[0m, float32_23<256,64,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_24<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_24<1,256,64,64>\u001b[0m) -> float32_29<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_24<1,256,64,64>\u001b[0m, float32_25<256>\u001b[0m, float32_26<256>\u001b[0m, float32_27<256>\u001b[0m, float32_28<256>\u001b[0m, False, 0.1, 1e-05) -> float32_29<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_24<1,256,64,64>\u001b[0m, float32_27<256>\u001b[0m, float32_28<256>\u001b[0m, float32_25<256>\u001b[0m, float32_26<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_29<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_8<1,64,64,64>\u001b[0m) -> float32_36<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_8<1,64,64,64>\u001b[0m) -> float32_31<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_8<1,64,64,64>\u001b[0m, float32_30<256,64,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_31<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_31<1,256,64,64>\u001b[0m) -> float32_36<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_31<1,256,64,64>\u001b[0m, float32_32<256>\u001b[0m, float32_33<256>\u001b[0m, float32_34<256>\u001b[0m, float32_35<256>\u001b[0m, False, 0.1, 1e-05) -> float32_36<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_31<1,256,64,64>\u001b[0m, float32_34<256>\u001b[0m, float32_35<256>\u001b[0m, float32_32<256>\u001b[0m, float32_33<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_36<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_29<1,256,64,64>\u001b[0m, float32_36<1,256,64,64>\u001b[0m) -> float32_29<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_29<1,256,64,64>\u001b[0m, float32_36<1,256,64,64>\u001b[0m) -> float32_29<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_29<1,256,64,64>\u001b[0m) -> float32_29<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_29<1,256,64,64>\u001b[0m) -> float32_57<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_29<1,256,64,64>\u001b[0m) -> float32_38<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_29<1,256,64,64>\u001b[0m, float32_37<64,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_38<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_38<1,64,64,64>\u001b[0m) -> float32_43<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_38<1,64,64,64>\u001b[0m, float32_39<64>\u001b[0m, float32_40<64>\u001b[0m, float32_41<64>\u001b[0m, float32_42<64>\u001b[0m, False, 0.1, 1e-05) -> float32_43<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_38<1,64,64,64>\u001b[0m, float32_41<64>\u001b[0m, float32_42<64>\u001b[0m, float32_39<64>\u001b[0m, float32_40<64>\u001b[0m, False, 0.1, 1e-05, True) -> float32_43<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_43<1,64,64,64>\u001b[0m) -> float32_43<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_43<1,64,64,64>\u001b[0m, inplace=True) -> float32_43<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_43<1,64,64,64>\u001b[0m) -> float32_43<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_43<1,64,64,64>\u001b[0m) -> float32_45<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_43<1,64,64,64>\u001b[0m, float32_44<64,64,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_45<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_45<1,64,64,64>\u001b[0m) -> float32_50<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_45<1,64,64,64>\u001b[0m, float32_46<64>\u001b[0m, float32_47<64>\u001b[0m, float32_48<64>\u001b[0m, float32_49<64>\u001b[0m, False, 0.1, 1e-05) -> float32_50<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_45<1,64,64,64>\u001b[0m, float32_48<64>\u001b[0m, float32_49<64>\u001b[0m, float32_46<64>\u001b[0m, float32_47<64>\u001b[0m, False, 0.1, 1e-05, True) -> float32_50<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_50<1,64,64,64>\u001b[0m) -> float32_50<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_50<1,64,64,64>\u001b[0m) -> float32_52<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_50<1,64,64,64>\u001b[0m, float32_51<256,64,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_52<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_52<1,256,64,64>\u001b[0m) -> float32_57<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_52<1,256,64,64>\u001b[0m, float32_53<256>\u001b[0m, float32_54<256>\u001b[0m, float32_55<256>\u001b[0m, float32_56<256>\u001b[0m, False, 0.1, 1e-05) -> float32_57<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_52<1,256,64,64>\u001b[0m, float32_55<256>\u001b[0m, float32_56<256>\u001b[0m, float32_53<256>\u001b[0m, float32_54<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_57<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_57<1,256,64,64>\u001b[0m, float32_29<1,256,64,64>\u001b[0m) -> float32_57<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_57<1,256,64,64>\u001b[0m, float32_29<1,256,64,64>\u001b[0m) -> float32_57<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_57<1,256,64,64>\u001b[0m) -> float32_57<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_57<1,256,64,64>\u001b[0m) -> float32_78<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_57<1,256,64,64>\u001b[0m) -> float32_59<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_57<1,256,64,64>\u001b[0m, float32_58<64,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_59<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_59<1,64,64,64>\u001b[0m) -> float32_64<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_59<1,64,64,64>\u001b[0m, float32_60<64>\u001b[0m, float32_61<64>\u001b[0m, float32_62<64>\u001b[0m, float32_63<64>\u001b[0m, False, 0.1, 1e-05) -> float32_64<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_59<1,64,64,64>\u001b[0m, float32_62<64>\u001b[0m, float32_63<64>\u001b[0m, float32_60<64>\u001b[0m, float32_61<64>\u001b[0m, False, 0.1, 1e-05, True) -> float32_64<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_64<1,64,64,64>\u001b[0m) -> float32_64<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_64<1,64,64,64>\u001b[0m, inplace=True) -> float32_64<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_64<1,64,64,64>\u001b[0m) -> float32_64<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_64<1,64,64,64>\u001b[0m) -> float32_66<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_64<1,64,64,64>\u001b[0m, float32_65<64,64,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_66<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_66<1,64,64,64>\u001b[0m) -> float32_71<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_66<1,64,64,64>\u001b[0m, float32_67<64>\u001b[0m, float32_68<64>\u001b[0m, float32_69<64>\u001b[0m, float32_70<64>\u001b[0m, False, 0.1, 1e-05) -> float32_71<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_66<1,64,64,64>\u001b[0m, float32_69<64>\u001b[0m, float32_70<64>\u001b[0m, float32_67<64>\u001b[0m, float32_68<64>\u001b[0m, False, 0.1, 1e-05, True) -> float32_71<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_71<1,64,64,64>\u001b[0m) -> float32_71<1,64,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_71<1,64,64,64>\u001b[0m) -> float32_73<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_71<1,64,64,64>\u001b[0m, float32_72<256,64,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_73<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_73<1,256,64,64>\u001b[0m) -> float32_78<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_73<1,256,64,64>\u001b[0m, float32_74<256>\u001b[0m, float32_75<256>\u001b[0m, float32_76<256>\u001b[0m, float32_77<256>\u001b[0m, False, 0.1, 1e-05) -> float32_78<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_73<1,256,64,64>\u001b[0m, float32_76<256>\u001b[0m, float32_77<256>\u001b[0m, float32_74<256>\u001b[0m, float32_75<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_78<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_78<1,256,64,64>\u001b[0m, float32_57<1,256,64,64>\u001b[0m) -> float32_78<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_78<1,256,64,64>\u001b[0m, float32_57<1,256,64,64>\u001b[0m) -> float32_78<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_78<1,256,64,64>\u001b[0m) -> float32_78<1,256,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_78<1,256,64,64>\u001b[0m) -> float32_253<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_78<1,256,64,64>\u001b[0m) -> float32_99<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_78<1,256,64,64>\u001b[0m) -> float32_80<1,128,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_78<1,256,64,64>\u001b[0m, float32_79<128,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_80<1,128,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_80<1,128,64,64>\u001b[0m) -> float32_85<1,128,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_80<1,128,64,64>\u001b[0m, float32_81<128>\u001b[0m, float32_82<128>\u001b[0m, float32_83<128>\u001b[0m, float32_84<128>\u001b[0m, False, 0.1, 1e-05) -> float32_85<1,128,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_80<1,128,64,64>\u001b[0m, float32_83<128>\u001b[0m, float32_84<128>\u001b[0m, float32_81<128>\u001b[0m, float32_82<128>\u001b[0m, False, 0.1, 1e-05, True) -> float32_85<1,128,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_85<1,128,64,64>\u001b[0m) -> float32_85<1,128,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_85<1,128,64,64>\u001b[0m, inplace=True) -> float32_85<1,128,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_85<1,128,64,64>\u001b[0m) -> float32_85<1,128,64,64>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_85<1,128,64,64>\u001b[0m) -> float32_87<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_85<1,128,64,64>\u001b[0m, float32_86<128,128,3,3>\u001b[0m, None, (2, 2), (1, 1), (1, 1), 1) -> float32_87<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_87<1,128,32,32>\u001b[0m) -> float32_92<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_87<1,128,32,32>\u001b[0m, float32_88<128>\u001b[0m, float32_89<128>\u001b[0m, float32_90<128>\u001b[0m, float32_91<128>\u001b[0m, False, 0.1, 1e-05) -> float32_92<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_87<1,128,32,32>\u001b[0m, float32_90<128>\u001b[0m, float32_91<128>\u001b[0m, float32_88<128>\u001b[0m, float32_89<128>\u001b[0m, False, 0.1, 1e-05, True) -> float32_92<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_92<1,128,32,32>\u001b[0m) -> float32_92<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_92<1,128,32,32>\u001b[0m) -> float32_94<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_92<1,128,32,32>\u001b[0m, float32_93<512,128,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_94<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_94<1,512,32,32>\u001b[0m) -> float32_99<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_94<1,512,32,32>\u001b[0m, float32_95<512>\u001b[0m, float32_96<512>\u001b[0m, float32_97<512>\u001b[0m, float32_98<512>\u001b[0m, False, 0.1, 1e-05) -> float32_99<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_94<1,512,32,32>\u001b[0m, float32_97<512>\u001b[0m, float32_98<512>\u001b[0m, float32_95<512>\u001b[0m, float32_96<512>\u001b[0m, False, 0.1, 1e-05, True) -> float32_99<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_78<1,256,64,64>\u001b[0m) -> float32_106<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_78<1,256,64,64>\u001b[0m) -> float32_101<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_78<1,256,64,64>\u001b[0m, float32_100<512,256,1,1>\u001b[0m, None, (2, 2), (0, 0), (1, 1), 1) -> float32_101<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_101<1,512,32,32>\u001b[0m) -> float32_106<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_101<1,512,32,32>\u001b[0m, float32_102<512>\u001b[0m, float32_103<512>\u001b[0m, float32_104<512>\u001b[0m, float32_105<512>\u001b[0m, False, 0.1, 1e-05) -> float32_106<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_101<1,512,32,32>\u001b[0m, float32_104<512>\u001b[0m, float32_105<512>\u001b[0m, float32_102<512>\u001b[0m, float32_103<512>\u001b[0m, False, 0.1, 1e-05, True) -> float32_106<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_99<1,512,32,32>\u001b[0m, float32_106<1,512,32,32>\u001b[0m) -> float32_99<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_99<1,512,32,32>\u001b[0m, float32_106<1,512,32,32>\u001b[0m) -> float32_99<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_99<1,512,32,32>\u001b[0m) -> float32_99<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_99<1,512,32,32>\u001b[0m) -> float32_127<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_99<1,512,32,32>\u001b[0m) -> float32_108<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_99<1,512,32,32>\u001b[0m, float32_107<128,512,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_108<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_108<1,128,32,32>\u001b[0m) -> float32_113<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_108<1,128,32,32>\u001b[0m, float32_109<128>\u001b[0m, float32_110<128>\u001b[0m, float32_111<128>\u001b[0m, float32_112<128>\u001b[0m, False, 0.1, 1e-05) -> float32_113<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_108<1,128,32,32>\u001b[0m, float32_111<128>\u001b[0m, float32_112<128>\u001b[0m, float32_109<128>\u001b[0m, float32_110<128>\u001b[0m, False, 0.1, 1e-05, True) -> float32_113<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_113<1,128,32,32>\u001b[0m) -> float32_113<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_113<1,128,32,32>\u001b[0m, inplace=True) -> float32_113<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_113<1,128,32,32>\u001b[0m) -> float32_113<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_113<1,128,32,32>\u001b[0m) -> float32_115<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_113<1,128,32,32>\u001b[0m, float32_114<128,128,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_115<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_115<1,128,32,32>\u001b[0m) -> float32_120<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_115<1,128,32,32>\u001b[0m, float32_116<128>\u001b[0m, float32_117<128>\u001b[0m, float32_118<128>\u001b[0m, float32_119<128>\u001b[0m, False, 0.1, 1e-05) -> float32_120<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_115<1,128,32,32>\u001b[0m, float32_118<128>\u001b[0m, float32_119<128>\u001b[0m, float32_116<128>\u001b[0m, float32_117<128>\u001b[0m, False, 0.1, 1e-05, True) -> float32_120<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_120<1,128,32,32>\u001b[0m) -> float32_120<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_120<1,128,32,32>\u001b[0m) -> float32_122<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_120<1,128,32,32>\u001b[0m, float32_121<512,128,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_122<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_122<1,512,32,32>\u001b[0m) -> float32_127<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_122<1,512,32,32>\u001b[0m, float32_123<512>\u001b[0m, float32_124<512>\u001b[0m, float32_125<512>\u001b[0m, float32_126<512>\u001b[0m, False, 0.1, 1e-05) -> float32_127<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_122<1,512,32,32>\u001b[0m, float32_125<512>\u001b[0m, float32_126<512>\u001b[0m, float32_123<512>\u001b[0m, float32_124<512>\u001b[0m, False, 0.1, 1e-05, True) -> float32_127<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_127<1,512,32,32>\u001b[0m, float32_99<1,512,32,32>\u001b[0m) -> float32_127<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_127<1,512,32,32>\u001b[0m, float32_99<1,512,32,32>\u001b[0m) -> float32_127<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_127<1,512,32,32>\u001b[0m) -> float32_127<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_127<1,512,32,32>\u001b[0m) -> float32_148<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_127<1,512,32,32>\u001b[0m) -> float32_129<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_127<1,512,32,32>\u001b[0m, float32_128<128,512,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_129<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_129<1,128,32,32>\u001b[0m) -> float32_134<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_129<1,128,32,32>\u001b[0m, float32_130<128>\u001b[0m, float32_131<128>\u001b[0m, float32_132<128>\u001b[0m, float32_133<128>\u001b[0m, False, 0.1, 1e-05) -> float32_134<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_129<1,128,32,32>\u001b[0m, float32_132<128>\u001b[0m, float32_133<128>\u001b[0m, float32_130<128>\u001b[0m, float32_131<128>\u001b[0m, False, 0.1, 1e-05, True) -> float32_134<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_134<1,128,32,32>\u001b[0m) -> float32_134<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_134<1,128,32,32>\u001b[0m, inplace=True) -> float32_134<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_134<1,128,32,32>\u001b[0m) -> float32_134<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_134<1,128,32,32>\u001b[0m) -> float32_136<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_134<1,128,32,32>\u001b[0m, float32_135<128,128,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_136<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_136<1,128,32,32>\u001b[0m) -> float32_141<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_136<1,128,32,32>\u001b[0m, float32_137<128>\u001b[0m, float32_138<128>\u001b[0m, float32_139<128>\u001b[0m, float32_140<128>\u001b[0m, False, 0.1, 1e-05) -> float32_141<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_136<1,128,32,32>\u001b[0m, float32_139<128>\u001b[0m, float32_140<128>\u001b[0m, float32_137<128>\u001b[0m, float32_138<128>\u001b[0m, False, 0.1, 1e-05, True) -> float32_141<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_141<1,128,32,32>\u001b[0m) -> float32_141<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_141<1,128,32,32>\u001b[0m) -> float32_143<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_141<1,128,32,32>\u001b[0m, float32_142<512,128,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_143<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_143<1,512,32,32>\u001b[0m) -> float32_148<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_143<1,512,32,32>\u001b[0m, float32_144<512>\u001b[0m, float32_145<512>\u001b[0m, float32_146<512>\u001b[0m, float32_147<512>\u001b[0m, False, 0.1, 1e-05) -> float32_148<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_143<1,512,32,32>\u001b[0m, float32_146<512>\u001b[0m, float32_147<512>\u001b[0m, float32_144<512>\u001b[0m, float32_145<512>\u001b[0m, False, 0.1, 1e-05, True) -> float32_148<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_148<1,512,32,32>\u001b[0m, float32_127<1,512,32,32>\u001b[0m) -> float32_148<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_148<1,512,32,32>\u001b[0m, float32_127<1,512,32,32>\u001b[0m) -> float32_148<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_148<1,512,32,32>\u001b[0m) -> float32_148<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_148<1,512,32,32>\u001b[0m) -> float32_169<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_148<1,512,32,32>\u001b[0m) -> float32_150<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_148<1,512,32,32>\u001b[0m, float32_149<128,512,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_150<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_150<1,128,32,32>\u001b[0m) -> float32_155<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_150<1,128,32,32>\u001b[0m, float32_151<128>\u001b[0m, float32_152<128>\u001b[0m, float32_153<128>\u001b[0m, float32_154<128>\u001b[0m, False, 0.1, 1e-05) -> float32_155<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_150<1,128,32,32>\u001b[0m, float32_153<128>\u001b[0m, float32_154<128>\u001b[0m, float32_151<128>\u001b[0m, float32_152<128>\u001b[0m, False, 0.1, 1e-05, True) -> float32_155<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_155<1,128,32,32>\u001b[0m) -> float32_155<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_155<1,128,32,32>\u001b[0m, inplace=True) -> float32_155<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_155<1,128,32,32>\u001b[0m) -> float32_155<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_155<1,128,32,32>\u001b[0m) -> float32_157<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_155<1,128,32,32>\u001b[0m, float32_156<128,128,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_157<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_157<1,128,32,32>\u001b[0m) -> float32_162<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_157<1,128,32,32>\u001b[0m, float32_158<128>\u001b[0m, float32_159<128>\u001b[0m, float32_160<128>\u001b[0m, float32_161<128>\u001b[0m, False, 0.1, 1e-05) -> float32_162<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_157<1,128,32,32>\u001b[0m, float32_160<128>\u001b[0m, float32_161<128>\u001b[0m, float32_158<128>\u001b[0m, float32_159<128>\u001b[0m, False, 0.1, 1e-05, True) -> float32_162<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_162<1,128,32,32>\u001b[0m) -> float32_162<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_162<1,128,32,32>\u001b[0m) -> float32_164<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_162<1,128,32,32>\u001b[0m, float32_163<512,128,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_164<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_164<1,512,32,32>\u001b[0m) -> float32_169<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_164<1,512,32,32>\u001b[0m, float32_165<512>\u001b[0m, float32_166<512>\u001b[0m, float32_167<512>\u001b[0m, float32_168<512>\u001b[0m, False, 0.1, 1e-05) -> float32_169<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_164<1,512,32,32>\u001b[0m, float32_167<512>\u001b[0m, float32_168<512>\u001b[0m, float32_165<512>\u001b[0m, float32_166<512>\u001b[0m, False, 0.1, 1e-05, True) -> float32_169<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_169<1,512,32,32>\u001b[0m, float32_148<1,512,32,32>\u001b[0m) -> float32_169<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_169<1,512,32,32>\u001b[0m, float32_148<1,512,32,32>\u001b[0m) -> float32_169<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_169<1,512,32,32>\u001b[0m) -> float32_169<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_169<1,512,32,32>\u001b[0m) -> float32_190<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_169<1,512,32,32>\u001b[0m) -> float32_171<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_169<1,512,32,32>\u001b[0m, float32_170<128,512,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_171<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_171<1,128,32,32>\u001b[0m) -> float32_176<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_171<1,128,32,32>\u001b[0m, float32_172<128>\u001b[0m, float32_173<128>\u001b[0m, float32_174<128>\u001b[0m, float32_175<128>\u001b[0m, False, 0.1, 1e-05) -> float32_176<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_171<1,128,32,32>\u001b[0m, float32_174<128>\u001b[0m, float32_175<128>\u001b[0m, float32_172<128>\u001b[0m, float32_173<128>\u001b[0m, False, 0.1, 1e-05, True) -> float32_176<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_176<1,128,32,32>\u001b[0m) -> float32_176<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_176<1,128,32,32>\u001b[0m, inplace=True) -> float32_176<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_176<1,128,32,32>\u001b[0m) -> float32_176<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_176<1,128,32,32>\u001b[0m) -> float32_178<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_176<1,128,32,32>\u001b[0m, float32_177<128,128,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_178<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_178<1,128,32,32>\u001b[0m) -> float32_183<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_178<1,128,32,32>\u001b[0m, float32_179<128>\u001b[0m, float32_180<128>\u001b[0m, float32_181<128>\u001b[0m, float32_182<128>\u001b[0m, False, 0.1, 1e-05) -> float32_183<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_178<1,128,32,32>\u001b[0m, float32_181<128>\u001b[0m, float32_182<128>\u001b[0m, float32_179<128>\u001b[0m, float32_180<128>\u001b[0m, False, 0.1, 1e-05, True) -> float32_183<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_183<1,128,32,32>\u001b[0m) -> float32_183<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_183<1,128,32,32>\u001b[0m) -> float32_185<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_183<1,128,32,32>\u001b[0m, float32_184<512,128,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_185<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_185<1,512,32,32>\u001b[0m) -> float32_190<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_185<1,512,32,32>\u001b[0m, float32_186<512>\u001b[0m, float32_187<512>\u001b[0m, float32_188<512>\u001b[0m, float32_189<512>\u001b[0m, False, 0.1, 1e-05) -> float32_190<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_185<1,512,32,32>\u001b[0m, float32_188<512>\u001b[0m, float32_189<512>\u001b[0m, float32_186<512>\u001b[0m, float32_187<512>\u001b[0m, False, 0.1, 1e-05, True) -> float32_190<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_190<1,512,32,32>\u001b[0m, float32_169<1,512,32,32>\u001b[0m) -> float32_190<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_190<1,512,32,32>\u001b[0m, float32_169<1,512,32,32>\u001b[0m) -> float32_190<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_190<1,512,32,32>\u001b[0m) -> float32_190<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_190<1,512,32,32>\u001b[0m) -> float32_211<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_190<1,512,32,32>\u001b[0m) -> float32_192<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_190<1,512,32,32>\u001b[0m, float32_191<128,512,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_192<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_192<1,128,32,32>\u001b[0m) -> float32_197<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_192<1,128,32,32>\u001b[0m, float32_193<128>\u001b[0m, float32_194<128>\u001b[0m, float32_195<128>\u001b[0m, float32_196<128>\u001b[0m, False, 0.1, 1e-05) -> float32_197<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_192<1,128,32,32>\u001b[0m, float32_195<128>\u001b[0m, float32_196<128>\u001b[0m, float32_193<128>\u001b[0m, float32_194<128>\u001b[0m, False, 0.1, 1e-05, True) -> float32_197<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_197<1,128,32,32>\u001b[0m) -> float32_197<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_197<1,128,32,32>\u001b[0m, inplace=True) -> float32_197<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_197<1,128,32,32>\u001b[0m) -> float32_197<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_197<1,128,32,32>\u001b[0m) -> float32_199<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_197<1,128,32,32>\u001b[0m, float32_198<128,128,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_199<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_199<1,128,32,32>\u001b[0m) -> float32_204<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_199<1,128,32,32>\u001b[0m, float32_200<128>\u001b[0m, float32_201<128>\u001b[0m, float32_202<128>\u001b[0m, float32_203<128>\u001b[0m, False, 0.1, 1e-05) -> float32_204<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_199<1,128,32,32>\u001b[0m, float32_202<128>\u001b[0m, float32_203<128>\u001b[0m, float32_200<128>\u001b[0m, float32_201<128>\u001b[0m, False, 0.1, 1e-05, True) -> float32_204<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_204<1,128,32,32>\u001b[0m) -> float32_204<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_204<1,128,32,32>\u001b[0m) -> float32_206<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_204<1,128,32,32>\u001b[0m, float32_205<512,128,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_206<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_206<1,512,32,32>\u001b[0m) -> float32_211<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_206<1,512,32,32>\u001b[0m, float32_207<512>\u001b[0m, float32_208<512>\u001b[0m, float32_209<512>\u001b[0m, float32_210<512>\u001b[0m, False, 0.1, 1e-05) -> float32_211<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_206<1,512,32,32>\u001b[0m, float32_209<512>\u001b[0m, float32_210<512>\u001b[0m, float32_207<512>\u001b[0m, float32_208<512>\u001b[0m, False, 0.1, 1e-05, True) -> float32_211<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_211<1,512,32,32>\u001b[0m, float32_190<1,512,32,32>\u001b[0m) -> float32_211<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_211<1,512,32,32>\u001b[0m, float32_190<1,512,32,32>\u001b[0m) -> float32_211<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_211<1,512,32,32>\u001b[0m) -> float32_211<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_211<1,512,32,32>\u001b[0m) -> float32_232<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_211<1,512,32,32>\u001b[0m) -> float32_213<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_211<1,512,32,32>\u001b[0m, float32_212<128,512,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_213<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_213<1,128,32,32>\u001b[0m) -> float32_218<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_213<1,128,32,32>\u001b[0m, float32_214<128>\u001b[0m, float32_215<128>\u001b[0m, float32_216<128>\u001b[0m, float32_217<128>\u001b[0m, False, 0.1, 1e-05) -> float32_218<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_213<1,128,32,32>\u001b[0m, float32_216<128>\u001b[0m, float32_217<128>\u001b[0m, float32_214<128>\u001b[0m, float32_215<128>\u001b[0m, False, 0.1, 1e-05, True) -> float32_218<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_218<1,128,32,32>\u001b[0m) -> float32_218<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_218<1,128,32,32>\u001b[0m, inplace=True) -> float32_218<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_218<1,128,32,32>\u001b[0m) -> float32_218<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_218<1,128,32,32>\u001b[0m) -> float32_220<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_218<1,128,32,32>\u001b[0m, float32_219<128,128,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_220<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_220<1,128,32,32>\u001b[0m) -> float32_225<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_220<1,128,32,32>\u001b[0m, float32_221<128>\u001b[0m, float32_222<128>\u001b[0m, float32_223<128>\u001b[0m, float32_224<128>\u001b[0m, False, 0.1, 1e-05) -> float32_225<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_220<1,128,32,32>\u001b[0m, float32_223<128>\u001b[0m, float32_224<128>\u001b[0m, float32_221<128>\u001b[0m, float32_222<128>\u001b[0m, False, 0.1, 1e-05, True) -> float32_225<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_225<1,128,32,32>\u001b[0m) -> float32_225<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_225<1,128,32,32>\u001b[0m) -> float32_227<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_225<1,128,32,32>\u001b[0m, float32_226<512,128,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_227<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_227<1,512,32,32>\u001b[0m) -> float32_232<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_227<1,512,32,32>\u001b[0m, float32_228<512>\u001b[0m, float32_229<512>\u001b[0m, float32_230<512>\u001b[0m, float32_231<512>\u001b[0m, False, 0.1, 1e-05) -> float32_232<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_227<1,512,32,32>\u001b[0m, float32_230<512>\u001b[0m, float32_231<512>\u001b[0m, float32_228<512>\u001b[0m, float32_229<512>\u001b[0m, False, 0.1, 1e-05, True) -> float32_232<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_232<1,512,32,32>\u001b[0m, float32_211<1,512,32,32>\u001b[0m) -> float32_232<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_232<1,512,32,32>\u001b[0m, float32_211<1,512,32,32>\u001b[0m) -> float32_232<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_232<1,512,32,32>\u001b[0m) -> float32_232<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_232<1,512,32,32>\u001b[0m) -> float32_253<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_232<1,512,32,32>\u001b[0m) -> float32_234<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_232<1,512,32,32>\u001b[0m, float32_233<128,512,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_234<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_234<1,128,32,32>\u001b[0m) -> float32_239<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_234<1,128,32,32>\u001b[0m, float32_235<128>\u001b[0m, float32_236<128>\u001b[0m, float32_237<128>\u001b[0m, float32_238<128>\u001b[0m, False, 0.1, 1e-05) -> float32_239<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_234<1,128,32,32>\u001b[0m, float32_237<128>\u001b[0m, float32_238<128>\u001b[0m, float32_235<128>\u001b[0m, float32_236<128>\u001b[0m, False, 0.1, 1e-05, True) -> float32_239<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_239<1,128,32,32>\u001b[0m) -> float32_239<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_239<1,128,32,32>\u001b[0m, inplace=True) -> float32_239<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_239<1,128,32,32>\u001b[0m) -> float32_239<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_239<1,128,32,32>\u001b[0m) -> float32_241<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_239<1,128,32,32>\u001b[0m, float32_240<128,128,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_241<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_241<1,128,32,32>\u001b[0m) -> float32_246<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_241<1,128,32,32>\u001b[0m, float32_242<128>\u001b[0m, float32_243<128>\u001b[0m, float32_244<128>\u001b[0m, float32_245<128>\u001b[0m, False, 0.1, 1e-05) -> float32_246<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_241<1,128,32,32>\u001b[0m, float32_244<128>\u001b[0m, float32_245<128>\u001b[0m, float32_242<128>\u001b[0m, float32_243<128>\u001b[0m, False, 0.1, 1e-05, True) -> float32_246<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_246<1,128,32,32>\u001b[0m) -> float32_246<1,128,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_246<1,128,32,32>\u001b[0m) -> float32_248<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_246<1,128,32,32>\u001b[0m, float32_247<512,128,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_248<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_248<1,512,32,32>\u001b[0m) -> float32_253<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_248<1,512,32,32>\u001b[0m, float32_249<512>\u001b[0m, float32_250<512>\u001b[0m, float32_251<512>\u001b[0m, float32_252<512>\u001b[0m, False, 0.1, 1e-05) -> float32_253<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_248<1,512,32,32>\u001b[0m, float32_251<512>\u001b[0m, float32_252<512>\u001b[0m, float32_249<512>\u001b[0m, float32_250<512>\u001b[0m, False, 0.1, 1e-05, True) -> float32_253<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_253<1,512,32,32>\u001b[0m, float32_232<1,512,32,32>\u001b[0m) -> float32_253<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_253<1,512,32,32>\u001b[0m, float32_232<1,512,32,32>\u001b[0m) -> float32_253<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_253<1,512,32,32>\u001b[0m) -> float32_253<1,512,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_253<1,512,32,32>\u001b[0m) -> float32_1016<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_253<1,512,32,32>\u001b[0m) -> float32_274<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_253<1,512,32,32>\u001b[0m) -> float32_255<1,256,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_253<1,512,32,32>\u001b[0m, float32_254<256,512,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_255<1,256,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_255<1,256,32,32>\u001b[0m) -> float32_260<1,256,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_255<1,256,32,32>\u001b[0m, float32_256<256>\u001b[0m, float32_257<256>\u001b[0m, float32_258<256>\u001b[0m, float32_259<256>\u001b[0m, False, 0.1, 1e-05) -> float32_260<1,256,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_255<1,256,32,32>\u001b[0m, float32_258<256>\u001b[0m, float32_259<256>\u001b[0m, float32_256<256>\u001b[0m, float32_257<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_260<1,256,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_260<1,256,32,32>\u001b[0m) -> float32_260<1,256,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_260<1,256,32,32>\u001b[0m, inplace=True) -> float32_260<1,256,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_260<1,256,32,32>\u001b[0m) -> float32_260<1,256,32,32>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_260<1,256,32,32>\u001b[0m) -> float32_262<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_260<1,256,32,32>\u001b[0m, float32_261<256,256,3,3>\u001b[0m, None, (2, 2), (1, 1), (1, 1), 1) -> float32_262<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_262<1,256,16,16>\u001b[0m) -> float32_267<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_262<1,256,16,16>\u001b[0m, float32_263<256>\u001b[0m, float32_264<256>\u001b[0m, float32_265<256>\u001b[0m, float32_266<256>\u001b[0m, False, 0.1, 1e-05) -> float32_267<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_262<1,256,16,16>\u001b[0m, float32_265<256>\u001b[0m, float32_266<256>\u001b[0m, float32_263<256>\u001b[0m, float32_264<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_267<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_267<1,256,16,16>\u001b[0m) -> float32_267<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_267<1,256,16,16>\u001b[0m) -> float32_269<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_267<1,256,16,16>\u001b[0m, float32_268<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_269<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_269<1,1024,16,16>\u001b[0m) -> float32_274<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_269<1,1024,16,16>\u001b[0m, float32_270<1024>\u001b[0m, float32_271<1024>\u001b[0m, float32_272<1024>\u001b[0m, float32_273<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_274<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_269<1,1024,16,16>\u001b[0m, float32_272<1024>\u001b[0m, float32_273<1024>\u001b[0m, float32_270<1024>\u001b[0m, float32_271<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_274<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_253<1,512,32,32>\u001b[0m) -> float32_281<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_253<1,512,32,32>\u001b[0m) -> float32_276<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_253<1,512,32,32>\u001b[0m, float32_275<1024,512,1,1>\u001b[0m, None, (2, 2), (0, 0), (1, 1), 1) -> float32_276<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_276<1,1024,16,16>\u001b[0m) -> float32_281<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_276<1,1024,16,16>\u001b[0m, float32_277<1024>\u001b[0m, float32_278<1024>\u001b[0m, float32_279<1024>\u001b[0m, float32_280<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_281<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_276<1,1024,16,16>\u001b[0m, float32_279<1024>\u001b[0m, float32_280<1024>\u001b[0m, float32_277<1024>\u001b[0m, float32_278<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_281<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_274<1,1024,16,16>\u001b[0m, float32_281<1,1024,16,16>\u001b[0m) -> float32_274<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_274<1,1024,16,16>\u001b[0m, float32_281<1,1024,16,16>\u001b[0m) -> float32_274<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_274<1,1024,16,16>\u001b[0m) -> float32_274<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_274<1,1024,16,16>\u001b[0m) -> float32_302<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_274<1,1024,16,16>\u001b[0m) -> float32_283<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_274<1,1024,16,16>\u001b[0m, float32_282<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_283<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_283<1,256,16,16>\u001b[0m) -> float32_288<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_283<1,256,16,16>\u001b[0m, float32_284<256>\u001b[0m, float32_285<256>\u001b[0m, float32_286<256>\u001b[0m, float32_287<256>\u001b[0m, False, 0.1, 1e-05) -> float32_288<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_283<1,256,16,16>\u001b[0m, float32_286<256>\u001b[0m, float32_287<256>\u001b[0m, float32_284<256>\u001b[0m, float32_285<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_288<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_288<1,256,16,16>\u001b[0m) -> float32_288<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_288<1,256,16,16>\u001b[0m, inplace=True) -> float32_288<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_288<1,256,16,16>\u001b[0m) -> float32_288<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_288<1,256,16,16>\u001b[0m) -> float32_290<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_288<1,256,16,16>\u001b[0m, float32_289<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_290<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_290<1,256,16,16>\u001b[0m) -> float32_295<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_290<1,256,16,16>\u001b[0m, float32_291<256>\u001b[0m, float32_292<256>\u001b[0m, float32_293<256>\u001b[0m, float32_294<256>\u001b[0m, False, 0.1, 1e-05) -> float32_295<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_290<1,256,16,16>\u001b[0m, float32_293<256>\u001b[0m, float32_294<256>\u001b[0m, float32_291<256>\u001b[0m, float32_292<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_295<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_295<1,256,16,16>\u001b[0m) -> float32_295<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_295<1,256,16,16>\u001b[0m) -> float32_297<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_295<1,256,16,16>\u001b[0m, float32_296<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_297<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_297<1,1024,16,16>\u001b[0m) -> float32_302<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_297<1,1024,16,16>\u001b[0m, float32_298<1024>\u001b[0m, float32_299<1024>\u001b[0m, float32_300<1024>\u001b[0m, float32_301<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_302<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_297<1,1024,16,16>\u001b[0m, float32_300<1024>\u001b[0m, float32_301<1024>\u001b[0m, float32_298<1024>\u001b[0m, float32_299<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_302<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_302<1,1024,16,16>\u001b[0m, float32_274<1,1024,16,16>\u001b[0m) -> float32_302<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_302<1,1024,16,16>\u001b[0m, float32_274<1,1024,16,16>\u001b[0m) -> float32_302<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_302<1,1024,16,16>\u001b[0m) -> float32_302<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_302<1,1024,16,16>\u001b[0m) -> float32_323<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_302<1,1024,16,16>\u001b[0m) -> float32_304<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_302<1,1024,16,16>\u001b[0m, float32_303<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_304<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_304<1,256,16,16>\u001b[0m) -> float32_309<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_304<1,256,16,16>\u001b[0m, float32_305<256>\u001b[0m, float32_306<256>\u001b[0m, float32_307<256>\u001b[0m, float32_308<256>\u001b[0m, False, 0.1, 1e-05) -> float32_309<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_304<1,256,16,16>\u001b[0m, float32_307<256>\u001b[0m, float32_308<256>\u001b[0m, float32_305<256>\u001b[0m, float32_306<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_309<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_309<1,256,16,16>\u001b[0m) -> float32_309<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_309<1,256,16,16>\u001b[0m, inplace=True) -> float32_309<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_309<1,256,16,16>\u001b[0m) -> float32_309<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_309<1,256,16,16>\u001b[0m) -> float32_311<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_309<1,256,16,16>\u001b[0m, float32_310<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_311<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_311<1,256,16,16>\u001b[0m) -> float32_316<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_311<1,256,16,16>\u001b[0m, float32_312<256>\u001b[0m, float32_313<256>\u001b[0m, float32_314<256>\u001b[0m, float32_315<256>\u001b[0m, False, 0.1, 1e-05) -> float32_316<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_311<1,256,16,16>\u001b[0m, float32_314<256>\u001b[0m, float32_315<256>\u001b[0m, float32_312<256>\u001b[0m, float32_313<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_316<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_316<1,256,16,16>\u001b[0m) -> float32_316<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_316<1,256,16,16>\u001b[0m) -> float32_318<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_316<1,256,16,16>\u001b[0m, float32_317<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_318<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_318<1,1024,16,16>\u001b[0m) -> float32_323<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_318<1,1024,16,16>\u001b[0m, float32_319<1024>\u001b[0m, float32_320<1024>\u001b[0m, float32_321<1024>\u001b[0m, float32_322<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_323<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_318<1,1024,16,16>\u001b[0m, float32_321<1024>\u001b[0m, float32_322<1024>\u001b[0m, float32_319<1024>\u001b[0m, float32_320<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_323<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_323<1,1024,16,16>\u001b[0m, float32_302<1,1024,16,16>\u001b[0m) -> float32_323<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_323<1,1024,16,16>\u001b[0m, float32_302<1,1024,16,16>\u001b[0m) -> float32_323<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_323<1,1024,16,16>\u001b[0m) -> float32_323<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_323<1,1024,16,16>\u001b[0m) -> float32_344<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_323<1,1024,16,16>\u001b[0m) -> float32_325<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_323<1,1024,16,16>\u001b[0m, float32_324<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_325<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_325<1,256,16,16>\u001b[0m) -> float32_330<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_325<1,256,16,16>\u001b[0m, float32_326<256>\u001b[0m, float32_327<256>\u001b[0m, float32_328<256>\u001b[0m, float32_329<256>\u001b[0m, False, 0.1, 1e-05) -> float32_330<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_325<1,256,16,16>\u001b[0m, float32_328<256>\u001b[0m, float32_329<256>\u001b[0m, float32_326<256>\u001b[0m, float32_327<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_330<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_330<1,256,16,16>\u001b[0m) -> float32_330<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_330<1,256,16,16>\u001b[0m, inplace=True) -> float32_330<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_330<1,256,16,16>\u001b[0m) -> float32_330<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_330<1,256,16,16>\u001b[0m) -> float32_332<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_330<1,256,16,16>\u001b[0m, float32_331<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_332<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_332<1,256,16,16>\u001b[0m) -> float32_337<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_332<1,256,16,16>\u001b[0m, float32_333<256>\u001b[0m, float32_334<256>\u001b[0m, float32_335<256>\u001b[0m, float32_336<256>\u001b[0m, False, 0.1, 1e-05) -> float32_337<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_332<1,256,16,16>\u001b[0m, float32_335<256>\u001b[0m, float32_336<256>\u001b[0m, float32_333<256>\u001b[0m, float32_334<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_337<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_337<1,256,16,16>\u001b[0m) -> float32_337<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_337<1,256,16,16>\u001b[0m) -> float32_339<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_337<1,256,16,16>\u001b[0m, float32_338<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_339<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_339<1,1024,16,16>\u001b[0m) -> float32_344<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_339<1,1024,16,16>\u001b[0m, float32_340<1024>\u001b[0m, float32_341<1024>\u001b[0m, float32_342<1024>\u001b[0m, float32_343<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_344<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_339<1,1024,16,16>\u001b[0m, float32_342<1024>\u001b[0m, float32_343<1024>\u001b[0m, float32_340<1024>\u001b[0m, float32_341<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_344<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_344<1,1024,16,16>\u001b[0m, float32_323<1,1024,16,16>\u001b[0m) -> float32_344<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_344<1,1024,16,16>\u001b[0m, float32_323<1,1024,16,16>\u001b[0m) -> float32_344<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_344<1,1024,16,16>\u001b[0m) -> float32_344<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_344<1,1024,16,16>\u001b[0m) -> float32_365<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_344<1,1024,16,16>\u001b[0m) -> float32_346<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_344<1,1024,16,16>\u001b[0m, float32_345<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_346<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_346<1,256,16,16>\u001b[0m) -> float32_351<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_346<1,256,16,16>\u001b[0m, float32_347<256>\u001b[0m, float32_348<256>\u001b[0m, float32_349<256>\u001b[0m, float32_350<256>\u001b[0m, False, 0.1, 1e-05) -> float32_351<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_346<1,256,16,16>\u001b[0m, float32_349<256>\u001b[0m, float32_350<256>\u001b[0m, float32_347<256>\u001b[0m, float32_348<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_351<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_351<1,256,16,16>\u001b[0m) -> float32_351<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_351<1,256,16,16>\u001b[0m, inplace=True) -> float32_351<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_351<1,256,16,16>\u001b[0m) -> float32_351<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_351<1,256,16,16>\u001b[0m) -> float32_353<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_351<1,256,16,16>\u001b[0m, float32_352<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_353<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_353<1,256,16,16>\u001b[0m) -> float32_358<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_353<1,256,16,16>\u001b[0m, float32_354<256>\u001b[0m, float32_355<256>\u001b[0m, float32_356<256>\u001b[0m, float32_357<256>\u001b[0m, False, 0.1, 1e-05) -> float32_358<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_353<1,256,16,16>\u001b[0m, float32_356<256>\u001b[0m, float32_357<256>\u001b[0m, float32_354<256>\u001b[0m, float32_355<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_358<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_358<1,256,16,16>\u001b[0m) -> float32_358<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_358<1,256,16,16>\u001b[0m) -> float32_360<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_358<1,256,16,16>\u001b[0m, float32_359<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_360<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_360<1,1024,16,16>\u001b[0m) -> float32_365<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_360<1,1024,16,16>\u001b[0m, float32_361<1024>\u001b[0m, float32_362<1024>\u001b[0m, float32_363<1024>\u001b[0m, float32_364<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_365<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_360<1,1024,16,16>\u001b[0m, float32_363<1024>\u001b[0m, float32_364<1024>\u001b[0m, float32_361<1024>\u001b[0m, float32_362<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_365<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_365<1,1024,16,16>\u001b[0m, float32_344<1,1024,16,16>\u001b[0m) -> float32_365<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_365<1,1024,16,16>\u001b[0m, float32_344<1,1024,16,16>\u001b[0m) -> float32_365<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_365<1,1024,16,16>\u001b[0m) -> float32_365<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_365<1,1024,16,16>\u001b[0m) -> float32_386<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_365<1,1024,16,16>\u001b[0m) -> float32_367<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_365<1,1024,16,16>\u001b[0m, float32_366<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_367<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_367<1,256,16,16>\u001b[0m) -> float32_372<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_367<1,256,16,16>\u001b[0m, float32_368<256>\u001b[0m, float32_369<256>\u001b[0m, float32_370<256>\u001b[0m, float32_371<256>\u001b[0m, False, 0.1, 1e-05) -> float32_372<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_367<1,256,16,16>\u001b[0m, float32_370<256>\u001b[0m, float32_371<256>\u001b[0m, float32_368<256>\u001b[0m, float32_369<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_372<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_372<1,256,16,16>\u001b[0m) -> float32_372<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_372<1,256,16,16>\u001b[0m, inplace=True) -> float32_372<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_372<1,256,16,16>\u001b[0m) -> float32_372<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_372<1,256,16,16>\u001b[0m) -> float32_374<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_372<1,256,16,16>\u001b[0m, float32_373<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_374<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_374<1,256,16,16>\u001b[0m) -> float32_379<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_374<1,256,16,16>\u001b[0m, float32_375<256>\u001b[0m, float32_376<256>\u001b[0m, float32_377<256>\u001b[0m, float32_378<256>\u001b[0m, False, 0.1, 1e-05) -> float32_379<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_374<1,256,16,16>\u001b[0m, float32_377<256>\u001b[0m, float32_378<256>\u001b[0m, float32_375<256>\u001b[0m, float32_376<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_379<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_379<1,256,16,16>\u001b[0m) -> float32_379<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_379<1,256,16,16>\u001b[0m) -> float32_381<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_379<1,256,16,16>\u001b[0m, float32_380<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_381<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_381<1,1024,16,16>\u001b[0m) -> float32_386<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_381<1,1024,16,16>\u001b[0m, float32_382<1024>\u001b[0m, float32_383<1024>\u001b[0m, float32_384<1024>\u001b[0m, float32_385<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_386<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_381<1,1024,16,16>\u001b[0m, float32_384<1024>\u001b[0m, float32_385<1024>\u001b[0m, float32_382<1024>\u001b[0m, float32_383<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_386<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_386<1,1024,16,16>\u001b[0m, float32_365<1,1024,16,16>\u001b[0m) -> float32_386<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_386<1,1024,16,16>\u001b[0m, float32_365<1,1024,16,16>\u001b[0m) -> float32_386<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_386<1,1024,16,16>\u001b[0m) -> float32_386<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_386<1,1024,16,16>\u001b[0m) -> float32_407<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_386<1,1024,16,16>\u001b[0m) -> float32_388<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_386<1,1024,16,16>\u001b[0m, float32_387<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_388<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_388<1,256,16,16>\u001b[0m) -> float32_393<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_388<1,256,16,16>\u001b[0m, float32_389<256>\u001b[0m, float32_390<256>\u001b[0m, float32_391<256>\u001b[0m, float32_392<256>\u001b[0m, False, 0.1, 1e-05) -> float32_393<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_388<1,256,16,16>\u001b[0m, float32_391<256>\u001b[0m, float32_392<256>\u001b[0m, float32_389<256>\u001b[0m, float32_390<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_393<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_393<1,256,16,16>\u001b[0m) -> float32_393<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_393<1,256,16,16>\u001b[0m, inplace=True) -> float32_393<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_393<1,256,16,16>\u001b[0m) -> float32_393<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_393<1,256,16,16>\u001b[0m) -> float32_395<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_393<1,256,16,16>\u001b[0m, float32_394<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_395<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_395<1,256,16,16>\u001b[0m) -> float32_400<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_395<1,256,16,16>\u001b[0m, float32_396<256>\u001b[0m, float32_397<256>\u001b[0m, float32_398<256>\u001b[0m, float32_399<256>\u001b[0m, False, 0.1, 1e-05) -> float32_400<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_395<1,256,16,16>\u001b[0m, float32_398<256>\u001b[0m, float32_399<256>\u001b[0m, float32_396<256>\u001b[0m, float32_397<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_400<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_400<1,256,16,16>\u001b[0m) -> float32_400<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_400<1,256,16,16>\u001b[0m) -> float32_402<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_400<1,256,16,16>\u001b[0m, float32_401<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_402<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_402<1,1024,16,16>\u001b[0m) -> float32_407<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_402<1,1024,16,16>\u001b[0m, float32_403<1024>\u001b[0m, float32_404<1024>\u001b[0m, float32_405<1024>\u001b[0m, float32_406<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_407<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_402<1,1024,16,16>\u001b[0m, float32_405<1024>\u001b[0m, float32_406<1024>\u001b[0m, float32_403<1024>\u001b[0m, float32_404<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_407<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_407<1,1024,16,16>\u001b[0m, float32_386<1,1024,16,16>\u001b[0m) -> float32_407<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_407<1,1024,16,16>\u001b[0m, float32_386<1,1024,16,16>\u001b[0m) -> float32_407<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_407<1,1024,16,16>\u001b[0m) -> float32_407<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_407<1,1024,16,16>\u001b[0m) -> float32_428<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_407<1,1024,16,16>\u001b[0m) -> float32_409<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_407<1,1024,16,16>\u001b[0m, float32_408<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_409<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_409<1,256,16,16>\u001b[0m) -> float32_414<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_409<1,256,16,16>\u001b[0m, float32_410<256>\u001b[0m, float32_411<256>\u001b[0m, float32_412<256>\u001b[0m, float32_413<256>\u001b[0m, False, 0.1, 1e-05) -> float32_414<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_409<1,256,16,16>\u001b[0m, float32_412<256>\u001b[0m, float32_413<256>\u001b[0m, float32_410<256>\u001b[0m, float32_411<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_414<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_414<1,256,16,16>\u001b[0m) -> float32_414<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_414<1,256,16,16>\u001b[0m, inplace=True) -> float32_414<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_414<1,256,16,16>\u001b[0m) -> float32_414<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_414<1,256,16,16>\u001b[0m) -> float32_416<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_414<1,256,16,16>\u001b[0m, float32_415<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_416<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_416<1,256,16,16>\u001b[0m) -> float32_421<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_416<1,256,16,16>\u001b[0m, float32_417<256>\u001b[0m, float32_418<256>\u001b[0m, float32_419<256>\u001b[0m, float32_420<256>\u001b[0m, False, 0.1, 1e-05) -> float32_421<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_416<1,256,16,16>\u001b[0m, float32_419<256>\u001b[0m, float32_420<256>\u001b[0m, float32_417<256>\u001b[0m, float32_418<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_421<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_421<1,256,16,16>\u001b[0m) -> float32_421<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_421<1,256,16,16>\u001b[0m) -> float32_423<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_421<1,256,16,16>\u001b[0m, float32_422<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_423<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_423<1,1024,16,16>\u001b[0m) -> float32_428<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_423<1,1024,16,16>\u001b[0m, float32_424<1024>\u001b[0m, float32_425<1024>\u001b[0m, float32_426<1024>\u001b[0m, float32_427<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_428<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_423<1,1024,16,16>\u001b[0m, float32_426<1024>\u001b[0m, float32_427<1024>\u001b[0m, float32_424<1024>\u001b[0m, float32_425<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_428<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_428<1,1024,16,16>\u001b[0m, float32_407<1,1024,16,16>\u001b[0m) -> float32_428<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_428<1,1024,16,16>\u001b[0m, float32_407<1,1024,16,16>\u001b[0m) -> float32_428<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_428<1,1024,16,16>\u001b[0m) -> float32_428<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_428<1,1024,16,16>\u001b[0m) -> float32_449<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_428<1,1024,16,16>\u001b[0m) -> float32_430<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_428<1,1024,16,16>\u001b[0m, float32_429<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_430<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_430<1,256,16,16>\u001b[0m) -> float32_435<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_430<1,256,16,16>\u001b[0m, float32_431<256>\u001b[0m, float32_432<256>\u001b[0m, float32_433<256>\u001b[0m, float32_434<256>\u001b[0m, False, 0.1, 1e-05) -> float32_435<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_430<1,256,16,16>\u001b[0m, float32_433<256>\u001b[0m, float32_434<256>\u001b[0m, float32_431<256>\u001b[0m, float32_432<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_435<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_435<1,256,16,16>\u001b[0m) -> float32_435<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_435<1,256,16,16>\u001b[0m, inplace=True) -> float32_435<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_435<1,256,16,16>\u001b[0m) -> float32_435<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_435<1,256,16,16>\u001b[0m) -> float32_437<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_435<1,256,16,16>\u001b[0m, float32_436<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_437<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_437<1,256,16,16>\u001b[0m) -> float32_442<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_437<1,256,16,16>\u001b[0m, float32_438<256>\u001b[0m, float32_439<256>\u001b[0m, float32_440<256>\u001b[0m, float32_441<256>\u001b[0m, False, 0.1, 1e-05) -> float32_442<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_437<1,256,16,16>\u001b[0m, float32_440<256>\u001b[0m, float32_441<256>\u001b[0m, float32_438<256>\u001b[0m, float32_439<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_442<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_442<1,256,16,16>\u001b[0m) -> float32_442<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_442<1,256,16,16>\u001b[0m) -> float32_444<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_442<1,256,16,16>\u001b[0m, float32_443<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_444<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_444<1,1024,16,16>\u001b[0m) -> float32_449<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_444<1,1024,16,16>\u001b[0m, float32_445<1024>\u001b[0m, float32_446<1024>\u001b[0m, float32_447<1024>\u001b[0m, float32_448<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_449<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_444<1,1024,16,16>\u001b[0m, float32_447<1024>\u001b[0m, float32_448<1024>\u001b[0m, float32_445<1024>\u001b[0m, float32_446<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_449<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_449<1,1024,16,16>\u001b[0m, float32_428<1,1024,16,16>\u001b[0m) -> float32_449<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_449<1,1024,16,16>\u001b[0m, float32_428<1,1024,16,16>\u001b[0m) -> float32_449<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_449<1,1024,16,16>\u001b[0m) -> float32_449<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_449<1,1024,16,16>\u001b[0m) -> float32_470<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_449<1,1024,16,16>\u001b[0m) -> float32_451<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_449<1,1024,16,16>\u001b[0m, float32_450<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_451<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_451<1,256,16,16>\u001b[0m) -> float32_456<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_451<1,256,16,16>\u001b[0m, float32_452<256>\u001b[0m, float32_453<256>\u001b[0m, float32_454<256>\u001b[0m, float32_455<256>\u001b[0m, False, 0.1, 1e-05) -> float32_456<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_451<1,256,16,16>\u001b[0m, float32_454<256>\u001b[0m, float32_455<256>\u001b[0m, float32_452<256>\u001b[0m, float32_453<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_456<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_456<1,256,16,16>\u001b[0m) -> float32_456<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_456<1,256,16,16>\u001b[0m, inplace=True) -> float32_456<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_456<1,256,16,16>\u001b[0m) -> float32_456<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_456<1,256,16,16>\u001b[0m) -> float32_458<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_456<1,256,16,16>\u001b[0m, float32_457<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_458<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_458<1,256,16,16>\u001b[0m) -> float32_463<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_458<1,256,16,16>\u001b[0m, float32_459<256>\u001b[0m, float32_460<256>\u001b[0m, float32_461<256>\u001b[0m, float32_462<256>\u001b[0m, False, 0.1, 1e-05) -> float32_463<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_458<1,256,16,16>\u001b[0m, float32_461<256>\u001b[0m, float32_462<256>\u001b[0m, float32_459<256>\u001b[0m, float32_460<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_463<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_463<1,256,16,16>\u001b[0m) -> float32_463<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_463<1,256,16,16>\u001b[0m) -> float32_465<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_463<1,256,16,16>\u001b[0m, float32_464<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_465<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_465<1,1024,16,16>\u001b[0m) -> float32_470<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_465<1,1024,16,16>\u001b[0m, float32_466<1024>\u001b[0m, float32_467<1024>\u001b[0m, float32_468<1024>\u001b[0m, float32_469<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_470<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_465<1,1024,16,16>\u001b[0m, float32_468<1024>\u001b[0m, float32_469<1024>\u001b[0m, float32_466<1024>\u001b[0m, float32_467<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_470<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_470<1,1024,16,16>\u001b[0m, float32_449<1,1024,16,16>\u001b[0m) -> float32_470<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_470<1,1024,16,16>\u001b[0m, float32_449<1,1024,16,16>\u001b[0m) -> float32_470<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_470<1,1024,16,16>\u001b[0m) -> float32_470<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_470<1,1024,16,16>\u001b[0m) -> float32_491<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_470<1,1024,16,16>\u001b[0m) -> float32_472<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_470<1,1024,16,16>\u001b[0m, float32_471<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_472<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_472<1,256,16,16>\u001b[0m) -> float32_477<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_472<1,256,16,16>\u001b[0m, float32_473<256>\u001b[0m, float32_474<256>\u001b[0m, float32_475<256>\u001b[0m, float32_476<256>\u001b[0m, False, 0.1, 1e-05) -> float32_477<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_472<1,256,16,16>\u001b[0m, float32_475<256>\u001b[0m, float32_476<256>\u001b[0m, float32_473<256>\u001b[0m, float32_474<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_477<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_477<1,256,16,16>\u001b[0m) -> float32_477<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_477<1,256,16,16>\u001b[0m, inplace=True) -> float32_477<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_477<1,256,16,16>\u001b[0m) -> float32_477<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_477<1,256,16,16>\u001b[0m) -> float32_479<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_477<1,256,16,16>\u001b[0m, float32_478<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_479<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_479<1,256,16,16>\u001b[0m) -> float32_484<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_479<1,256,16,16>\u001b[0m, float32_480<256>\u001b[0m, float32_481<256>\u001b[0m, float32_482<256>\u001b[0m, float32_483<256>\u001b[0m, False, 0.1, 1e-05) -> float32_484<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_479<1,256,16,16>\u001b[0m, float32_482<256>\u001b[0m, float32_483<256>\u001b[0m, float32_480<256>\u001b[0m, float32_481<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_484<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_484<1,256,16,16>\u001b[0m) -> float32_484<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_484<1,256,16,16>\u001b[0m) -> float32_486<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_484<1,256,16,16>\u001b[0m, float32_485<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_486<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_486<1,1024,16,16>\u001b[0m) -> float32_491<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_486<1,1024,16,16>\u001b[0m, float32_487<1024>\u001b[0m, float32_488<1024>\u001b[0m, float32_489<1024>\u001b[0m, float32_490<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_491<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_486<1,1024,16,16>\u001b[0m, float32_489<1024>\u001b[0m, float32_490<1024>\u001b[0m, float32_487<1024>\u001b[0m, float32_488<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_491<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_491<1,1024,16,16>\u001b[0m, float32_470<1,1024,16,16>\u001b[0m) -> float32_491<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_491<1,1024,16,16>\u001b[0m, float32_470<1,1024,16,16>\u001b[0m) -> float32_491<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_491<1,1024,16,16>\u001b[0m) -> float32_491<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_491<1,1024,16,16>\u001b[0m) -> float32_512<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_491<1,1024,16,16>\u001b[0m) -> float32_493<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_491<1,1024,16,16>\u001b[0m, float32_492<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_493<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_493<1,256,16,16>\u001b[0m) -> float32_498<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_493<1,256,16,16>\u001b[0m, float32_494<256>\u001b[0m, float32_495<256>\u001b[0m, float32_496<256>\u001b[0m, float32_497<256>\u001b[0m, False, 0.1, 1e-05) -> float32_498<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_493<1,256,16,16>\u001b[0m, float32_496<256>\u001b[0m, float32_497<256>\u001b[0m, float32_494<256>\u001b[0m, float32_495<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_498<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_498<1,256,16,16>\u001b[0m) -> float32_498<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_498<1,256,16,16>\u001b[0m, inplace=True) -> float32_498<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_498<1,256,16,16>\u001b[0m) -> float32_498<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_498<1,256,16,16>\u001b[0m) -> float32_500<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_498<1,256,16,16>\u001b[0m, float32_499<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_500<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_500<1,256,16,16>\u001b[0m) -> float32_505<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_500<1,256,16,16>\u001b[0m, float32_501<256>\u001b[0m, float32_502<256>\u001b[0m, float32_503<256>\u001b[0m, float32_504<256>\u001b[0m, False, 0.1, 1e-05) -> float32_505<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_500<1,256,16,16>\u001b[0m, float32_503<256>\u001b[0m, float32_504<256>\u001b[0m, float32_501<256>\u001b[0m, float32_502<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_505<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_505<1,256,16,16>\u001b[0m) -> float32_505<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_505<1,256,16,16>\u001b[0m) -> float32_507<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_505<1,256,16,16>\u001b[0m, float32_506<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_507<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_507<1,1024,16,16>\u001b[0m) -> float32_512<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_507<1,1024,16,16>\u001b[0m, float32_508<1024>\u001b[0m, float32_509<1024>\u001b[0m, float32_510<1024>\u001b[0m, float32_511<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_512<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_507<1,1024,16,16>\u001b[0m, float32_510<1024>\u001b[0m, float32_511<1024>\u001b[0m, float32_508<1024>\u001b[0m, float32_509<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_512<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_512<1,1024,16,16>\u001b[0m, float32_491<1,1024,16,16>\u001b[0m) -> float32_512<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_512<1,1024,16,16>\u001b[0m, float32_491<1,1024,16,16>\u001b[0m) -> float32_512<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_512<1,1024,16,16>\u001b[0m) -> float32_512<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_512<1,1024,16,16>\u001b[0m) -> float32_533<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_512<1,1024,16,16>\u001b[0m) -> float32_514<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_512<1,1024,16,16>\u001b[0m, float32_513<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_514<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_514<1,256,16,16>\u001b[0m) -> float32_519<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_514<1,256,16,16>\u001b[0m, float32_515<256>\u001b[0m, float32_516<256>\u001b[0m, float32_517<256>\u001b[0m, float32_518<256>\u001b[0m, False, 0.1, 1e-05) -> float32_519<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_514<1,256,16,16>\u001b[0m, float32_517<256>\u001b[0m, float32_518<256>\u001b[0m, float32_515<256>\u001b[0m, float32_516<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_519<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_519<1,256,16,16>\u001b[0m) -> float32_519<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_519<1,256,16,16>\u001b[0m, inplace=True) -> float32_519<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_519<1,256,16,16>\u001b[0m) -> float32_519<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_519<1,256,16,16>\u001b[0m) -> float32_521<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_519<1,256,16,16>\u001b[0m, float32_520<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_521<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_521<1,256,16,16>\u001b[0m) -> float32_526<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_521<1,256,16,16>\u001b[0m, float32_522<256>\u001b[0m, float32_523<256>\u001b[0m, float32_524<256>\u001b[0m, float32_525<256>\u001b[0m, False, 0.1, 1e-05) -> float32_526<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_521<1,256,16,16>\u001b[0m, float32_524<256>\u001b[0m, float32_525<256>\u001b[0m, float32_522<256>\u001b[0m, float32_523<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_526<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_526<1,256,16,16>\u001b[0m) -> float32_526<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_526<1,256,16,16>\u001b[0m) -> float32_528<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_526<1,256,16,16>\u001b[0m, float32_527<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_528<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_528<1,1024,16,16>\u001b[0m) -> float32_533<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_528<1,1024,16,16>\u001b[0m, float32_529<1024>\u001b[0m, float32_530<1024>\u001b[0m, float32_531<1024>\u001b[0m, float32_532<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_533<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_528<1,1024,16,16>\u001b[0m, float32_531<1024>\u001b[0m, float32_532<1024>\u001b[0m, float32_529<1024>\u001b[0m, float32_530<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_533<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_533<1,1024,16,16>\u001b[0m, float32_512<1,1024,16,16>\u001b[0m) -> float32_533<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_533<1,1024,16,16>\u001b[0m, float32_512<1,1024,16,16>\u001b[0m) -> float32_533<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_533<1,1024,16,16>\u001b[0m) -> float32_533<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_533<1,1024,16,16>\u001b[0m) -> float32_554<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_533<1,1024,16,16>\u001b[0m) -> float32_535<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_533<1,1024,16,16>\u001b[0m, float32_534<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_535<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_535<1,256,16,16>\u001b[0m) -> float32_540<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_535<1,256,16,16>\u001b[0m, float32_536<256>\u001b[0m, float32_537<256>\u001b[0m, float32_538<256>\u001b[0m, float32_539<256>\u001b[0m, False, 0.1, 1e-05) -> float32_540<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_535<1,256,16,16>\u001b[0m, float32_538<256>\u001b[0m, float32_539<256>\u001b[0m, float32_536<256>\u001b[0m, float32_537<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_540<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_540<1,256,16,16>\u001b[0m) -> float32_540<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_540<1,256,16,16>\u001b[0m, inplace=True) -> float32_540<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_540<1,256,16,16>\u001b[0m) -> float32_540<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_540<1,256,16,16>\u001b[0m) -> float32_542<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_540<1,256,16,16>\u001b[0m, float32_541<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_542<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_542<1,256,16,16>\u001b[0m) -> float32_547<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_542<1,256,16,16>\u001b[0m, float32_543<256>\u001b[0m, float32_544<256>\u001b[0m, float32_545<256>\u001b[0m, float32_546<256>\u001b[0m, False, 0.1, 1e-05) -> float32_547<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_542<1,256,16,16>\u001b[0m, float32_545<256>\u001b[0m, float32_546<256>\u001b[0m, float32_543<256>\u001b[0m, float32_544<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_547<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_547<1,256,16,16>\u001b[0m) -> float32_547<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_547<1,256,16,16>\u001b[0m) -> float32_549<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_547<1,256,16,16>\u001b[0m, float32_548<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_549<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_549<1,1024,16,16>\u001b[0m) -> float32_554<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_549<1,1024,16,16>\u001b[0m, float32_550<1024>\u001b[0m, float32_551<1024>\u001b[0m, float32_552<1024>\u001b[0m, float32_553<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_554<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_549<1,1024,16,16>\u001b[0m, float32_552<1024>\u001b[0m, float32_553<1024>\u001b[0m, float32_550<1024>\u001b[0m, float32_551<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_554<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_554<1,1024,16,16>\u001b[0m, float32_533<1,1024,16,16>\u001b[0m) -> float32_554<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_554<1,1024,16,16>\u001b[0m, float32_533<1,1024,16,16>\u001b[0m) -> float32_554<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_554<1,1024,16,16>\u001b[0m) -> float32_554<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_554<1,1024,16,16>\u001b[0m) -> float32_575<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_554<1,1024,16,16>\u001b[0m) -> float32_556<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_554<1,1024,16,16>\u001b[0m, float32_555<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_556<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_556<1,256,16,16>\u001b[0m) -> float32_561<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_556<1,256,16,16>\u001b[0m, float32_557<256>\u001b[0m, float32_558<256>\u001b[0m, float32_559<256>\u001b[0m, float32_560<256>\u001b[0m, False, 0.1, 1e-05) -> float32_561<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_556<1,256,16,16>\u001b[0m, float32_559<256>\u001b[0m, float32_560<256>\u001b[0m, float32_557<256>\u001b[0m, float32_558<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_561<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_561<1,256,16,16>\u001b[0m) -> float32_561<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_561<1,256,16,16>\u001b[0m, inplace=True) -> float32_561<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_561<1,256,16,16>\u001b[0m) -> float32_561<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_561<1,256,16,16>\u001b[0m) -> float32_563<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_561<1,256,16,16>\u001b[0m, float32_562<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_563<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_563<1,256,16,16>\u001b[0m) -> float32_568<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_563<1,256,16,16>\u001b[0m, float32_564<256>\u001b[0m, float32_565<256>\u001b[0m, float32_566<256>\u001b[0m, float32_567<256>\u001b[0m, False, 0.1, 1e-05) -> float32_568<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_563<1,256,16,16>\u001b[0m, float32_566<256>\u001b[0m, float32_567<256>\u001b[0m, float32_564<256>\u001b[0m, float32_565<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_568<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_568<1,256,16,16>\u001b[0m) -> float32_568<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_568<1,256,16,16>\u001b[0m) -> float32_570<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_568<1,256,16,16>\u001b[0m, float32_569<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_570<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_570<1,1024,16,16>\u001b[0m) -> float32_575<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_570<1,1024,16,16>\u001b[0m, float32_571<1024>\u001b[0m, float32_572<1024>\u001b[0m, float32_573<1024>\u001b[0m, float32_574<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_575<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_570<1,1024,16,16>\u001b[0m, float32_573<1024>\u001b[0m, float32_574<1024>\u001b[0m, float32_571<1024>\u001b[0m, float32_572<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_575<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_575<1,1024,16,16>\u001b[0m, float32_554<1,1024,16,16>\u001b[0m) -> float32_575<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_575<1,1024,16,16>\u001b[0m, float32_554<1,1024,16,16>\u001b[0m) -> float32_575<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_575<1,1024,16,16>\u001b[0m) -> float32_575<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_575<1,1024,16,16>\u001b[0m) -> float32_596<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_575<1,1024,16,16>\u001b[0m) -> float32_577<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_575<1,1024,16,16>\u001b[0m, float32_576<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_577<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_577<1,256,16,16>\u001b[0m) -> float32_582<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_577<1,256,16,16>\u001b[0m, float32_578<256>\u001b[0m, float32_579<256>\u001b[0m, float32_580<256>\u001b[0m, float32_581<256>\u001b[0m, False, 0.1, 1e-05) -> float32_582<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_577<1,256,16,16>\u001b[0m, float32_580<256>\u001b[0m, float32_581<256>\u001b[0m, float32_578<256>\u001b[0m, float32_579<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_582<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_582<1,256,16,16>\u001b[0m) -> float32_582<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_582<1,256,16,16>\u001b[0m, inplace=True) -> float32_582<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_582<1,256,16,16>\u001b[0m) -> float32_582<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_582<1,256,16,16>\u001b[0m) -> float32_584<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_582<1,256,16,16>\u001b[0m, float32_583<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_584<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_584<1,256,16,16>\u001b[0m) -> float32_589<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_584<1,256,16,16>\u001b[0m, float32_585<256>\u001b[0m, float32_586<256>\u001b[0m, float32_587<256>\u001b[0m, float32_588<256>\u001b[0m, False, 0.1, 1e-05) -> float32_589<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_584<1,256,16,16>\u001b[0m, float32_587<256>\u001b[0m, float32_588<256>\u001b[0m, float32_585<256>\u001b[0m, float32_586<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_589<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_589<1,256,16,16>\u001b[0m) -> float32_589<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_589<1,256,16,16>\u001b[0m) -> float32_591<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_589<1,256,16,16>\u001b[0m, float32_590<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_591<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_591<1,1024,16,16>\u001b[0m) -> float32_596<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_591<1,1024,16,16>\u001b[0m, float32_592<1024>\u001b[0m, float32_593<1024>\u001b[0m, float32_594<1024>\u001b[0m, float32_595<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_596<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_591<1,1024,16,16>\u001b[0m, float32_594<1024>\u001b[0m, float32_595<1024>\u001b[0m, float32_592<1024>\u001b[0m, float32_593<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_596<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_596<1,1024,16,16>\u001b[0m, float32_575<1,1024,16,16>\u001b[0m) -> float32_596<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_596<1,1024,16,16>\u001b[0m, float32_575<1,1024,16,16>\u001b[0m) -> float32_596<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_596<1,1024,16,16>\u001b[0m) -> float32_596<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_596<1,1024,16,16>\u001b[0m) -> float32_617<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_596<1,1024,16,16>\u001b[0m) -> float32_598<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_596<1,1024,16,16>\u001b[0m, float32_597<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_598<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_598<1,256,16,16>\u001b[0m) -> float32_603<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_598<1,256,16,16>\u001b[0m, float32_599<256>\u001b[0m, float32_600<256>\u001b[0m, float32_601<256>\u001b[0m, float32_602<256>\u001b[0m, False, 0.1, 1e-05) -> float32_603<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_598<1,256,16,16>\u001b[0m, float32_601<256>\u001b[0m, float32_602<256>\u001b[0m, float32_599<256>\u001b[0m, float32_600<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_603<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_603<1,256,16,16>\u001b[0m) -> float32_603<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_603<1,256,16,16>\u001b[0m, inplace=True) -> float32_603<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_603<1,256,16,16>\u001b[0m) -> float32_603<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_603<1,256,16,16>\u001b[0m) -> float32_605<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_603<1,256,16,16>\u001b[0m, float32_604<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_605<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_605<1,256,16,16>\u001b[0m) -> float32_610<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_605<1,256,16,16>\u001b[0m, float32_606<256>\u001b[0m, float32_607<256>\u001b[0m, float32_608<256>\u001b[0m, float32_609<256>\u001b[0m, False, 0.1, 1e-05) -> float32_610<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_605<1,256,16,16>\u001b[0m, float32_608<256>\u001b[0m, float32_609<256>\u001b[0m, float32_606<256>\u001b[0m, float32_607<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_610<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_610<1,256,16,16>\u001b[0m) -> float32_610<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_610<1,256,16,16>\u001b[0m) -> float32_612<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_610<1,256,16,16>\u001b[0m, float32_611<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_612<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_612<1,1024,16,16>\u001b[0m) -> float32_617<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_612<1,1024,16,16>\u001b[0m, float32_613<1024>\u001b[0m, float32_614<1024>\u001b[0m, float32_615<1024>\u001b[0m, float32_616<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_617<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_612<1,1024,16,16>\u001b[0m, float32_615<1024>\u001b[0m, float32_616<1024>\u001b[0m, float32_613<1024>\u001b[0m, float32_614<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_617<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_617<1,1024,16,16>\u001b[0m, float32_596<1,1024,16,16>\u001b[0m) -> float32_617<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_617<1,1024,16,16>\u001b[0m, float32_596<1,1024,16,16>\u001b[0m) -> float32_617<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_617<1,1024,16,16>\u001b[0m) -> float32_617<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_617<1,1024,16,16>\u001b[0m) -> float32_638<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_617<1,1024,16,16>\u001b[0m) -> float32_619<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_617<1,1024,16,16>\u001b[0m, float32_618<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_619<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_619<1,256,16,16>\u001b[0m) -> float32_624<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_619<1,256,16,16>\u001b[0m, float32_620<256>\u001b[0m, float32_621<256>\u001b[0m, float32_622<256>\u001b[0m, float32_623<256>\u001b[0m, False, 0.1, 1e-05) -> float32_624<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_619<1,256,16,16>\u001b[0m, float32_622<256>\u001b[0m, float32_623<256>\u001b[0m, float32_620<256>\u001b[0m, float32_621<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_624<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_624<1,256,16,16>\u001b[0m) -> float32_624<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_624<1,256,16,16>\u001b[0m, inplace=True) -> float32_624<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_624<1,256,16,16>\u001b[0m) -> float32_624<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_624<1,256,16,16>\u001b[0m) -> float32_626<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_624<1,256,16,16>\u001b[0m, float32_625<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_626<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_626<1,256,16,16>\u001b[0m) -> float32_631<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_626<1,256,16,16>\u001b[0m, float32_627<256>\u001b[0m, float32_628<256>\u001b[0m, float32_629<256>\u001b[0m, float32_630<256>\u001b[0m, False, 0.1, 1e-05) -> float32_631<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_626<1,256,16,16>\u001b[0m, float32_629<256>\u001b[0m, float32_630<256>\u001b[0m, float32_627<256>\u001b[0m, float32_628<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_631<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_631<1,256,16,16>\u001b[0m) -> float32_631<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_631<1,256,16,16>\u001b[0m) -> float32_633<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_631<1,256,16,16>\u001b[0m, float32_632<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_633<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_633<1,1024,16,16>\u001b[0m) -> float32_638<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_633<1,1024,16,16>\u001b[0m, float32_634<1024>\u001b[0m, float32_635<1024>\u001b[0m, float32_636<1024>\u001b[0m, float32_637<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_638<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_633<1,1024,16,16>\u001b[0m, float32_636<1024>\u001b[0m, float32_637<1024>\u001b[0m, float32_634<1024>\u001b[0m, float32_635<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_638<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_638<1,1024,16,16>\u001b[0m, float32_617<1,1024,16,16>\u001b[0m) -> float32_638<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_638<1,1024,16,16>\u001b[0m, float32_617<1,1024,16,16>\u001b[0m) -> float32_638<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_638<1,1024,16,16>\u001b[0m) -> float32_638<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_638<1,1024,16,16>\u001b[0m) -> float32_659<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_638<1,1024,16,16>\u001b[0m) -> float32_640<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_638<1,1024,16,16>\u001b[0m, float32_639<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_640<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_640<1,256,16,16>\u001b[0m) -> float32_645<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_640<1,256,16,16>\u001b[0m, float32_641<256>\u001b[0m, float32_642<256>\u001b[0m, float32_643<256>\u001b[0m, float32_644<256>\u001b[0m, False, 0.1, 1e-05) -> float32_645<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_640<1,256,16,16>\u001b[0m, float32_643<256>\u001b[0m, float32_644<256>\u001b[0m, float32_641<256>\u001b[0m, float32_642<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_645<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_645<1,256,16,16>\u001b[0m) -> float32_645<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_645<1,256,16,16>\u001b[0m, inplace=True) -> float32_645<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_645<1,256,16,16>\u001b[0m) -> float32_645<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_645<1,256,16,16>\u001b[0m) -> float32_647<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_645<1,256,16,16>\u001b[0m, float32_646<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_647<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_647<1,256,16,16>\u001b[0m) -> float32_652<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_647<1,256,16,16>\u001b[0m, float32_648<256>\u001b[0m, float32_649<256>\u001b[0m, float32_650<256>\u001b[0m, float32_651<256>\u001b[0m, False, 0.1, 1e-05) -> float32_652<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_647<1,256,16,16>\u001b[0m, float32_650<256>\u001b[0m, float32_651<256>\u001b[0m, float32_648<256>\u001b[0m, float32_649<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_652<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_652<1,256,16,16>\u001b[0m) -> float32_652<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_652<1,256,16,16>\u001b[0m) -> float32_654<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_652<1,256,16,16>\u001b[0m, float32_653<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_654<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_654<1,1024,16,16>\u001b[0m) -> float32_659<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_654<1,1024,16,16>\u001b[0m, float32_655<1024>\u001b[0m, float32_656<1024>\u001b[0m, float32_657<1024>\u001b[0m, float32_658<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_659<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_654<1,1024,16,16>\u001b[0m, float32_657<1024>\u001b[0m, float32_658<1024>\u001b[0m, float32_655<1024>\u001b[0m, float32_656<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_659<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_659<1,1024,16,16>\u001b[0m, float32_638<1,1024,16,16>\u001b[0m) -> float32_659<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_659<1,1024,16,16>\u001b[0m, float32_638<1,1024,16,16>\u001b[0m) -> float32_659<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_659<1,1024,16,16>\u001b[0m) -> float32_659<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_659<1,1024,16,16>\u001b[0m) -> float32_680<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_659<1,1024,16,16>\u001b[0m) -> float32_661<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_659<1,1024,16,16>\u001b[0m, float32_660<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_661<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_661<1,256,16,16>\u001b[0m) -> float32_666<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_661<1,256,16,16>\u001b[0m, float32_662<256>\u001b[0m, float32_663<256>\u001b[0m, float32_664<256>\u001b[0m, float32_665<256>\u001b[0m, False, 0.1, 1e-05) -> float32_666<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_661<1,256,16,16>\u001b[0m, float32_664<256>\u001b[0m, float32_665<256>\u001b[0m, float32_662<256>\u001b[0m, float32_663<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_666<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_666<1,256,16,16>\u001b[0m) -> float32_666<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_666<1,256,16,16>\u001b[0m, inplace=True) -> float32_666<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_666<1,256,16,16>\u001b[0m) -> float32_666<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_666<1,256,16,16>\u001b[0m) -> float32_668<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_666<1,256,16,16>\u001b[0m, float32_667<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_668<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_668<1,256,16,16>\u001b[0m) -> float32_673<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_668<1,256,16,16>\u001b[0m, float32_669<256>\u001b[0m, float32_670<256>\u001b[0m, float32_671<256>\u001b[0m, float32_672<256>\u001b[0m, False, 0.1, 1e-05) -> float32_673<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_668<1,256,16,16>\u001b[0m, float32_671<256>\u001b[0m, float32_672<256>\u001b[0m, float32_669<256>\u001b[0m, float32_670<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_673<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_673<1,256,16,16>\u001b[0m) -> float32_673<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_673<1,256,16,16>\u001b[0m) -> float32_675<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_673<1,256,16,16>\u001b[0m, float32_674<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_675<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_675<1,1024,16,16>\u001b[0m) -> float32_680<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_675<1,1024,16,16>\u001b[0m, float32_676<1024>\u001b[0m, float32_677<1024>\u001b[0m, float32_678<1024>\u001b[0m, float32_679<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_680<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_675<1,1024,16,16>\u001b[0m, float32_678<1024>\u001b[0m, float32_679<1024>\u001b[0m, float32_676<1024>\u001b[0m, float32_677<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_680<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_680<1,1024,16,16>\u001b[0m, float32_659<1,1024,16,16>\u001b[0m) -> float32_680<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_680<1,1024,16,16>\u001b[0m, float32_659<1,1024,16,16>\u001b[0m) -> float32_680<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_680<1,1024,16,16>\u001b[0m) -> float32_680<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_680<1,1024,16,16>\u001b[0m) -> float32_701<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_680<1,1024,16,16>\u001b[0m) -> float32_682<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_680<1,1024,16,16>\u001b[0m, float32_681<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_682<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_682<1,256,16,16>\u001b[0m) -> float32_687<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_682<1,256,16,16>\u001b[0m, float32_683<256>\u001b[0m, float32_684<256>\u001b[0m, float32_685<256>\u001b[0m, float32_686<256>\u001b[0m, False, 0.1, 1e-05) -> float32_687<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_682<1,256,16,16>\u001b[0m, float32_685<256>\u001b[0m, float32_686<256>\u001b[0m, float32_683<256>\u001b[0m, float32_684<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_687<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_687<1,256,16,16>\u001b[0m) -> float32_687<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_687<1,256,16,16>\u001b[0m, inplace=True) -> float32_687<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_687<1,256,16,16>\u001b[0m) -> float32_687<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_687<1,256,16,16>\u001b[0m) -> float32_689<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_687<1,256,16,16>\u001b[0m, float32_688<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_689<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_689<1,256,16,16>\u001b[0m) -> float32_694<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_689<1,256,16,16>\u001b[0m, float32_690<256>\u001b[0m, float32_691<256>\u001b[0m, float32_692<256>\u001b[0m, float32_693<256>\u001b[0m, False, 0.1, 1e-05) -> float32_694<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_689<1,256,16,16>\u001b[0m, float32_692<256>\u001b[0m, float32_693<256>\u001b[0m, float32_690<256>\u001b[0m, float32_691<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_694<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_694<1,256,16,16>\u001b[0m) -> float32_694<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_694<1,256,16,16>\u001b[0m) -> float32_696<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_694<1,256,16,16>\u001b[0m, float32_695<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_696<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_696<1,1024,16,16>\u001b[0m) -> float32_701<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_696<1,1024,16,16>\u001b[0m, float32_697<1024>\u001b[0m, float32_698<1024>\u001b[0m, float32_699<1024>\u001b[0m, float32_700<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_701<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_696<1,1024,16,16>\u001b[0m, float32_699<1024>\u001b[0m, float32_700<1024>\u001b[0m, float32_697<1024>\u001b[0m, float32_698<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_701<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_701<1,1024,16,16>\u001b[0m, float32_680<1,1024,16,16>\u001b[0m) -> float32_701<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_701<1,1024,16,16>\u001b[0m, float32_680<1,1024,16,16>\u001b[0m) -> float32_701<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_701<1,1024,16,16>\u001b[0m) -> float32_701<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_701<1,1024,16,16>\u001b[0m) -> float32_722<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_701<1,1024,16,16>\u001b[0m) -> float32_703<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_701<1,1024,16,16>\u001b[0m, float32_702<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_703<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_703<1,256,16,16>\u001b[0m) -> float32_708<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_703<1,256,16,16>\u001b[0m, float32_704<256>\u001b[0m, float32_705<256>\u001b[0m, float32_706<256>\u001b[0m, float32_707<256>\u001b[0m, False, 0.1, 1e-05) -> float32_708<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_703<1,256,16,16>\u001b[0m, float32_706<256>\u001b[0m, float32_707<256>\u001b[0m, float32_704<256>\u001b[0m, float32_705<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_708<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_708<1,256,16,16>\u001b[0m) -> float32_708<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_708<1,256,16,16>\u001b[0m, inplace=True) -> float32_708<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_708<1,256,16,16>\u001b[0m) -> float32_708<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_708<1,256,16,16>\u001b[0m) -> float32_710<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_708<1,256,16,16>\u001b[0m, float32_709<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_710<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_710<1,256,16,16>\u001b[0m) -> float32_715<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_710<1,256,16,16>\u001b[0m, float32_711<256>\u001b[0m, float32_712<256>\u001b[0m, float32_713<256>\u001b[0m, float32_714<256>\u001b[0m, False, 0.1, 1e-05) -> float32_715<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_710<1,256,16,16>\u001b[0m, float32_713<256>\u001b[0m, float32_714<256>\u001b[0m, float32_711<256>\u001b[0m, float32_712<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_715<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_715<1,256,16,16>\u001b[0m) -> float32_715<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_715<1,256,16,16>\u001b[0m) -> float32_717<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_715<1,256,16,16>\u001b[0m, float32_716<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_717<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_717<1,1024,16,16>\u001b[0m) -> float32_722<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_717<1,1024,16,16>\u001b[0m, float32_718<1024>\u001b[0m, float32_719<1024>\u001b[0m, float32_720<1024>\u001b[0m, float32_721<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_722<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_717<1,1024,16,16>\u001b[0m, float32_720<1024>\u001b[0m, float32_721<1024>\u001b[0m, float32_718<1024>\u001b[0m, float32_719<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_722<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_722<1,1024,16,16>\u001b[0m, float32_701<1,1024,16,16>\u001b[0m) -> float32_722<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_722<1,1024,16,16>\u001b[0m, float32_701<1,1024,16,16>\u001b[0m) -> float32_722<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_722<1,1024,16,16>\u001b[0m) -> float32_722<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_722<1,1024,16,16>\u001b[0m) -> float32_743<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_722<1,1024,16,16>\u001b[0m) -> float32_724<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_722<1,1024,16,16>\u001b[0m, float32_723<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_724<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_724<1,256,16,16>\u001b[0m) -> float32_729<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_724<1,256,16,16>\u001b[0m, float32_725<256>\u001b[0m, float32_726<256>\u001b[0m, float32_727<256>\u001b[0m, float32_728<256>\u001b[0m, False, 0.1, 1e-05) -> float32_729<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_724<1,256,16,16>\u001b[0m, float32_727<256>\u001b[0m, float32_728<256>\u001b[0m, float32_725<256>\u001b[0m, float32_726<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_729<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_729<1,256,16,16>\u001b[0m) -> float32_729<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_729<1,256,16,16>\u001b[0m, inplace=True) -> float32_729<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_729<1,256,16,16>\u001b[0m) -> float32_729<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_729<1,256,16,16>\u001b[0m) -> float32_731<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_729<1,256,16,16>\u001b[0m, float32_730<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_731<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_731<1,256,16,16>\u001b[0m) -> float32_736<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_731<1,256,16,16>\u001b[0m, float32_732<256>\u001b[0m, float32_733<256>\u001b[0m, float32_734<256>\u001b[0m, float32_735<256>\u001b[0m, False, 0.1, 1e-05) -> float32_736<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_731<1,256,16,16>\u001b[0m, float32_734<256>\u001b[0m, float32_735<256>\u001b[0m, float32_732<256>\u001b[0m, float32_733<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_736<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_736<1,256,16,16>\u001b[0m) -> float32_736<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_736<1,256,16,16>\u001b[0m) -> float32_738<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_736<1,256,16,16>\u001b[0m, float32_737<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_738<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_738<1,1024,16,16>\u001b[0m) -> float32_743<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_738<1,1024,16,16>\u001b[0m, float32_739<1024>\u001b[0m, float32_740<1024>\u001b[0m, float32_741<1024>\u001b[0m, float32_742<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_743<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_738<1,1024,16,16>\u001b[0m, float32_741<1024>\u001b[0m, float32_742<1024>\u001b[0m, float32_739<1024>\u001b[0m, float32_740<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_743<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_743<1,1024,16,16>\u001b[0m, float32_722<1,1024,16,16>\u001b[0m) -> float32_743<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_743<1,1024,16,16>\u001b[0m, float32_722<1,1024,16,16>\u001b[0m) -> float32_743<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_743<1,1024,16,16>\u001b[0m) -> float32_743<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_743<1,1024,16,16>\u001b[0m) -> float32_764<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_743<1,1024,16,16>\u001b[0m) -> float32_745<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_743<1,1024,16,16>\u001b[0m, float32_744<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_745<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_745<1,256,16,16>\u001b[0m) -> float32_750<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_745<1,256,16,16>\u001b[0m, float32_746<256>\u001b[0m, float32_747<256>\u001b[0m, float32_748<256>\u001b[0m, float32_749<256>\u001b[0m, False, 0.1, 1e-05) -> float32_750<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_745<1,256,16,16>\u001b[0m, float32_748<256>\u001b[0m, float32_749<256>\u001b[0m, float32_746<256>\u001b[0m, float32_747<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_750<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_750<1,256,16,16>\u001b[0m) -> float32_750<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_750<1,256,16,16>\u001b[0m, inplace=True) -> float32_750<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_750<1,256,16,16>\u001b[0m) -> float32_750<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_750<1,256,16,16>\u001b[0m) -> float32_752<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_750<1,256,16,16>\u001b[0m, float32_751<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_752<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_752<1,256,16,16>\u001b[0m) -> float32_757<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_752<1,256,16,16>\u001b[0m, float32_753<256>\u001b[0m, float32_754<256>\u001b[0m, float32_755<256>\u001b[0m, float32_756<256>\u001b[0m, False, 0.1, 1e-05) -> float32_757<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_752<1,256,16,16>\u001b[0m, float32_755<256>\u001b[0m, float32_756<256>\u001b[0m, float32_753<256>\u001b[0m, float32_754<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_757<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_757<1,256,16,16>\u001b[0m) -> float32_757<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_757<1,256,16,16>\u001b[0m) -> float32_759<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_757<1,256,16,16>\u001b[0m, float32_758<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_759<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_759<1,1024,16,16>\u001b[0m) -> float32_764<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_759<1,1024,16,16>\u001b[0m, float32_760<1024>\u001b[0m, float32_761<1024>\u001b[0m, float32_762<1024>\u001b[0m, float32_763<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_764<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_759<1,1024,16,16>\u001b[0m, float32_762<1024>\u001b[0m, float32_763<1024>\u001b[0m, float32_760<1024>\u001b[0m, float32_761<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_764<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_764<1,1024,16,16>\u001b[0m, float32_743<1,1024,16,16>\u001b[0m) -> float32_764<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_764<1,1024,16,16>\u001b[0m, float32_743<1,1024,16,16>\u001b[0m) -> float32_764<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_764<1,1024,16,16>\u001b[0m) -> float32_764<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_764<1,1024,16,16>\u001b[0m) -> float32_785<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_764<1,1024,16,16>\u001b[0m) -> float32_766<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_764<1,1024,16,16>\u001b[0m, float32_765<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_766<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_766<1,256,16,16>\u001b[0m) -> float32_771<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_766<1,256,16,16>\u001b[0m, float32_767<256>\u001b[0m, float32_768<256>\u001b[0m, float32_769<256>\u001b[0m, float32_770<256>\u001b[0m, False, 0.1, 1e-05) -> float32_771<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_766<1,256,16,16>\u001b[0m, float32_769<256>\u001b[0m, float32_770<256>\u001b[0m, float32_767<256>\u001b[0m, float32_768<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_771<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_771<1,256,16,16>\u001b[0m) -> float32_771<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_771<1,256,16,16>\u001b[0m, inplace=True) -> float32_771<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_771<1,256,16,16>\u001b[0m) -> float32_771<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_771<1,256,16,16>\u001b[0m) -> float32_773<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_771<1,256,16,16>\u001b[0m, float32_772<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_773<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_773<1,256,16,16>\u001b[0m) -> float32_778<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_773<1,256,16,16>\u001b[0m, float32_774<256>\u001b[0m, float32_775<256>\u001b[0m, float32_776<256>\u001b[0m, float32_777<256>\u001b[0m, False, 0.1, 1e-05) -> float32_778<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_773<1,256,16,16>\u001b[0m, float32_776<256>\u001b[0m, float32_777<256>\u001b[0m, float32_774<256>\u001b[0m, float32_775<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_778<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_778<1,256,16,16>\u001b[0m) -> float32_778<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_778<1,256,16,16>\u001b[0m) -> float32_780<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_778<1,256,16,16>\u001b[0m, float32_779<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_780<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_780<1,1024,16,16>\u001b[0m) -> float32_785<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_780<1,1024,16,16>\u001b[0m, float32_781<1024>\u001b[0m, float32_782<1024>\u001b[0m, float32_783<1024>\u001b[0m, float32_784<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_785<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_780<1,1024,16,16>\u001b[0m, float32_783<1024>\u001b[0m, float32_784<1024>\u001b[0m, float32_781<1024>\u001b[0m, float32_782<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_785<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_785<1,1024,16,16>\u001b[0m, float32_764<1,1024,16,16>\u001b[0m) -> float32_785<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_785<1,1024,16,16>\u001b[0m, float32_764<1,1024,16,16>\u001b[0m) -> float32_785<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_785<1,1024,16,16>\u001b[0m) -> float32_785<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_785<1,1024,16,16>\u001b[0m) -> float32_806<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_785<1,1024,16,16>\u001b[0m) -> float32_787<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_785<1,1024,16,16>\u001b[0m, float32_786<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_787<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_787<1,256,16,16>\u001b[0m) -> float32_792<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_787<1,256,16,16>\u001b[0m, float32_788<256>\u001b[0m, float32_789<256>\u001b[0m, float32_790<256>\u001b[0m, float32_791<256>\u001b[0m, False, 0.1, 1e-05) -> float32_792<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_787<1,256,16,16>\u001b[0m, float32_790<256>\u001b[0m, float32_791<256>\u001b[0m, float32_788<256>\u001b[0m, float32_789<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_792<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_792<1,256,16,16>\u001b[0m) -> float32_792<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_792<1,256,16,16>\u001b[0m, inplace=True) -> float32_792<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_792<1,256,16,16>\u001b[0m) -> float32_792<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_792<1,256,16,16>\u001b[0m) -> float32_794<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_792<1,256,16,16>\u001b[0m, float32_793<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_794<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_794<1,256,16,16>\u001b[0m) -> float32_799<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_794<1,256,16,16>\u001b[0m, float32_795<256>\u001b[0m, float32_796<256>\u001b[0m, float32_797<256>\u001b[0m, float32_798<256>\u001b[0m, False, 0.1, 1e-05) -> float32_799<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_794<1,256,16,16>\u001b[0m, float32_797<256>\u001b[0m, float32_798<256>\u001b[0m, float32_795<256>\u001b[0m, float32_796<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_799<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_799<1,256,16,16>\u001b[0m) -> float32_799<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_799<1,256,16,16>\u001b[0m) -> float32_801<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_799<1,256,16,16>\u001b[0m, float32_800<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_801<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_801<1,1024,16,16>\u001b[0m) -> float32_806<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_801<1,1024,16,16>\u001b[0m, float32_802<1024>\u001b[0m, float32_803<1024>\u001b[0m, float32_804<1024>\u001b[0m, float32_805<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_806<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_801<1,1024,16,16>\u001b[0m, float32_804<1024>\u001b[0m, float32_805<1024>\u001b[0m, float32_802<1024>\u001b[0m, float32_803<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_806<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_806<1,1024,16,16>\u001b[0m, float32_785<1,1024,16,16>\u001b[0m) -> float32_806<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_806<1,1024,16,16>\u001b[0m, float32_785<1,1024,16,16>\u001b[0m) -> float32_806<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_806<1,1024,16,16>\u001b[0m) -> float32_806<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_806<1,1024,16,16>\u001b[0m) -> float32_827<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_806<1,1024,16,16>\u001b[0m) -> float32_808<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_806<1,1024,16,16>\u001b[0m, float32_807<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_808<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_808<1,256,16,16>\u001b[0m) -> float32_813<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_808<1,256,16,16>\u001b[0m, float32_809<256>\u001b[0m, float32_810<256>\u001b[0m, float32_811<256>\u001b[0m, float32_812<256>\u001b[0m, False, 0.1, 1e-05) -> float32_813<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_808<1,256,16,16>\u001b[0m, float32_811<256>\u001b[0m, float32_812<256>\u001b[0m, float32_809<256>\u001b[0m, float32_810<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_813<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_813<1,256,16,16>\u001b[0m) -> float32_813<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_813<1,256,16,16>\u001b[0m, inplace=True) -> float32_813<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_813<1,256,16,16>\u001b[0m) -> float32_813<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_813<1,256,16,16>\u001b[0m) -> float32_815<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_813<1,256,16,16>\u001b[0m, float32_814<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_815<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_815<1,256,16,16>\u001b[0m) -> float32_820<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_815<1,256,16,16>\u001b[0m, float32_816<256>\u001b[0m, float32_817<256>\u001b[0m, float32_818<256>\u001b[0m, float32_819<256>\u001b[0m, False, 0.1, 1e-05) -> float32_820<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_815<1,256,16,16>\u001b[0m, float32_818<256>\u001b[0m, float32_819<256>\u001b[0m, float32_816<256>\u001b[0m, float32_817<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_820<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_820<1,256,16,16>\u001b[0m) -> float32_820<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_820<1,256,16,16>\u001b[0m) -> float32_822<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_820<1,256,16,16>\u001b[0m, float32_821<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_822<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_822<1,1024,16,16>\u001b[0m) -> float32_827<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_822<1,1024,16,16>\u001b[0m, float32_823<1024>\u001b[0m, float32_824<1024>\u001b[0m, float32_825<1024>\u001b[0m, float32_826<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_827<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_822<1,1024,16,16>\u001b[0m, float32_825<1024>\u001b[0m, float32_826<1024>\u001b[0m, float32_823<1024>\u001b[0m, float32_824<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_827<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_827<1,1024,16,16>\u001b[0m, float32_806<1,1024,16,16>\u001b[0m) -> float32_827<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_827<1,1024,16,16>\u001b[0m, float32_806<1,1024,16,16>\u001b[0m) -> float32_827<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_827<1,1024,16,16>\u001b[0m) -> float32_827<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_827<1,1024,16,16>\u001b[0m) -> float32_848<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_827<1,1024,16,16>\u001b[0m) -> float32_829<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_827<1,1024,16,16>\u001b[0m, float32_828<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_829<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_829<1,256,16,16>\u001b[0m) -> float32_834<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_829<1,256,16,16>\u001b[0m, float32_830<256>\u001b[0m, float32_831<256>\u001b[0m, float32_832<256>\u001b[0m, float32_833<256>\u001b[0m, False, 0.1, 1e-05) -> float32_834<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_829<1,256,16,16>\u001b[0m, float32_832<256>\u001b[0m, float32_833<256>\u001b[0m, float32_830<256>\u001b[0m, float32_831<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_834<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_834<1,256,16,16>\u001b[0m) -> float32_834<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_834<1,256,16,16>\u001b[0m, inplace=True) -> float32_834<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_834<1,256,16,16>\u001b[0m) -> float32_834<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_834<1,256,16,16>\u001b[0m) -> float32_836<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_834<1,256,16,16>\u001b[0m, float32_835<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_836<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_836<1,256,16,16>\u001b[0m) -> float32_841<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_836<1,256,16,16>\u001b[0m, float32_837<256>\u001b[0m, float32_838<256>\u001b[0m, float32_839<256>\u001b[0m, float32_840<256>\u001b[0m, False, 0.1, 1e-05) -> float32_841<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_836<1,256,16,16>\u001b[0m, float32_839<256>\u001b[0m, float32_840<256>\u001b[0m, float32_837<256>\u001b[0m, float32_838<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_841<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_841<1,256,16,16>\u001b[0m) -> float32_841<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_841<1,256,16,16>\u001b[0m) -> float32_843<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_841<1,256,16,16>\u001b[0m, float32_842<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_843<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_843<1,1024,16,16>\u001b[0m) -> float32_848<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_843<1,1024,16,16>\u001b[0m, float32_844<1024>\u001b[0m, float32_845<1024>\u001b[0m, float32_846<1024>\u001b[0m, float32_847<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_848<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_843<1,1024,16,16>\u001b[0m, float32_846<1024>\u001b[0m, float32_847<1024>\u001b[0m, float32_844<1024>\u001b[0m, float32_845<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_848<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_848<1,1024,16,16>\u001b[0m, float32_827<1,1024,16,16>\u001b[0m) -> float32_848<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_848<1,1024,16,16>\u001b[0m, float32_827<1,1024,16,16>\u001b[0m) -> float32_848<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_848<1,1024,16,16>\u001b[0m) -> float32_848<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_848<1,1024,16,16>\u001b[0m) -> float32_869<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_848<1,1024,16,16>\u001b[0m) -> float32_850<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_848<1,1024,16,16>\u001b[0m, float32_849<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_850<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_850<1,256,16,16>\u001b[0m) -> float32_855<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_850<1,256,16,16>\u001b[0m, float32_851<256>\u001b[0m, float32_852<256>\u001b[0m, float32_853<256>\u001b[0m, float32_854<256>\u001b[0m, False, 0.1, 1e-05) -> float32_855<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_850<1,256,16,16>\u001b[0m, float32_853<256>\u001b[0m, float32_854<256>\u001b[0m, float32_851<256>\u001b[0m, float32_852<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_855<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_855<1,256,16,16>\u001b[0m) -> float32_855<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_855<1,256,16,16>\u001b[0m, inplace=True) -> float32_855<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_855<1,256,16,16>\u001b[0m) -> float32_855<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_855<1,256,16,16>\u001b[0m) -> float32_857<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_855<1,256,16,16>\u001b[0m, float32_856<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_857<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_857<1,256,16,16>\u001b[0m) -> float32_862<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_857<1,256,16,16>\u001b[0m, float32_858<256>\u001b[0m, float32_859<256>\u001b[0m, float32_860<256>\u001b[0m, float32_861<256>\u001b[0m, False, 0.1, 1e-05) -> float32_862<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_857<1,256,16,16>\u001b[0m, float32_860<256>\u001b[0m, float32_861<256>\u001b[0m, float32_858<256>\u001b[0m, float32_859<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_862<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_862<1,256,16,16>\u001b[0m) -> float32_862<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_862<1,256,16,16>\u001b[0m) -> float32_864<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_862<1,256,16,16>\u001b[0m, float32_863<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_864<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_864<1,1024,16,16>\u001b[0m) -> float32_869<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_864<1,1024,16,16>\u001b[0m, float32_865<1024>\u001b[0m, float32_866<1024>\u001b[0m, float32_867<1024>\u001b[0m, float32_868<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_869<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_864<1,1024,16,16>\u001b[0m, float32_867<1024>\u001b[0m, float32_868<1024>\u001b[0m, float32_865<1024>\u001b[0m, float32_866<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_869<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_869<1,1024,16,16>\u001b[0m, float32_848<1,1024,16,16>\u001b[0m) -> float32_869<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_869<1,1024,16,16>\u001b[0m, float32_848<1,1024,16,16>\u001b[0m) -> float32_869<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_869<1,1024,16,16>\u001b[0m) -> float32_869<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_869<1,1024,16,16>\u001b[0m) -> float32_890<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_869<1,1024,16,16>\u001b[0m) -> float32_871<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_869<1,1024,16,16>\u001b[0m, float32_870<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_871<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_871<1,256,16,16>\u001b[0m) -> float32_876<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_871<1,256,16,16>\u001b[0m, float32_872<256>\u001b[0m, float32_873<256>\u001b[0m, float32_874<256>\u001b[0m, float32_875<256>\u001b[0m, False, 0.1, 1e-05) -> float32_876<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_871<1,256,16,16>\u001b[0m, float32_874<256>\u001b[0m, float32_875<256>\u001b[0m, float32_872<256>\u001b[0m, float32_873<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_876<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_876<1,256,16,16>\u001b[0m) -> float32_876<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_876<1,256,16,16>\u001b[0m, inplace=True) -> float32_876<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_876<1,256,16,16>\u001b[0m) -> float32_876<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_876<1,256,16,16>\u001b[0m) -> float32_878<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_876<1,256,16,16>\u001b[0m, float32_877<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_878<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_878<1,256,16,16>\u001b[0m) -> float32_883<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_878<1,256,16,16>\u001b[0m, float32_879<256>\u001b[0m, float32_880<256>\u001b[0m, float32_881<256>\u001b[0m, float32_882<256>\u001b[0m, False, 0.1, 1e-05) -> float32_883<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_878<1,256,16,16>\u001b[0m, float32_881<256>\u001b[0m, float32_882<256>\u001b[0m, float32_879<256>\u001b[0m, float32_880<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_883<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_883<1,256,16,16>\u001b[0m) -> float32_883<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_883<1,256,16,16>\u001b[0m) -> float32_885<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_883<1,256,16,16>\u001b[0m, float32_884<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_885<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_885<1,1024,16,16>\u001b[0m) -> float32_890<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_885<1,1024,16,16>\u001b[0m, float32_886<1024>\u001b[0m, float32_887<1024>\u001b[0m, float32_888<1024>\u001b[0m, float32_889<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_890<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_885<1,1024,16,16>\u001b[0m, float32_888<1024>\u001b[0m, float32_889<1024>\u001b[0m, float32_886<1024>\u001b[0m, float32_887<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_890<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_890<1,1024,16,16>\u001b[0m, float32_869<1,1024,16,16>\u001b[0m) -> float32_890<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_890<1,1024,16,16>\u001b[0m, float32_869<1,1024,16,16>\u001b[0m) -> float32_890<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_890<1,1024,16,16>\u001b[0m) -> float32_890<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_890<1,1024,16,16>\u001b[0m) -> float32_911<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_890<1,1024,16,16>\u001b[0m) -> float32_892<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_890<1,1024,16,16>\u001b[0m, float32_891<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_892<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_892<1,256,16,16>\u001b[0m) -> float32_897<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_892<1,256,16,16>\u001b[0m, float32_893<256>\u001b[0m, float32_894<256>\u001b[0m, float32_895<256>\u001b[0m, float32_896<256>\u001b[0m, False, 0.1, 1e-05) -> float32_897<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_892<1,256,16,16>\u001b[0m, float32_895<256>\u001b[0m, float32_896<256>\u001b[0m, float32_893<256>\u001b[0m, float32_894<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_897<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_897<1,256,16,16>\u001b[0m) -> float32_897<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_897<1,256,16,16>\u001b[0m, inplace=True) -> float32_897<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_897<1,256,16,16>\u001b[0m) -> float32_897<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_897<1,256,16,16>\u001b[0m) -> float32_899<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_897<1,256,16,16>\u001b[0m, float32_898<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_899<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_899<1,256,16,16>\u001b[0m) -> float32_904<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_899<1,256,16,16>\u001b[0m, float32_900<256>\u001b[0m, float32_901<256>\u001b[0m, float32_902<256>\u001b[0m, float32_903<256>\u001b[0m, False, 0.1, 1e-05) -> float32_904<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_899<1,256,16,16>\u001b[0m, float32_902<256>\u001b[0m, float32_903<256>\u001b[0m, float32_900<256>\u001b[0m, float32_901<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_904<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_904<1,256,16,16>\u001b[0m) -> float32_904<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_904<1,256,16,16>\u001b[0m) -> float32_906<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_904<1,256,16,16>\u001b[0m, float32_905<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_906<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_906<1,1024,16,16>\u001b[0m) -> float32_911<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_906<1,1024,16,16>\u001b[0m, float32_907<1024>\u001b[0m, float32_908<1024>\u001b[0m, float32_909<1024>\u001b[0m, float32_910<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_911<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_906<1,1024,16,16>\u001b[0m, float32_909<1024>\u001b[0m, float32_910<1024>\u001b[0m, float32_907<1024>\u001b[0m, float32_908<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_911<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_911<1,1024,16,16>\u001b[0m, float32_890<1,1024,16,16>\u001b[0m) -> float32_911<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_911<1,1024,16,16>\u001b[0m, float32_890<1,1024,16,16>\u001b[0m) -> float32_911<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_911<1,1024,16,16>\u001b[0m) -> float32_911<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_911<1,1024,16,16>\u001b[0m) -> float32_932<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_911<1,1024,16,16>\u001b[0m) -> float32_913<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_911<1,1024,16,16>\u001b[0m, float32_912<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_913<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_913<1,256,16,16>\u001b[0m) -> float32_918<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_913<1,256,16,16>\u001b[0m, float32_914<256>\u001b[0m, float32_915<256>\u001b[0m, float32_916<256>\u001b[0m, float32_917<256>\u001b[0m, False, 0.1, 1e-05) -> float32_918<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_913<1,256,16,16>\u001b[0m, float32_916<256>\u001b[0m, float32_917<256>\u001b[0m, float32_914<256>\u001b[0m, float32_915<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_918<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_918<1,256,16,16>\u001b[0m) -> float32_918<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_918<1,256,16,16>\u001b[0m, inplace=True) -> float32_918<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_918<1,256,16,16>\u001b[0m) -> float32_918<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_918<1,256,16,16>\u001b[0m) -> float32_920<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_918<1,256,16,16>\u001b[0m, float32_919<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_920<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_920<1,256,16,16>\u001b[0m) -> float32_925<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_920<1,256,16,16>\u001b[0m, float32_921<256>\u001b[0m, float32_922<256>\u001b[0m, float32_923<256>\u001b[0m, float32_924<256>\u001b[0m, False, 0.1, 1e-05) -> float32_925<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_920<1,256,16,16>\u001b[0m, float32_923<256>\u001b[0m, float32_924<256>\u001b[0m, float32_921<256>\u001b[0m, float32_922<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_925<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_925<1,256,16,16>\u001b[0m) -> float32_925<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_925<1,256,16,16>\u001b[0m) -> float32_927<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_925<1,256,16,16>\u001b[0m, float32_926<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_927<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_927<1,1024,16,16>\u001b[0m) -> float32_932<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_927<1,1024,16,16>\u001b[0m, float32_928<1024>\u001b[0m, float32_929<1024>\u001b[0m, float32_930<1024>\u001b[0m, float32_931<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_932<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_927<1,1024,16,16>\u001b[0m, float32_930<1024>\u001b[0m, float32_931<1024>\u001b[0m, float32_928<1024>\u001b[0m, float32_929<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_932<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_932<1,1024,16,16>\u001b[0m, float32_911<1,1024,16,16>\u001b[0m) -> float32_932<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_932<1,1024,16,16>\u001b[0m, float32_911<1,1024,16,16>\u001b[0m) -> float32_932<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_932<1,1024,16,16>\u001b[0m) -> float32_932<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_932<1,1024,16,16>\u001b[0m) -> float32_953<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_932<1,1024,16,16>\u001b[0m) -> float32_934<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_932<1,1024,16,16>\u001b[0m, float32_933<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_934<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_934<1,256,16,16>\u001b[0m) -> float32_939<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_934<1,256,16,16>\u001b[0m, float32_935<256>\u001b[0m, float32_936<256>\u001b[0m, float32_937<256>\u001b[0m, float32_938<256>\u001b[0m, False, 0.1, 1e-05) -> float32_939<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_934<1,256,16,16>\u001b[0m, float32_937<256>\u001b[0m, float32_938<256>\u001b[0m, float32_935<256>\u001b[0m, float32_936<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_939<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_939<1,256,16,16>\u001b[0m) -> float32_939<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_939<1,256,16,16>\u001b[0m, inplace=True) -> float32_939<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_939<1,256,16,16>\u001b[0m) -> float32_939<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_939<1,256,16,16>\u001b[0m) -> float32_941<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_939<1,256,16,16>\u001b[0m, float32_940<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_941<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_941<1,256,16,16>\u001b[0m) -> float32_946<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_941<1,256,16,16>\u001b[0m, float32_942<256>\u001b[0m, float32_943<256>\u001b[0m, float32_944<256>\u001b[0m, float32_945<256>\u001b[0m, False, 0.1, 1e-05) -> float32_946<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_941<1,256,16,16>\u001b[0m, float32_944<256>\u001b[0m, float32_945<256>\u001b[0m, float32_942<256>\u001b[0m, float32_943<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_946<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_946<1,256,16,16>\u001b[0m) -> float32_946<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_946<1,256,16,16>\u001b[0m) -> float32_948<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_946<1,256,16,16>\u001b[0m, float32_947<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_948<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_948<1,1024,16,16>\u001b[0m) -> float32_953<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_948<1,1024,16,16>\u001b[0m, float32_949<1024>\u001b[0m, float32_950<1024>\u001b[0m, float32_951<1024>\u001b[0m, float32_952<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_953<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_948<1,1024,16,16>\u001b[0m, float32_951<1024>\u001b[0m, float32_952<1024>\u001b[0m, float32_949<1024>\u001b[0m, float32_950<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_953<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_953<1,1024,16,16>\u001b[0m, float32_932<1,1024,16,16>\u001b[0m) -> float32_953<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_953<1,1024,16,16>\u001b[0m, float32_932<1,1024,16,16>\u001b[0m) -> float32_953<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_953<1,1024,16,16>\u001b[0m) -> float32_953<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_953<1,1024,16,16>\u001b[0m) -> float32_974<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_953<1,1024,16,16>\u001b[0m) -> float32_955<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_953<1,1024,16,16>\u001b[0m, float32_954<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_955<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_955<1,256,16,16>\u001b[0m) -> float32_960<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_955<1,256,16,16>\u001b[0m, float32_956<256>\u001b[0m, float32_957<256>\u001b[0m, float32_958<256>\u001b[0m, float32_959<256>\u001b[0m, False, 0.1, 1e-05) -> float32_960<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_955<1,256,16,16>\u001b[0m, float32_958<256>\u001b[0m, float32_959<256>\u001b[0m, float32_956<256>\u001b[0m, float32_957<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_960<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_960<1,256,16,16>\u001b[0m) -> float32_960<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_960<1,256,16,16>\u001b[0m, inplace=True) -> float32_960<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_960<1,256,16,16>\u001b[0m) -> float32_960<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_960<1,256,16,16>\u001b[0m) -> float32_962<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_960<1,256,16,16>\u001b[0m, float32_961<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_962<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_962<1,256,16,16>\u001b[0m) -> float32_967<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_962<1,256,16,16>\u001b[0m, float32_963<256>\u001b[0m, float32_964<256>\u001b[0m, float32_965<256>\u001b[0m, float32_966<256>\u001b[0m, False, 0.1, 1e-05) -> float32_967<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_962<1,256,16,16>\u001b[0m, float32_965<256>\u001b[0m, float32_966<256>\u001b[0m, float32_963<256>\u001b[0m, float32_964<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_967<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_967<1,256,16,16>\u001b[0m) -> float32_967<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_967<1,256,16,16>\u001b[0m) -> float32_969<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_967<1,256,16,16>\u001b[0m, float32_968<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_969<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_969<1,1024,16,16>\u001b[0m) -> float32_974<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_969<1,1024,16,16>\u001b[0m, float32_970<1024>\u001b[0m, float32_971<1024>\u001b[0m, float32_972<1024>\u001b[0m, float32_973<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_974<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_969<1,1024,16,16>\u001b[0m, float32_972<1024>\u001b[0m, float32_973<1024>\u001b[0m, float32_970<1024>\u001b[0m, float32_971<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_974<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_974<1,1024,16,16>\u001b[0m, float32_953<1,1024,16,16>\u001b[0m) -> float32_974<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_974<1,1024,16,16>\u001b[0m, float32_953<1,1024,16,16>\u001b[0m) -> float32_974<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_974<1,1024,16,16>\u001b[0m) -> float32_974<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_974<1,1024,16,16>\u001b[0m) -> float32_995<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_974<1,1024,16,16>\u001b[0m) -> float32_976<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_974<1,1024,16,16>\u001b[0m, float32_975<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_976<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_976<1,256,16,16>\u001b[0m) -> float32_981<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_976<1,256,16,16>\u001b[0m, float32_977<256>\u001b[0m, float32_978<256>\u001b[0m, float32_979<256>\u001b[0m, float32_980<256>\u001b[0m, False, 0.1, 1e-05) -> float32_981<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_976<1,256,16,16>\u001b[0m, float32_979<256>\u001b[0m, float32_980<256>\u001b[0m, float32_977<256>\u001b[0m, float32_978<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_981<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_981<1,256,16,16>\u001b[0m) -> float32_981<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_981<1,256,16,16>\u001b[0m, inplace=True) -> float32_981<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_981<1,256,16,16>\u001b[0m) -> float32_981<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_981<1,256,16,16>\u001b[0m) -> float32_983<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_981<1,256,16,16>\u001b[0m, float32_982<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_983<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_983<1,256,16,16>\u001b[0m) -> float32_988<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_983<1,256,16,16>\u001b[0m, float32_984<256>\u001b[0m, float32_985<256>\u001b[0m, float32_986<256>\u001b[0m, float32_987<256>\u001b[0m, False, 0.1, 1e-05) -> float32_988<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_983<1,256,16,16>\u001b[0m, float32_986<256>\u001b[0m, float32_987<256>\u001b[0m, float32_984<256>\u001b[0m, float32_985<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_988<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_988<1,256,16,16>\u001b[0m) -> float32_988<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_988<1,256,16,16>\u001b[0m) -> float32_990<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_988<1,256,16,16>\u001b[0m, float32_989<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_990<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_990<1,1024,16,16>\u001b[0m) -> float32_995<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_990<1,1024,16,16>\u001b[0m, float32_991<1024>\u001b[0m, float32_992<1024>\u001b[0m, float32_993<1024>\u001b[0m, float32_994<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_995<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_990<1,1024,16,16>\u001b[0m, float32_993<1024>\u001b[0m, float32_994<1024>\u001b[0m, float32_991<1024>\u001b[0m, float32_992<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_995<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_995<1,1024,16,16>\u001b[0m, float32_974<1,1024,16,16>\u001b[0m) -> float32_995<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_995<1,1024,16,16>\u001b[0m, float32_974<1,1024,16,16>\u001b[0m) -> float32_995<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_995<1,1024,16,16>\u001b[0m) -> float32_995<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_995<1,1024,16,16>\u001b[0m) -> float32_1016<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_995<1,1024,16,16>\u001b[0m) -> float32_997<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_995<1,1024,16,16>\u001b[0m, float32_996<256,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_997<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_997<1,256,16,16>\u001b[0m) -> float32_1002<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_997<1,256,16,16>\u001b[0m, float32_998<256>\u001b[0m, float32_999<256>\u001b[0m, float32_1000<256>\u001b[0m, float32_1001<256>\u001b[0m, False, 0.1, 1e-05) -> float32_1002<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_997<1,256,16,16>\u001b[0m, float32_1000<256>\u001b[0m, float32_1001<256>\u001b[0m, float32_998<256>\u001b[0m, float32_999<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_1002<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_1002<1,256,16,16>\u001b[0m) -> float32_1002<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_1002<1,256,16,16>\u001b[0m, inplace=True) -> float32_1002<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_1002<1,256,16,16>\u001b[0m) -> float32_1002<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_1002<1,256,16,16>\u001b[0m) -> float32_1004<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_1002<1,256,16,16>\u001b[0m, float32_1003<256,256,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_1004<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_1004<1,256,16,16>\u001b[0m) -> float32_1009<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_1004<1,256,16,16>\u001b[0m, float32_1005<256>\u001b[0m, float32_1006<256>\u001b[0m, float32_1007<256>\u001b[0m, float32_1008<256>\u001b[0m, False, 0.1, 1e-05) -> float32_1009<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_1004<1,256,16,16>\u001b[0m, float32_1007<256>\u001b[0m, float32_1008<256>\u001b[0m, float32_1005<256>\u001b[0m, float32_1006<256>\u001b[0m, False, 0.1, 1e-05, True) -> float32_1009<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_1009<1,256,16,16>\u001b[0m) -> float32_1009<1,256,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_1009<1,256,16,16>\u001b[0m) -> float32_1011<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_1009<1,256,16,16>\u001b[0m, float32_1010<1024,256,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_1011<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_1011<1,1024,16,16>\u001b[0m) -> float32_1016<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_1011<1,1024,16,16>\u001b[0m, float32_1012<1024>\u001b[0m, float32_1013<1024>\u001b[0m, float32_1014<1024>\u001b[0m, float32_1015<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_1016<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_1011<1,1024,16,16>\u001b[0m, float32_1014<1024>\u001b[0m, float32_1015<1024>\u001b[0m, float32_1012<1024>\u001b[0m, float32_1013<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_1016<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_1016<1,1024,16,16>\u001b[0m, float32_995<1,1024,16,16>\u001b[0m) -> float32_1016<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_1016<1,1024,16,16>\u001b[0m, float32_995<1,1024,16,16>\u001b[0m) -> float32_1016<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_1016<1,1024,16,16>\u001b[0m) -> float32_1016<1,1024,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_1016<1,1024,16,16>\u001b[0m) -> float32_1086<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_1016<1,1024,16,16>\u001b[0m) -> float32_1037<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_1016<1,1024,16,16>\u001b[0m) -> float32_1018<1,512,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_1016<1,1024,16,16>\u001b[0m, float32_1017<512,1024,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_1018<1,512,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_1018<1,512,16,16>\u001b[0m) -> float32_1023<1,512,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_1018<1,512,16,16>\u001b[0m, float32_1019<512>\u001b[0m, float32_1020<512>\u001b[0m, float32_1021<512>\u001b[0m, float32_1022<512>\u001b[0m, False, 0.1, 1e-05) -> float32_1023<1,512,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_1018<1,512,16,16>\u001b[0m, float32_1021<512>\u001b[0m, float32_1022<512>\u001b[0m, float32_1019<512>\u001b[0m, float32_1020<512>\u001b[0m, False, 0.1, 1e-05, True) -> float32_1023<1,512,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_1023<1,512,16,16>\u001b[0m) -> float32_1023<1,512,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_1023<1,512,16,16>\u001b[0m, inplace=True) -> float32_1023<1,512,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_1023<1,512,16,16>\u001b[0m) -> float32_1023<1,512,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_1023<1,512,16,16>\u001b[0m) -> float32_1025<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_1023<1,512,16,16>\u001b[0m, float32_1024<512,512,3,3>\u001b[0m, None, (2, 2), (1, 1), (1, 1), 1) -> float32_1025<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_1025<1,512,8,8>\u001b[0m) -> float32_1030<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_1025<1,512,8,8>\u001b[0m, float32_1026<512>\u001b[0m, float32_1027<512>\u001b[0m, float32_1028<512>\u001b[0m, float32_1029<512>\u001b[0m, False, 0.1, 1e-05) -> float32_1030<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_1025<1,512,8,8>\u001b[0m, float32_1028<512>\u001b[0m, float32_1029<512>\u001b[0m, float32_1026<512>\u001b[0m, float32_1027<512>\u001b[0m, False, 0.1, 1e-05, True) -> float32_1030<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_1030<1,512,8,8>\u001b[0m) -> float32_1030<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_1030<1,512,8,8>\u001b[0m) -> float32_1032<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_1030<1,512,8,8>\u001b[0m, float32_1031<2048,512,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_1032<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_1032<1,2048,8,8>\u001b[0m) -> float32_1037<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_1032<1,2048,8,8>\u001b[0m, float32_1033<2048>\u001b[0m, float32_1034<2048>\u001b[0m, float32_1035<2048>\u001b[0m, float32_1036<2048>\u001b[0m, False, 0.1, 1e-05) -> float32_1037<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_1032<1,2048,8,8>\u001b[0m, float32_1035<2048>\u001b[0m, float32_1036<2048>\u001b[0m, float32_1033<2048>\u001b[0m, float32_1034<2048>\u001b[0m, False, 0.1, 1e-05, True) -> float32_1037<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_1016<1,1024,16,16>\u001b[0m) -> float32_1044<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_1016<1,1024,16,16>\u001b[0m) -> float32_1039<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_1016<1,1024,16,16>\u001b[0m, float32_1038<2048,1024,1,1>\u001b[0m, None, (2, 2), (0, 0), (1, 1), 1) -> float32_1039<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_1039<1,2048,8,8>\u001b[0m) -> float32_1044<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_1039<1,2048,8,8>\u001b[0m, float32_1040<2048>\u001b[0m, float32_1041<2048>\u001b[0m, float32_1042<2048>\u001b[0m, float32_1043<2048>\u001b[0m, False, 0.1, 1e-05) -> float32_1044<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_1039<1,2048,8,8>\u001b[0m, float32_1042<2048>\u001b[0m, float32_1043<2048>\u001b[0m, float32_1040<2048>\u001b[0m, float32_1041<2048>\u001b[0m, False, 0.1, 1e-05, True) -> float32_1044<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_1037<1,2048,8,8>\u001b[0m, float32_1044<1,2048,8,8>\u001b[0m) -> float32_1037<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_1037<1,2048,8,8>\u001b[0m, float32_1044<1,2048,8,8>\u001b[0m) -> float32_1037<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_1037<1,2048,8,8>\u001b[0m) -> float32_1037<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_1037<1,2048,8,8>\u001b[0m) -> float32_1065<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_1037<1,2048,8,8>\u001b[0m) -> float32_1046<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_1037<1,2048,8,8>\u001b[0m, float32_1045<512,2048,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_1046<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_1046<1,512,8,8>\u001b[0m) -> float32_1051<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_1046<1,512,8,8>\u001b[0m, float32_1047<512>\u001b[0m, float32_1048<512>\u001b[0m, float32_1049<512>\u001b[0m, float32_1050<512>\u001b[0m, False, 0.1, 1e-05) -> float32_1051<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_1046<1,512,8,8>\u001b[0m, float32_1049<512>\u001b[0m, float32_1050<512>\u001b[0m, float32_1047<512>\u001b[0m, float32_1048<512>\u001b[0m, False, 0.1, 1e-05, True) -> float32_1051<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_1051<1,512,8,8>\u001b[0m) -> float32_1051<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_1051<1,512,8,8>\u001b[0m, inplace=True) -> float32_1051<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_1051<1,512,8,8>\u001b[0m) -> float32_1051<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_1051<1,512,8,8>\u001b[0m) -> float32_1053<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_1051<1,512,8,8>\u001b[0m, float32_1052<512,512,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_1053<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_1053<1,512,8,8>\u001b[0m) -> float32_1058<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_1053<1,512,8,8>\u001b[0m, float32_1054<512>\u001b[0m, float32_1055<512>\u001b[0m, float32_1056<512>\u001b[0m, float32_1057<512>\u001b[0m, False, 0.1, 1e-05) -> float32_1058<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_1053<1,512,8,8>\u001b[0m, float32_1056<512>\u001b[0m, float32_1057<512>\u001b[0m, float32_1054<512>\u001b[0m, float32_1055<512>\u001b[0m, False, 0.1, 1e-05, True) -> float32_1058<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_1058<1,512,8,8>\u001b[0m) -> float32_1058<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_1058<1,512,8,8>\u001b[0m) -> float32_1060<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_1058<1,512,8,8>\u001b[0m, float32_1059<2048,512,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_1060<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_1060<1,2048,8,8>\u001b[0m) -> float32_1065<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_1060<1,2048,8,8>\u001b[0m, float32_1061<2048>\u001b[0m, float32_1062<2048>\u001b[0m, float32_1063<2048>\u001b[0m, float32_1064<2048>\u001b[0m, False, 0.1, 1e-05) -> float32_1065<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_1060<1,2048,8,8>\u001b[0m, float32_1063<2048>\u001b[0m, float32_1064<2048>\u001b[0m, float32_1061<2048>\u001b[0m, float32_1062<2048>\u001b[0m, False, 0.1, 1e-05, True) -> float32_1065<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_1065<1,2048,8,8>\u001b[0m, float32_1037<1,2048,8,8>\u001b[0m) -> float32_1065<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_1065<1,2048,8,8>\u001b[0m, float32_1037<1,2048,8,8>\u001b[0m) -> float32_1065<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_1065<1,2048,8,8>\u001b[0m) -> float32_1065<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mBottleneck[torchvision.models.resnet]\u001b[0m(float32_1065<1,2048,8,8>\u001b[0m) -> float32_1086<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_1065<1,2048,8,8>\u001b[0m) -> float32_1067<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_1065<1,2048,8,8>\u001b[0m, float32_1066<512,2048,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_1067<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_1067<1,512,8,8>\u001b[0m) -> float32_1072<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_1067<1,512,8,8>\u001b[0m, float32_1068<512>\u001b[0m, float32_1069<512>\u001b[0m, float32_1070<512>\u001b[0m, float32_1071<512>\u001b[0m, False, 0.1, 1e-05) -> float32_1072<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_1067<1,512,8,8>\u001b[0m, float32_1070<512>\u001b[0m, float32_1071<512>\u001b[0m, float32_1068<512>\u001b[0m, float32_1069<512>\u001b[0m, False, 0.1, 1e-05, True) -> float32_1072<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_1072<1,512,8,8>\u001b[0m) -> float32_1072<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_1072<1,512,8,8>\u001b[0m, inplace=True) -> float32_1072<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_1072<1,512,8,8>\u001b[0m) -> float32_1072<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_1072<1,512,8,8>\u001b[0m) -> float32_1074<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_1072<1,512,8,8>\u001b[0m, float32_1073<512,512,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 1) -> float32_1074<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_1074<1,512,8,8>\u001b[0m) -> float32_1079<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_1074<1,512,8,8>\u001b[0m, float32_1075<512>\u001b[0m, float32_1076<512>\u001b[0m, float32_1077<512>\u001b[0m, float32_1078<512>\u001b[0m, False, 0.1, 1e-05) -> float32_1079<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_1074<1,512,8,8>\u001b[0m, float32_1077<512>\u001b[0m, float32_1078<512>\u001b[0m, float32_1075<512>\u001b[0m, float32_1076<512>\u001b[0m, False, 0.1, 1e-05, True) -> float32_1079<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_1079<1,512,8,8>\u001b[0m) -> float32_1079<1,512,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_1079<1,512,8,8>\u001b[0m) -> float32_1081<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_1079<1,512,8,8>\u001b[0m, float32_1080<2048,512,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_1081<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_1081<1,2048,8,8>\u001b[0m) -> float32_1086<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_1081<1,2048,8,8>\u001b[0m, float32_1082<2048>\u001b[0m, float32_1083<2048>\u001b[0m, float32_1084<2048>\u001b[0m, float32_1085<2048>\u001b[0m, False, 0.1, 1e-05) -> float32_1086<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_1081<1,2048,8,8>\u001b[0m, float32_1084<2048>\u001b[0m, float32_1085<2048>\u001b[0m, float32_1082<2048>\u001b[0m, float32_1083<2048>\u001b[0m, False, 0.1, 1e-05, True) -> float32_1086<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_1086<1,2048,8,8>\u001b[0m, float32_1065<1,2048,8,8>\u001b[0m) -> float32_1086<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[_TensorBase]\u001b[0m(float32_1086<1,2048,8,8>\u001b[0m, float32_1065<1,2048,8,8>\u001b[0m) -> float32_1086<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m*ReLU[torch.nn.modules.activation]\u001b[0m(float32_1086<1,2048,8,8>\u001b[0m) -> float32_1086<1,2048,8,8>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_1086<1,2048,8,8>\u001b[0m) -> float32_1104<1,512,4,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m\u001b[1m\u001b[7m (!) Max diff 0.00336 (0.000%) \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/home/athena/anaconda3/envs/nobuCon/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 215\u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/home/athena/anaconda3/envs/nobuCon/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 313 \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m\u001b[1m C \u001b[0m\u001b[90m File \"/home/athena/anaconda3/envs/nobuCon/lib/python3.10/site-packages/nobuco/node_converters/convolution.py\", line 300 \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_1086<1,2048,8,8>\u001b[0m) -> float32_1089<1,1024,6,6>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_1086<1,2048,8,8>\u001b[0m, float32_1087<1024,2048,3,3>\u001b[0m, float32_1088<1024>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_1089<1,1024,6,6>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_1089<1,1024,6,6>\u001b[0m) -> float32_1094<1,1024,6,6>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_1089<1,1024,6,6>\u001b[0m, float32_1090<1024>\u001b[0m, float32_1091<1024>\u001b[0m, float32_1092<1024>\u001b[0m, float32_1093<1024>\u001b[0m, False, 0.1, 1e-05) -> float32_1094<1,1024,6,6>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_1089<1,1024,6,6>\u001b[0m, float32_1092<1024>\u001b[0m, float32_1093<1024>\u001b[0m, float32_1090<1024>\u001b[0m, float32_1091<1024>\u001b[0m, False, 0.1, 1e-05, True) -> float32_1094<1,1024,6,6>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_1094<1,1024,6,6>\u001b[0m) -> float32_1095<1,1024,6,6>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_1094<1,1024,6,6>\u001b[0m, inplace=False) -> float32_1095<1,1024,6,6>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_1094<1,1024,6,6>\u001b[0m) -> float32_1095<1,1024,6,6>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m\u001b[1m\u001b[7m (!) Max diff 0.00063 (0.000%) \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"/home/athena/anaconda3/envs/nobuCon/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 215\u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"/home/athena/anaconda3/envs/nobuCon/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 313 \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m\u001b[1m C \u001b[0m\u001b[90m File \"/home/athena/anaconda3/envs/nobuCon/lib/python3.10/site-packages/nobuco/node_converters/convolution.py\", line 300 \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_1095<1,1024,6,6>\u001b[0m) -> float32_1098<1,512,4,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_1095<1,1024,6,6>\u001b[0m, float32_1096<512,1024,3,3>\u001b[0m, float32_1097<512>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_1098<1,512,4,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_1098<1,512,4,4>\u001b[0m) -> float32_1103<1,512,4,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_1098<1,512,4,4>\u001b[0m, float32_1099<512>\u001b[0m, float32_1100<512>\u001b[0m, float32_1101<512>\u001b[0m, float32_1102<512>\u001b[0m, False, 0.1, 1e-05) -> float32_1103<1,512,4,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_1098<1,512,4,4>\u001b[0m, float32_1101<512>\u001b[0m, float32_1102<512>\u001b[0m, float32_1099<512>\u001b[0m, float32_1100<512>\u001b[0m, False, 0.1, 1e-05, True) -> float32_1103<1,512,4,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_1103<1,512,4,4>\u001b[0m) -> float32_1104<1,512,4,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_1103<1,512,4,4>\u001b[0m, inplace=False) -> float32_1104<1,512,4,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_1103<1,512,4,4>\u001b[0m) -> float32_1104<1,512,4,4>\u001b[0m\n",
      "\u001b[32m ├·\u001b[0m \u001b[32mDualAttentionNetwork[__main__]\u001b[0m(float32_1104<1,512,4,4>\u001b[0m) -> float32_1140<1,1024>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mChannelAttention[__main__]\u001b[0m(float32_1104<1,512,4,4>\u001b[0m) -> float32_1113<1,512,4,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_1104<1,512,4,4>\u001b[0m, 1, 512, -1) -> float32_1105<1,512,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mtranspose[torch.Tensor]\u001b[0m(float32_1105<1,512,16>\u001b[0m, 1, 2) -> float32_1106<1,16,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mbmm[torch]\u001b[0m(float32_1105<1,512,16>\u001b[0m, float32_1106<1,16,512>\u001b[0m) -> float32_1107<1,512,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1msoftmax[torch.nn.functional]\u001b[0m(float32_1107<1,512,512>\u001b[0m, dim=1) -> float32_1108<1,512,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0msoftmax[torch.Tensor]\u001b[0m(float32_1107<1,512,512>\u001b[0m, 1) -> float32_1108<1,512,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mbmm[torch]\u001b[0m(float32_1108<1,512,512>\u001b[0m, float32_1105<1,512,16>\u001b[0m) -> float32_1109<1,512,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_1109<1,512,16>\u001b[0m, 1, 512, 4, 4) -> float32_1110<1,512,4,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(\u001b[4mfloat32_1111<1>\u001b[0m, float32_1110<1,512,4,4>\u001b[0m) -> float32_1112<1,512,4,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[_TensorBase]\u001b[0m(float32_1111<1>\u001b[0m, float32_1110<1,512,4,4>\u001b[0m) -> float32_1112<1,512,4,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_1112<1,512,4,4>\u001b[0m, float32_1104<1,512,4,4>\u001b[0m) -> float32_1113<1,512,4,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[_TensorBase]\u001b[0m(float32_1112<1,512,4,4>\u001b[0m, float32_1104<1,512,4,4>\u001b[0m) -> float32_1113<1,512,4,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSpatialAttention[__main__]\u001b[0m(float32_1104<1,512,4,4>\u001b[0m) -> float32_1134<1,512,4,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_1104<1,512,4,4>\u001b[0m) -> float32_1116<1,512,4,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_1104<1,512,4,4>\u001b[0m, float32_1114<512,512,1,1>\u001b[0m, float32_1115<512>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_1116<1,512,4,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_1104<1,512,4,4>\u001b[0m) -> float32_1119<1,512,4,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_1104<1,512,4,4>\u001b[0m, float32_1117<512,512,1,1>\u001b[0m, float32_1118<512>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_1119<1,512,4,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_1116<1,512,4,4>\u001b[0m, 1, 512, -1) -> float32_1120<1,512,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_1119<1,512,4,4>\u001b[0m, 1, 512, -1) -> float32_1121<1,512,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mtranspose[torch.Tensor]\u001b[0m(float32_1120<1,512,16>\u001b[0m, 1, 2) -> float32_1122<1,16,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mbmm[torch]\u001b[0m(float32_1122<1,16,512>\u001b[0m, float32_1121<1,512,16>\u001b[0m) -> float32_1123<1,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1msoftmax[torch.nn.functional]\u001b[0m(float32_1123<1,16,16>\u001b[0m, dim=1) -> float32_1124<1,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0msoftmax[torch.Tensor]\u001b[0m(float32_1123<1,16,16>\u001b[0m, 1) -> float32_1124<1,16,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_1104<1,512,4,4>\u001b[0m) -> float32_1127<1,512,4,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_1104<1,512,4,4>\u001b[0m, float32_1125<512,512,1,1>\u001b[0m, float32_1126<512>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_1127<1,512,4,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_1127<1,512,4,4>\u001b[0m, 1, 512, -1) -> float32_1128<1,512,16>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mtranspose[torch.Tensor]\u001b[0m(float32_1128<1,512,16>\u001b[0m, 1, 2) -> float32_1129<1,16,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mbmm[torch]\u001b[0m(float32_1124<1,16,16>\u001b[0m, float32_1129<1,16,512>\u001b[0m) -> float32_1130<1,16,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_1130<1,16,512>\u001b[0m, 1, 512, 4, 4) -> float32_1131<1,512,4,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(\u001b[4mfloat32_1132<1>\u001b[0m, float32_1131<1,512,4,4>\u001b[0m) -> float32_1133<1,512,4,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[_TensorBase]\u001b[0m(float32_1132<1>\u001b[0m, float32_1131<1,512,4,4>\u001b[0m) -> float32_1133<1,512,4,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__add__[torch.Tensor]\u001b[0m(float32_1133<1,512,4,4>\u001b[0m, float32_1104<1,512,4,4>\u001b[0m) -> float32_1134<1,512,4,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd[_TensorBase]\u001b[0m(float32_1133<1,512,4,4>\u001b[0m, float32_1104<1,512,4,4>\u001b[0m) -> float32_1134<1,512,4,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mcat[torch]\u001b[0m([float32_1104<1,512,4,4>\u001b[0m, float32_1113<1,512,4,4>\u001b[0m, float32_1134<1,512,4,4>\u001b[0m], dim=1) -> float32_1135<1,1536,4,4>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_1135<1,1536,4,4>\u001b[0m) -> float32_1136<1,1536,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_1135<1,1536,4,4>\u001b[0m, 1) -> float32_1136<1,1536,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mview[torch.Tensor]\u001b[0m(float32_1136<1,1536,1,1>\u001b[0m, 1, -1) -> float32_1137<1,1536>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_1137<1,1536>\u001b[0m) -> float32_1140<1,1024>\u001b[0m\n",
      "\u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_1137<1,1536>\u001b[0m, float32_1138<1024,1536>\u001b[0m, float32_1139<1024>\u001b[0m) -> float32_1140<1,1024>\u001b[0m\n",
      "\n",
      "[Nobuco] Conversion complete. Elapsed time: 10.12 sec.\n"
     ]
    }
   ],
   "source": [
    "pytorch_module = model.eval()\n",
    "with torch.no_grad():\n",
    "    # output = pytorch_module(dummy_input)\n",
    "    keras_model = nobuco.pytorch_to_keras(\n",
    "        pytorch_module,\n",
    "        args=[dummy_input], kwargs=None,\n",
    "        inputs_channel_order=ChannelOrder.TENSORFLOW,\n",
    "        outputs_channel_order=ChannelOrder.TENSORFLOW\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 256, 256])\n",
      "1/1 [==============================] - 0s 131ms/step\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "img_path = \"/home/athena/Documents/GitHub/Dog-NosePrint-Recognition/dataset2/classes_with_6imgs/5672/O1CN01fjcDg01yHK0TN1bE3_!!0-mtopupload.jpg\"\n",
    "image = Image.open(img_path).convert('RGB')\n",
    "transform_image = transform_val(image).unsqueeze(0)\n",
    "print(transform_image.shape)\n",
    "# convert it to 1,256,256,3\n",
    "transform_image = transform_image.permute(0, 2, 3, 1)\n",
    "keras_output = keras_model.predict(transform_image.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1024)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np_vector = np.load('output.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1024)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(arr1, arr2):\n",
    "    dot_product = np.dot(arr1, arr2.T)\n",
    "    norm_a = np.linalg.norm(arr1)\n",
    "    norm_b = np.linalg.norm(arr2)\n",
    "    similarity = dot_product / (norm_a * norm_b)\n",
    "    return similarity\n",
    "\n",
    "cosine_similarity(keras_output, np_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(1, 256, 256, 3)]           0         []                            \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPaddin  (1, 262, 262, 3)             0         ['input_1[0][0]']             \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (1, 128, 128, 64)            9408      ['zero_padding2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (1, 128, 128, 64)            256       ['conv2d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                (1, 128, 128, 64)            0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " tf.compat.v1.pad (TFOpLamb  (1, 130, 130, 64)            0         ['re_lu[0][0]']               \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (1, 64, 64, 64)              0         ['tf.compat.v1.pad[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (1, 64, 64, 64)              4096      ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (1, 64, 64, 64)              256       ['conv2d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)              multiple                     0         ['batch_normalization_1[0][0]'\n",
      "                                                                    , 'batch_normalization_2[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add[0][0]']\n",
      "                                                                                                  \n",
      " zero_padding2d_1 (ZeroPadd  (1, 66, 66, 64)              0         ['re_lu_1[0][0]']             \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (1, 64, 64, 64)              36864     ['zero_padding2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (1, 64, 64, 64)              256       ['conv2d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (1, 64, 64, 256)             16384     ['re_lu_1[1][0]']             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (1, 64, 64, 256)             16384     ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (1, 64, 64, 256)             1024      ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (1, 64, 64, 256)             1024      ['conv2d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOp  (1, 64, 64, 256)             0         ['batch_normalization_3[0][0]'\n",
      " Lambda)                                                            , 'batch_normalization_4[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (1, 64, 64, 64)              16384     ['re_lu_1[2][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (1, 64, 64, 64)              256       ['conv2d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)              multiple                     0         ['batch_normalization_5[0][0]'\n",
      "                                                                    , 'batch_normalization_6[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " zero_padding2d_2 (ZeroPadd  (1, 66, 66, 64)              0         ['re_lu_2[0][0]']             \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (1, 64, 64, 64)              36864     ['zero_padding2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (1, 64, 64, 64)              256       ['conv2d_6[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (1, 64, 64, 256)             16384     ['re_lu_2[1][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (1, 64, 64, 256)             1024      ['conv2d_7[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TF  (1, 64, 64, 256)             0         ['batch_normalization_7[0][0]'\n",
      " OpLambda)                                                          , 're_lu_1[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (1, 64, 64, 64)              16384     ['re_lu_2[2][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (1, 64, 64, 64)              256       ['conv2d_8[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)              multiple                     0         ['batch_normalization_8[0][0]'\n",
      "                                                                    , 'batch_normalization_9[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_2[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " zero_padding2d_3 (ZeroPadd  (1, 66, 66, 64)              0         ['re_lu_3[0][0]']             \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (1, 64, 64, 64)              36864     ['zero_padding2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (1, 64, 64, 64)              256       ['conv2d_9[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (1, 64, 64, 256)             16384     ['re_lu_3[1][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (1, 64, 64, 256)             1024      ['conv2d_10[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TF  (1, 64, 64, 256)             0         ['batch_normalization_10[0][0]\n",
      " OpLambda)                                                          ',                            \n",
      "                                                                     're_lu_2[2][0]']             \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (1, 64, 64, 128)             32768     ['re_lu_3[2][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (1, 64, 64, 128)             512       ['conv2d_11[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)              multiple                     0         ['batch_normalization_11[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'batch_normalization_12[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_3[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " zero_padding2d_4 (ZeroPadd  (1, 66, 66, 128)             0         ['re_lu_4[0][0]']             \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (1, 32, 32, 128)             147456    ['zero_padding2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (1, 32, 32, 128)             512       ['conv2d_12[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (1, 32, 32, 512)             65536     ['re_lu_4[1][0]']             \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (1, 32, 32, 512)             131072    ['re_lu_3[2][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (1, 32, 32, 512)             2048      ['conv2d_13[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_14 (Ba  (1, 32, 32, 512)             2048      ['conv2d_14[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TF  (1, 32, 32, 512)             0         ['batch_normalization_13[0][0]\n",
      " OpLambda)                                                          ',                            \n",
      "                                                                     'batch_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (1, 32, 32, 128)             65536     ['re_lu_4[2][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_15 (Ba  (1, 32, 32, 128)             512       ['conv2d_15[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)              multiple                     0         ['batch_normalization_15[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'batch_normalization_16[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_4[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " zero_padding2d_5 (ZeroPadd  (1, 34, 34, 128)             0         ['re_lu_5[0][0]']             \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (1, 32, 32, 128)             147456    ['zero_padding2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (Ba  (1, 32, 32, 128)             512       ['conv2d_16[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (1, 32, 32, 512)             65536     ['re_lu_5[1][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_17 (Ba  (1, 32, 32, 512)             2048      ['conv2d_17[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TF  (1, 32, 32, 512)             0         ['batch_normalization_17[0][0]\n",
      " OpLambda)                                                          ',                            \n",
      "                                                                     're_lu_4[2][0]']             \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (1, 32, 32, 128)             65536     ['re_lu_5[2][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_18 (Ba  (1, 32, 32, 128)             512       ['conv2d_18[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)              multiple                     0         ['batch_normalization_18[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'batch_normalization_19[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_5[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " zero_padding2d_6 (ZeroPadd  (1, 34, 34, 128)             0         ['re_lu_6[0][0]']             \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)          (1, 32, 32, 128)             147456    ['zero_padding2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (Ba  (1, 32, 32, 128)             512       ['conv2d_19[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)          (1, 32, 32, 512)             65536     ['re_lu_6[1][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_20 (Ba  (1, 32, 32, 512)             2048      ['conv2d_20[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TF  (1, 32, 32, 512)             0         ['batch_normalization_20[0][0]\n",
      " OpLambda)                                                          ',                            \n",
      "                                                                     're_lu_5[2][0]']             \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)          (1, 32, 32, 128)             65536     ['re_lu_6[2][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_21 (Ba  (1, 32, 32, 128)             512       ['conv2d_21[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)              multiple                     0         ['batch_normalization_21[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'batch_normalization_22[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_6[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " zero_padding2d_7 (ZeroPadd  (1, 34, 34, 128)             0         ['re_lu_7[0][0]']             \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)          (1, 32, 32, 128)             147456    ['zero_padding2d_7[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_22 (Ba  (1, 32, 32, 128)             512       ['conv2d_22[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)          (1, 32, 32, 512)             65536     ['re_lu_7[1][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_23 (Ba  (1, 32, 32, 512)             2048      ['conv2d_23[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TF  (1, 32, 32, 512)             0         ['batch_normalization_23[0][0]\n",
      " OpLambda)                                                          ',                            \n",
      "                                                                     're_lu_6[2][0]']             \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)          (1, 32, 32, 128)             65536     ['re_lu_7[2][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_24 (Ba  (1, 32, 32, 128)             512       ['conv2d_24[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)              multiple                     0         ['batch_normalization_24[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'batch_normalization_25[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_7[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " zero_padding2d_8 (ZeroPadd  (1, 34, 34, 128)             0         ['re_lu_8[0][0]']             \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)          (1, 32, 32, 128)             147456    ['zero_padding2d_8[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (Ba  (1, 32, 32, 128)             512       ['conv2d_25[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)          (1, 32, 32, 512)             65536     ['re_lu_8[1][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_26 (Ba  (1, 32, 32, 512)             2048      ['conv2d_26[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TF  (1, 32, 32, 512)             0         ['batch_normalization_26[0][0]\n",
      " OpLambda)                                                          ',                            \n",
      "                                                                     're_lu_7[2][0]']             \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)          (1, 32, 32, 128)             65536     ['re_lu_8[2][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_27 (Ba  (1, 32, 32, 128)             512       ['conv2d_27[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_9 (ReLU)              multiple                     0         ['batch_normalization_27[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'batch_normalization_28[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_8[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " zero_padding2d_9 (ZeroPadd  (1, 34, 34, 128)             0         ['re_lu_9[0][0]']             \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)          (1, 32, 32, 128)             147456    ['zero_padding2d_9[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_28 (Ba  (1, 32, 32, 128)             512       ['conv2d_28[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)          (1, 32, 32, 512)             65536     ['re_lu_9[1][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_29 (Ba  (1, 32, 32, 512)             2048      ['conv2d_29[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_8 (TF  (1, 32, 32, 512)             0         ['batch_normalization_29[0][0]\n",
      " OpLambda)                                                          ',                            \n",
      "                                                                     're_lu_8[2][0]']             \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)          (1, 32, 32, 128)             65536     ['re_lu_9[2][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_30 (Ba  (1, 32, 32, 128)             512       ['conv2d_30[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)             multiple                     0         ['batch_normalization_30[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'batch_normalization_31[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_9[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " zero_padding2d_10 (ZeroPad  (1, 34, 34, 128)             0         ['re_lu_10[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)          (1, 32, 32, 128)             147456    ['zero_padding2d_10[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_31 (Ba  (1, 32, 32, 128)             512       ['conv2d_31[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)          (1, 32, 32, 512)             65536     ['re_lu_10[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_32 (Ba  (1, 32, 32, 512)             2048      ['conv2d_32[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_9 (TF  (1, 32, 32, 512)             0         ['batch_normalization_32[0][0]\n",
      " OpLambda)                                                          ',                            \n",
      "                                                                     're_lu_9[2][0]']             \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)          (1, 32, 32, 128)             65536     ['re_lu_10[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_33 (Ba  (1, 32, 32, 128)             512       ['conv2d_33[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_11 (ReLU)             multiple                     0         ['batch_normalization_33[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'batch_normalization_34[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_10[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_11 (ZeroPad  (1, 34, 34, 128)             0         ['re_lu_11[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)          (1, 32, 32, 128)             147456    ['zero_padding2d_11[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_34 (Ba  (1, 32, 32, 128)             512       ['conv2d_34[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)          (1, 32, 32, 512)             65536     ['re_lu_11[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_35 (Ba  (1, 32, 32, 512)             2048      ['conv2d_35[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_10 (T  (1, 32, 32, 512)             0         ['batch_normalization_35[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     're_lu_10[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)          (1, 32, 32, 256)             131072    ['re_lu_11[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_36 (Ba  (1, 32, 32, 256)             1024      ['conv2d_36[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_12 (ReLU)             multiple                     0         ['batch_normalization_36[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'batch_normalization_37[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_11[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_12 (ZeroPad  (1, 34, 34, 256)             0         ['re_lu_12[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)          (1, 16, 16, 256)             589824    ['zero_padding2d_12[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_37 (Ba  (1, 16, 16, 256)             1024      ['conv2d_37[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)          (1, 16, 16, 1024)            262144    ['re_lu_12[1][0]']            \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)          (1, 16, 16, 1024)            524288    ['re_lu_11[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_38 (Ba  (1, 16, 16, 1024)            4096      ['conv2d_38[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_39 (Ba  (1, 16, 16, 1024)            4096      ['conv2d_39[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_11 (T  (1, 16, 16, 1024)            0         ['batch_normalization_38[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'batch_normalization_39[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)          (1, 16, 16, 256)             262144    ['re_lu_12[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_40 (Ba  (1, 16, 16, 256)             1024      ['conv2d_40[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_13 (ReLU)             multiple                     0         ['batch_normalization_40[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'batch_normalization_41[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_12[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_13 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_13[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)          (1, 16, 16, 256)             589824    ['zero_padding2d_13[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_41 (Ba  (1, 16, 16, 256)             1024      ['conv2d_41[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)          (1, 16, 16, 1024)            262144    ['re_lu_13[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_42 (Ba  (1, 16, 16, 1024)            4096      ['conv2d_42[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_12 (T  (1, 16, 16, 1024)            0         ['batch_normalization_42[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     're_lu_12[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)          (1, 16, 16, 256)             262144    ['re_lu_13[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_43 (Ba  (1, 16, 16, 256)             1024      ['conv2d_43[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_14 (ReLU)             multiple                     0         ['batch_normalization_43[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'batch_normalization_44[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_13[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_14 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_14[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)          (1, 16, 16, 256)             589824    ['zero_padding2d_14[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_44 (Ba  (1, 16, 16, 256)             1024      ['conv2d_44[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)          (1, 16, 16, 1024)            262144    ['re_lu_14[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_45 (Ba  (1, 16, 16, 1024)            4096      ['conv2d_45[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_13 (T  (1, 16, 16, 1024)            0         ['batch_normalization_45[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     're_lu_13[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)          (1, 16, 16, 256)             262144    ['re_lu_14[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_46 (Ba  (1, 16, 16, 256)             1024      ['conv2d_46[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_15 (ReLU)             multiple                     0         ['batch_normalization_46[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'batch_normalization_47[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_14[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_15 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_15[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)          (1, 16, 16, 256)             589824    ['zero_padding2d_15[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_47 (Ba  (1, 16, 16, 256)             1024      ['conv2d_47[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)          (1, 16, 16, 1024)            262144    ['re_lu_15[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_48 (Ba  (1, 16, 16, 1024)            4096      ['conv2d_48[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_14 (T  (1, 16, 16, 1024)            0         ['batch_normalization_48[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     're_lu_14[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)          (1, 16, 16, 256)             262144    ['re_lu_15[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_49 (Ba  (1, 16, 16, 256)             1024      ['conv2d_49[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_16 (ReLU)             multiple                     0         ['batch_normalization_49[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'batch_normalization_50[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_15[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_16 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_16[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)          (1, 16, 16, 256)             589824    ['zero_padding2d_16[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_50 (Ba  (1, 16, 16, 256)             1024      ['conv2d_50[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)          (1, 16, 16, 1024)            262144    ['re_lu_16[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_51 (Ba  (1, 16, 16, 1024)            4096      ['conv2d_51[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_15 (T  (1, 16, 16, 1024)            0         ['batch_normalization_51[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     're_lu_15[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)          (1, 16, 16, 256)             262144    ['re_lu_16[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_52 (Ba  (1, 16, 16, 256)             1024      ['conv2d_52[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_17 (ReLU)             multiple                     0         ['batch_normalization_52[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'batch_normalization_53[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_16[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_17 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_17[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)          (1, 16, 16, 256)             589824    ['zero_padding2d_17[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_53 (Ba  (1, 16, 16, 256)             1024      ['conv2d_53[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)          (1, 16, 16, 1024)            262144    ['re_lu_17[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_54 (Ba  (1, 16, 16, 1024)            4096      ['conv2d_54[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_16 (T  (1, 16, 16, 1024)            0         ['batch_normalization_54[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     're_lu_16[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)          (1, 16, 16, 256)             262144    ['re_lu_17[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_55 (Ba  (1, 16, 16, 256)             1024      ['conv2d_55[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_18 (ReLU)             multiple                     0         ['batch_normalization_55[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'batch_normalization_56[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_17[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_18 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_18[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)          (1, 16, 16, 256)             589824    ['zero_padding2d_18[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_56 (Ba  (1, 16, 16, 256)             1024      ['conv2d_56[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)          (1, 16, 16, 1024)            262144    ['re_lu_18[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_57 (Ba  (1, 16, 16, 1024)            4096      ['conv2d_57[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_17 (T  (1, 16, 16, 1024)            0         ['batch_normalization_57[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     're_lu_17[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)          (1, 16, 16, 256)             262144    ['re_lu_18[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_58 (Ba  (1, 16, 16, 256)             1024      ['conv2d_58[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_19 (ReLU)             multiple                     0         ['batch_normalization_58[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'batch_normalization_59[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_18[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_19 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_19[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)          (1, 16, 16, 256)             589824    ['zero_padding2d_19[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_59 (Ba  (1, 16, 16, 256)             1024      ['conv2d_59[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)          (1, 16, 16, 1024)            262144    ['re_lu_19[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_60 (Ba  (1, 16, 16, 1024)            4096      ['conv2d_60[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_18 (T  (1, 16, 16, 1024)            0         ['batch_normalization_60[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     're_lu_18[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)          (1, 16, 16, 256)             262144    ['re_lu_19[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_61 (Ba  (1, 16, 16, 256)             1024      ['conv2d_61[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_20 (ReLU)             multiple                     0         ['batch_normalization_61[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'batch_normalization_62[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_19[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_20 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_20[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)          (1, 16, 16, 256)             589824    ['zero_padding2d_20[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_62 (Ba  (1, 16, 16, 256)             1024      ['conv2d_62[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)          (1, 16, 16, 1024)            262144    ['re_lu_20[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_63 (Ba  (1, 16, 16, 1024)            4096      ['conv2d_63[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_19 (T  (1, 16, 16, 1024)            0         ['batch_normalization_63[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     're_lu_19[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)          (1, 16, 16, 256)             262144    ['re_lu_20[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_64 (Ba  (1, 16, 16, 256)             1024      ['conv2d_64[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_21 (ReLU)             multiple                     0         ['batch_normalization_64[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'batch_normalization_65[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_20[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_21 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_21[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)          (1, 16, 16, 256)             589824    ['zero_padding2d_21[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_65 (Ba  (1, 16, 16, 256)             1024      ['conv2d_65[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)          (1, 16, 16, 1024)            262144    ['re_lu_21[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_66 (Ba  (1, 16, 16, 1024)            4096      ['conv2d_66[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_20 (T  (1, 16, 16, 1024)            0         ['batch_normalization_66[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     're_lu_20[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)          (1, 16, 16, 256)             262144    ['re_lu_21[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_67 (Ba  (1, 16, 16, 256)             1024      ['conv2d_67[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_22 (ReLU)             multiple                     0         ['batch_normalization_67[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'batch_normalization_68[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_21[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_22 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_22[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)          (1, 16, 16, 256)             589824    ['zero_padding2d_22[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_68 (Ba  (1, 16, 16, 256)             1024      ['conv2d_68[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)          (1, 16, 16, 1024)            262144    ['re_lu_22[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_69 (Ba  (1, 16, 16, 1024)            4096      ['conv2d_69[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_21 (T  (1, 16, 16, 1024)            0         ['batch_normalization_69[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     're_lu_21[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)          (1, 16, 16, 256)             262144    ['re_lu_22[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_70 (Ba  (1, 16, 16, 256)             1024      ['conv2d_70[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_23 (ReLU)             multiple                     0         ['batch_normalization_70[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'batch_normalization_71[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_22[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_23 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_23[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)          (1, 16, 16, 256)             589824    ['zero_padding2d_23[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_71 (Ba  (1, 16, 16, 256)             1024      ['conv2d_71[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)          (1, 16, 16, 1024)            262144    ['re_lu_23[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_72 (Ba  (1, 16, 16, 1024)            4096      ['conv2d_72[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_22 (T  (1, 16, 16, 1024)            0         ['batch_normalization_72[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     're_lu_22[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)          (1, 16, 16, 256)             262144    ['re_lu_23[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_73 (Ba  (1, 16, 16, 256)             1024      ['conv2d_73[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_24 (ReLU)             multiple                     0         ['batch_normalization_73[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'batch_normalization_74[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_23[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_24 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_24[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)          (1, 16, 16, 256)             589824    ['zero_padding2d_24[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_74 (Ba  (1, 16, 16, 256)             1024      ['conv2d_74[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)          (1, 16, 16, 1024)            262144    ['re_lu_24[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_75 (Ba  (1, 16, 16, 1024)            4096      ['conv2d_75[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_23 (T  (1, 16, 16, 1024)            0         ['batch_normalization_75[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     're_lu_23[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)          (1, 16, 16, 256)             262144    ['re_lu_24[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_76 (Ba  (1, 16, 16, 256)             1024      ['conv2d_76[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_25 (ReLU)             multiple                     0         ['batch_normalization_76[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'batch_normalization_77[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_24[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_25 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_25[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)          (1, 16, 16, 256)             589824    ['zero_padding2d_25[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_77 (Ba  (1, 16, 16, 256)             1024      ['conv2d_77[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)          (1, 16, 16, 1024)            262144    ['re_lu_25[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_78 (Ba  (1, 16, 16, 1024)            4096      ['conv2d_78[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_24 (T  (1, 16, 16, 1024)            0         ['batch_normalization_78[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     're_lu_24[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)          (1, 16, 16, 256)             262144    ['re_lu_25[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_79 (Ba  (1, 16, 16, 256)             1024      ['conv2d_79[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_26 (ReLU)             multiple                     0         ['batch_normalization_79[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'batch_normalization_80[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_25[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_26 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_26[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)          (1, 16, 16, 256)             589824    ['zero_padding2d_26[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_80 (Ba  (1, 16, 16, 256)             1024      ['conv2d_80[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)          (1, 16, 16, 1024)            262144    ['re_lu_26[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_81 (Ba  (1, 16, 16, 1024)            4096      ['conv2d_81[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_25 (T  (1, 16, 16, 1024)            0         ['batch_normalization_81[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     're_lu_25[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)          (1, 16, 16, 256)             262144    ['re_lu_26[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_82 (Ba  (1, 16, 16, 256)             1024      ['conv2d_82[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_27 (ReLU)             multiple                     0         ['batch_normalization_82[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'batch_normalization_83[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_26[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_27 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_27[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)          (1, 16, 16, 256)             589824    ['zero_padding2d_27[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_83 (Ba  (1, 16, 16, 256)             1024      ['conv2d_83[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)          (1, 16, 16, 1024)            262144    ['re_lu_27[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_84 (Ba  (1, 16, 16, 1024)            4096      ['conv2d_84[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_26 (T  (1, 16, 16, 1024)            0         ['batch_normalization_84[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     're_lu_26[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)          (1, 16, 16, 256)             262144    ['re_lu_27[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_85 (Ba  (1, 16, 16, 256)             1024      ['conv2d_85[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_28 (ReLU)             multiple                     0         ['batch_normalization_85[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'batch_normalization_86[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_27[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_28 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_28[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)          (1, 16, 16, 256)             589824    ['zero_padding2d_28[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_86 (Ba  (1, 16, 16, 256)             1024      ['conv2d_86[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)          (1, 16, 16, 1024)            262144    ['re_lu_28[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_87 (Ba  (1, 16, 16, 1024)            4096      ['conv2d_87[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_27 (T  (1, 16, 16, 1024)            0         ['batch_normalization_87[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     're_lu_27[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)          (1, 16, 16, 256)             262144    ['re_lu_28[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_88 (Ba  (1, 16, 16, 256)             1024      ['conv2d_88[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_29 (ReLU)             multiple                     0         ['batch_normalization_88[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'batch_normalization_89[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_28[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_29 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_29[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)          (1, 16, 16, 256)             589824    ['zero_padding2d_29[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_89 (Ba  (1, 16, 16, 256)             1024      ['conv2d_89[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)          (1, 16, 16, 1024)            262144    ['re_lu_29[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_90 (Ba  (1, 16, 16, 1024)            4096      ['conv2d_90[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_28 (T  (1, 16, 16, 1024)            0         ['batch_normalization_90[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     're_lu_28[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)          (1, 16, 16, 256)             262144    ['re_lu_29[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_91 (Ba  (1, 16, 16, 256)             1024      ['conv2d_91[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_30 (ReLU)             multiple                     0         ['batch_normalization_91[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'batch_normalization_92[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_29[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_30 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_30[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)          (1, 16, 16, 256)             589824    ['zero_padding2d_30[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_92 (Ba  (1, 16, 16, 256)             1024      ['conv2d_92[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)          (1, 16, 16, 1024)            262144    ['re_lu_30[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_93 (Ba  (1, 16, 16, 1024)            4096      ['conv2d_93[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_29 (T  (1, 16, 16, 1024)            0         ['batch_normalization_93[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     're_lu_29[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_94 (Conv2D)          (1, 16, 16, 256)             262144    ['re_lu_30[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_94 (Ba  (1, 16, 16, 256)             1024      ['conv2d_94[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_31 (ReLU)             multiple                     0         ['batch_normalization_94[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'batch_normalization_95[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_30[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_31 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_31[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_95 (Conv2D)          (1, 16, 16, 256)             589824    ['zero_padding2d_31[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_95 (Ba  (1, 16, 16, 256)             1024      ['conv2d_95[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_96 (Conv2D)          (1, 16, 16, 1024)            262144    ['re_lu_31[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_96 (Ba  (1, 16, 16, 1024)            4096      ['conv2d_96[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_30 (T  (1, 16, 16, 1024)            0         ['batch_normalization_96[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     're_lu_30[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_97 (Conv2D)          (1, 16, 16, 256)             262144    ['re_lu_31[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_97 (Ba  (1, 16, 16, 256)             1024      ['conv2d_97[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_32 (ReLU)             multiple                     0         ['batch_normalization_97[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'batch_normalization_98[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_31[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_32 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_32[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_98 (Conv2D)          (1, 16, 16, 256)             589824    ['zero_padding2d_32[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_98 (Ba  (1, 16, 16, 256)             1024      ['conv2d_98[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_99 (Conv2D)          (1, 16, 16, 1024)            262144    ['re_lu_32[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_99 (Ba  (1, 16, 16, 1024)            4096      ['conv2d_99[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_31 (T  (1, 16, 16, 1024)            0         ['batch_normalization_99[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     're_lu_31[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_100 (Conv2D)         (1, 16, 16, 256)             262144    ['re_lu_32[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_100 (B  (1, 16, 16, 256)             1024      ['conv2d_100[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_33 (ReLU)             multiple                     0         ['batch_normalization_100[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'batch_normalization_101[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'tf.__operators__.add_32[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_33 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_33[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_101 (Conv2D)         (1, 16, 16, 256)             589824    ['zero_padding2d_33[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_101 (B  (1, 16, 16, 256)             1024      ['conv2d_101[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_102 (Conv2D)         (1, 16, 16, 1024)            262144    ['re_lu_33[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_102 (B  (1, 16, 16, 1024)            4096      ['conv2d_102[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_32 (T  (1, 16, 16, 1024)            0         ['batch_normalization_102[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     're_lu_32[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_103 (Conv2D)         (1, 16, 16, 256)             262144    ['re_lu_33[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_103 (B  (1, 16, 16, 256)             1024      ['conv2d_103[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_34 (ReLU)             multiple                     0         ['batch_normalization_103[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'batch_normalization_104[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'tf.__operators__.add_33[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_34 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_34[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_104 (Conv2D)         (1, 16, 16, 256)             589824    ['zero_padding2d_34[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_104 (B  (1, 16, 16, 256)             1024      ['conv2d_104[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_105 (Conv2D)         (1, 16, 16, 1024)            262144    ['re_lu_34[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_105 (B  (1, 16, 16, 1024)            4096      ['conv2d_105[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_33 (T  (1, 16, 16, 1024)            0         ['batch_normalization_105[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     're_lu_33[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_106 (Conv2D)         (1, 16, 16, 256)             262144    ['re_lu_34[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_106 (B  (1, 16, 16, 256)             1024      ['conv2d_106[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_35 (ReLU)             multiple                     0         ['batch_normalization_106[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'batch_normalization_107[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'tf.__operators__.add_34[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_35 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_35[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_107 (Conv2D)         (1, 16, 16, 256)             589824    ['zero_padding2d_35[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_107 (B  (1, 16, 16, 256)             1024      ['conv2d_107[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_108 (Conv2D)         (1, 16, 16, 1024)            262144    ['re_lu_35[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_108 (B  (1, 16, 16, 1024)            4096      ['conv2d_108[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_34 (T  (1, 16, 16, 1024)            0         ['batch_normalization_108[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     're_lu_34[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_109 (Conv2D)         (1, 16, 16, 256)             262144    ['re_lu_35[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_109 (B  (1, 16, 16, 256)             1024      ['conv2d_109[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_36 (ReLU)             multiple                     0         ['batch_normalization_109[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'batch_normalization_110[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'tf.__operators__.add_35[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_36 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_36[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_110 (Conv2D)         (1, 16, 16, 256)             589824    ['zero_padding2d_36[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_110 (B  (1, 16, 16, 256)             1024      ['conv2d_110[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_111 (Conv2D)         (1, 16, 16, 1024)            262144    ['re_lu_36[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_111 (B  (1, 16, 16, 1024)            4096      ['conv2d_111[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_35 (T  (1, 16, 16, 1024)            0         ['batch_normalization_111[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     're_lu_35[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_112 (Conv2D)         (1, 16, 16, 256)             262144    ['re_lu_36[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_112 (B  (1, 16, 16, 256)             1024      ['conv2d_112[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_37 (ReLU)             multiple                     0         ['batch_normalization_112[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'batch_normalization_113[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'tf.__operators__.add_36[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_37 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_37[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_113 (Conv2D)         (1, 16, 16, 256)             589824    ['zero_padding2d_37[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_113 (B  (1, 16, 16, 256)             1024      ['conv2d_113[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_114 (Conv2D)         (1, 16, 16, 1024)            262144    ['re_lu_37[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_114 (B  (1, 16, 16, 1024)            4096      ['conv2d_114[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_36 (T  (1, 16, 16, 1024)            0         ['batch_normalization_114[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     're_lu_36[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_115 (Conv2D)         (1, 16, 16, 256)             262144    ['re_lu_37[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_115 (B  (1, 16, 16, 256)             1024      ['conv2d_115[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_38 (ReLU)             multiple                     0         ['batch_normalization_115[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'batch_normalization_116[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'tf.__operators__.add_37[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_38 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_38[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_116 (Conv2D)         (1, 16, 16, 256)             589824    ['zero_padding2d_38[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_116 (B  (1, 16, 16, 256)             1024      ['conv2d_116[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_117 (Conv2D)         (1, 16, 16, 1024)            262144    ['re_lu_38[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_117 (B  (1, 16, 16, 1024)            4096      ['conv2d_117[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_37 (T  (1, 16, 16, 1024)            0         ['batch_normalization_117[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     're_lu_37[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_118 (Conv2D)         (1, 16, 16, 256)             262144    ['re_lu_38[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_118 (B  (1, 16, 16, 256)             1024      ['conv2d_118[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_39 (ReLU)             multiple                     0         ['batch_normalization_118[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'batch_normalization_119[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'tf.__operators__.add_38[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_39 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_39[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_119 (Conv2D)         (1, 16, 16, 256)             589824    ['zero_padding2d_39[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_119 (B  (1, 16, 16, 256)             1024      ['conv2d_119[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_120 (Conv2D)         (1, 16, 16, 1024)            262144    ['re_lu_39[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_120 (B  (1, 16, 16, 1024)            4096      ['conv2d_120[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_38 (T  (1, 16, 16, 1024)            0         ['batch_normalization_120[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     're_lu_38[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_121 (Conv2D)         (1, 16, 16, 256)             262144    ['re_lu_39[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_121 (B  (1, 16, 16, 256)             1024      ['conv2d_121[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_40 (ReLU)             multiple                     0         ['batch_normalization_121[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'batch_normalization_122[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'tf.__operators__.add_39[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_40 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_40[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_122 (Conv2D)         (1, 16, 16, 256)             589824    ['zero_padding2d_40[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_122 (B  (1, 16, 16, 256)             1024      ['conv2d_122[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_123 (Conv2D)         (1, 16, 16, 1024)            262144    ['re_lu_40[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_123 (B  (1, 16, 16, 1024)            4096      ['conv2d_123[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_39 (T  (1, 16, 16, 1024)            0         ['batch_normalization_123[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     're_lu_39[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_124 (Conv2D)         (1, 16, 16, 256)             262144    ['re_lu_40[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_124 (B  (1, 16, 16, 256)             1024      ['conv2d_124[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_41 (ReLU)             multiple                     0         ['batch_normalization_124[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'batch_normalization_125[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'tf.__operators__.add_40[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_41 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_41[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_125 (Conv2D)         (1, 16, 16, 256)             589824    ['zero_padding2d_41[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_125 (B  (1, 16, 16, 256)             1024      ['conv2d_125[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_126 (Conv2D)         (1, 16, 16, 1024)            262144    ['re_lu_41[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_126 (B  (1, 16, 16, 1024)            4096      ['conv2d_126[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_40 (T  (1, 16, 16, 1024)            0         ['batch_normalization_126[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     're_lu_40[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_127 (Conv2D)         (1, 16, 16, 256)             262144    ['re_lu_41[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_127 (B  (1, 16, 16, 256)             1024      ['conv2d_127[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_42 (ReLU)             multiple                     0         ['batch_normalization_127[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'batch_normalization_128[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'tf.__operators__.add_41[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_42 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_42[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_128 (Conv2D)         (1, 16, 16, 256)             589824    ['zero_padding2d_42[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_128 (B  (1, 16, 16, 256)             1024      ['conv2d_128[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_129 (Conv2D)         (1, 16, 16, 1024)            262144    ['re_lu_42[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_129 (B  (1, 16, 16, 1024)            4096      ['conv2d_129[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_41 (T  (1, 16, 16, 1024)            0         ['batch_normalization_129[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     're_lu_41[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_130 (Conv2D)         (1, 16, 16, 256)             262144    ['re_lu_42[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_130 (B  (1, 16, 16, 256)             1024      ['conv2d_130[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_43 (ReLU)             multiple                     0         ['batch_normalization_130[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'batch_normalization_131[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'tf.__operators__.add_42[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_43 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_43[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_131 (Conv2D)         (1, 16, 16, 256)             589824    ['zero_padding2d_43[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_131 (B  (1, 16, 16, 256)             1024      ['conv2d_131[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_132 (Conv2D)         (1, 16, 16, 1024)            262144    ['re_lu_43[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_132 (B  (1, 16, 16, 1024)            4096      ['conv2d_132[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_42 (T  (1, 16, 16, 1024)            0         ['batch_normalization_132[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     're_lu_42[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_133 (Conv2D)         (1, 16, 16, 256)             262144    ['re_lu_43[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_133 (B  (1, 16, 16, 256)             1024      ['conv2d_133[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_44 (ReLU)             multiple                     0         ['batch_normalization_133[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'batch_normalization_134[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'tf.__operators__.add_43[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_44 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_44[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_134 (Conv2D)         (1, 16, 16, 256)             589824    ['zero_padding2d_44[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_134 (B  (1, 16, 16, 256)             1024      ['conv2d_134[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_135 (Conv2D)         (1, 16, 16, 1024)            262144    ['re_lu_44[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_135 (B  (1, 16, 16, 1024)            4096      ['conv2d_135[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_43 (T  (1, 16, 16, 1024)            0         ['batch_normalization_135[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     're_lu_43[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_136 (Conv2D)         (1, 16, 16, 256)             262144    ['re_lu_44[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_136 (B  (1, 16, 16, 256)             1024      ['conv2d_136[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_45 (ReLU)             multiple                     0         ['batch_normalization_136[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'batch_normalization_137[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'tf.__operators__.add_44[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_45 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_45[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_137 (Conv2D)         (1, 16, 16, 256)             589824    ['zero_padding2d_45[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_137 (B  (1, 16, 16, 256)             1024      ['conv2d_137[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_138 (Conv2D)         (1, 16, 16, 1024)            262144    ['re_lu_45[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_138 (B  (1, 16, 16, 1024)            4096      ['conv2d_138[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_44 (T  (1, 16, 16, 1024)            0         ['batch_normalization_138[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     're_lu_44[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_139 (Conv2D)         (1, 16, 16, 256)             262144    ['re_lu_45[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_139 (B  (1, 16, 16, 256)             1024      ['conv2d_139[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_46 (ReLU)             multiple                     0         ['batch_normalization_139[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'batch_normalization_140[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'tf.__operators__.add_45[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_46 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_46[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_140 (Conv2D)         (1, 16, 16, 256)             589824    ['zero_padding2d_46[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_140 (B  (1, 16, 16, 256)             1024      ['conv2d_140[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_141 (Conv2D)         (1, 16, 16, 1024)            262144    ['re_lu_46[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_141 (B  (1, 16, 16, 1024)            4096      ['conv2d_141[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_45 (T  (1, 16, 16, 1024)            0         ['batch_normalization_141[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     're_lu_45[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_142 (Conv2D)         (1, 16, 16, 256)             262144    ['re_lu_46[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_142 (B  (1, 16, 16, 256)             1024      ['conv2d_142[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_47 (ReLU)             multiple                     0         ['batch_normalization_142[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'batch_normalization_143[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'tf.__operators__.add_46[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_47 (ZeroPad  (1, 18, 18, 256)             0         ['re_lu_47[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_143 (Conv2D)         (1, 16, 16, 256)             589824    ['zero_padding2d_47[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_143 (B  (1, 16, 16, 256)             1024      ['conv2d_143[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_144 (Conv2D)         (1, 16, 16, 1024)            262144    ['re_lu_47[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_144 (B  (1, 16, 16, 1024)            4096      ['conv2d_144[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_46 (T  (1, 16, 16, 1024)            0         ['batch_normalization_144[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     're_lu_46[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_145 (Conv2D)         (1, 16, 16, 512)             524288    ['re_lu_47[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_145 (B  (1, 16, 16, 512)             2048      ['conv2d_145[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_48 (ReLU)             multiple                     0         ['batch_normalization_145[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'batch_normalization_146[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'tf.__operators__.add_47[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_48 (ZeroPad  (1, 18, 18, 512)             0         ['re_lu_48[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_146 (Conv2D)         (1, 8, 8, 512)               2359296   ['zero_padding2d_48[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_146 (B  (1, 8, 8, 512)               2048      ['conv2d_146[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_147 (Conv2D)         (1, 8, 8, 2048)              1048576   ['re_lu_48[1][0]']            \n",
      "                                                                                                  \n",
      " conv2d_148 (Conv2D)         (1, 8, 8, 2048)              2097152   ['re_lu_47[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_147 (B  (1, 8, 8, 2048)              8192      ['conv2d_147[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_148 (B  (1, 8, 8, 2048)              8192      ['conv2d_148[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_47 (T  (1, 8, 8, 2048)              0         ['batch_normalization_147[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     'batch_normalization_148[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_149 (Conv2D)         (1, 8, 8, 512)               1048576   ['re_lu_48[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_149 (B  (1, 8, 8, 512)               2048      ['conv2d_149[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_49 (ReLU)             multiple                     0         ['batch_normalization_149[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'batch_normalization_150[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'tf.__operators__.add_48[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_49 (ZeroPad  (1, 10, 10, 512)             0         ['re_lu_49[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_150 (Conv2D)         (1, 8, 8, 512)               2359296   ['zero_padding2d_49[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_150 (B  (1, 8, 8, 512)               2048      ['conv2d_150[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_151 (Conv2D)         (1, 8, 8, 2048)              1048576   ['re_lu_49[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_151 (B  (1, 8, 8, 2048)              8192      ['conv2d_151[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_48 (T  (1, 8, 8, 2048)              0         ['batch_normalization_151[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     're_lu_48[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_152 (Conv2D)         (1, 8, 8, 512)               1048576   ['re_lu_49[2][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_152 (B  (1, 8, 8, 512)               2048      ['conv2d_152[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_50 (ReLU)             multiple                     0         ['batch_normalization_152[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'batch_normalization_153[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'tf.__operators__.add_49[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " zero_padding2d_50 (ZeroPad  (1, 10, 10, 512)             0         ['re_lu_50[0][0]']            \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_153 (Conv2D)         (1, 8, 8, 512)               2359296   ['zero_padding2d_50[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_153 (B  (1, 8, 8, 512)               2048      ['conv2d_153[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_154 (Conv2D)         (1, 8, 8, 2048)              1048576   ['re_lu_50[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_154 (B  (1, 8, 8, 2048)              8192      ['conv2d_154[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_49 (T  (1, 8, 8, 2048)              0         ['batch_normalization_154[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     're_lu_49[2][0]']            \n",
      "                                                                                                  \n",
      " conv2d_155 (Conv2D)         (1, 6, 6, 1024)              1887539   ['re_lu_50[2][0]']            \n",
      "                                                          2                                       \n",
      "                                                                                                  \n",
      " batch_normalization_155 (B  (1, 6, 6, 1024)              4096      ['conv2d_155[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_51 (ReLU)             (1, 6, 6, 1024)              0         ['batch_normalization_155[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_156 (Conv2D)         (1, 4, 4, 512)               4719104   ['re_lu_51[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_156 (B  (1, 4, 4, 512)               2048      ['conv2d_156[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_52 (ReLU)             (1, 4, 4, 512)               0         ['batch_normalization_156[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_157 (Conv2D)         (1, 4, 4, 512)               262656    ['re_lu_52[0][0]']            \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose (TF  (1, 512, 4, 4)               0         ['re_lu_52[0][0]']            \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_3 (  (1, 512, 4, 4)               0         ['conv2d_157[0][0]']          \n",
      " TFOpLambda)                                                                                      \n",
      "                                                                                                  \n",
      " tf.reshape (TFOpLambda)     (1, 512, 16)                 0         ['tf.compat.v1.transpose[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.reshape_2 (TFOpLambda)   (1, 512, 16)                 0         ['tf.compat.v1.transpose_3[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " conv2d_158 (Conv2D)         (1, 4, 4, 512)               262656    ['re_lu_52[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_159 (Conv2D)         (1, 4, 4, 512)               262656    ['re_lu_52[0][0]']            \n",
      "                                                                                                  \n",
      " tf.identity (TFOpLambda)    (1, 512, 16)                 0         ['tf.reshape[0][0]']          \n",
      "                                                                                                  \n",
      " tf.identity_1 (TFOpLambda)  (1, 512, 16)                 0         ['tf.reshape_2[0][0]']        \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_4 (  (1, 512, 4, 4)               0         ['conv2d_158[0][0]']          \n",
      " TFOpLambda)                                                                                      \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_6 (  (1, 512, 4, 4)               0         ['conv2d_159[0][0]']          \n",
      " TFOpLambda)                                                                                      \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_1 (  (1, 16, 512)                 0         ['tf.identity[0][0]']         \n",
      " TFOpLambda)                                                                                      \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_5 (  (1, 16, 512)                 0         ['tf.identity_1[0][0]']       \n",
      " TFOpLambda)                                                                                      \n",
      "                                                                                                  \n",
      " tf.reshape_3 (TFOpLambda)   (1, 512, 16)                 0         ['tf.compat.v1.transpose_4[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " tf.reshape_4 (TFOpLambda)   (1, 512, 16)                 0         ['tf.compat.v1.transpose_6[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " tf.linalg.matmul (TFOpLamb  (1, 512, 512)                0         ['tf.reshape[0][0]',          \n",
      " da)                                                                 'tf.compat.v1.transpose_1[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_2 (TFOpLa  (1, 16, 16)                  0         ['tf.compat.v1.transpose_5[0][\n",
      " mbda)                                                              0]',                          \n",
      "                                                                     'tf.reshape_3[0][0]']        \n",
      "                                                                                                  \n",
      " tf.identity_2 (TFOpLambda)  (1, 512, 16)                 0         ['tf.reshape_4[0][0]']        \n",
      "                                                                                                  \n",
      " tf.nn.softmax (TFOpLambda)  (1, 512, 512)                0         ['tf.linalg.matmul[0][0]']    \n",
      "                                                                                                  \n",
      " tf.nn.softmax_1 (TFOpLambd  (1, 16, 16)                  0         ['tf.linalg.matmul_2[0][0]']  \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_7 (  (1, 16, 512)                 0         ['tf.identity_2[0][0]']       \n",
      " TFOpLambda)                                                                                      \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_1 (TFOpLa  (1, 512, 16)                 0         ['tf.nn.softmax[0][0]',       \n",
      " mbda)                                                               'tf.reshape[0][0]']          \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_3 (TFOpLa  (1, 16, 512)                 0         ['tf.nn.softmax_1[0][0]',     \n",
      " mbda)                                                               'tf.compat.v1.transpose_7[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " weight_layer (WeightLayer)  (1,)                         1         ['re_lu_52[0][0]']            \n",
      "                                                                                                  \n",
      " tf.reshape_1 (TFOpLambda)   (1, 512, 4, 4)               0         ['tf.linalg.matmul_1[0][0]']  \n",
      "                                                                                                  \n",
      " weight_layer_1 (WeightLaye  (1,)                         1         ['re_lu_52[0][0]']            \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " tf.reshape_5 (TFOpLambda)   (1, 512, 4, 4)               0         ['tf.linalg.matmul_3[0][0]']  \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLamb  (1, 512, 4, 4)               0         ['weight_layer[0][0]',        \n",
      " da)                                                                 'tf.reshape_1[0][0]']        \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLa  (1, 512, 4, 4)               0         ['weight_layer_1[0][0]',      \n",
      " mbda)                                                               'tf.reshape_5[0][0]']        \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_2 (  (1, 4, 4, 512)               0         ['tf.math.multiply[0][0]']    \n",
      " TFOpLambda)                                                                                      \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_8 (  (1, 4, 4, 512)               0         ['tf.math.multiply_1[0][0]']  \n",
      " TFOpLambda)                                                                                      \n",
      "                                                                                                  \n",
      " tf.__operators__.add_50 (T  (1, 4, 4, 512)               0         ['tf.compat.v1.transpose_2[0][\n",
      " FOpLambda)                                                         0]',                          \n",
      "                                                                     're_lu_52[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_51 (T  (1, 4, 4, 512)               0         ['tf.compat.v1.transpose_8[0][\n",
      " FOpLambda)                                                         0]',                          \n",
      "                                                                     're_lu_52[0][0]']            \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)      (1, 4, 4, 1536)              0         ['re_lu_52[0][0]',            \n",
      "                                                                     'tf.__operators__.add_50[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'tf.__operators__.add_51[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " global_average_pooling2d_4  (1, 1, 1, 1536)              0         ['tf.concat[0][0]']           \n",
      "  (GlobalAveragePooling2D)                                                                        \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_9 (  (1, 1536, 1, 1)              0         ['global_average_pooling2d_4[0\n",
      " TFOpLambda)                                                        ][0]']                        \n",
      "                                                                                                  \n",
      " tf.reshape_6 (TFOpLambda)   (1, 1536)                    0         ['tf.compat.v1.transpose_9[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dense (Dense)               (1, 1024)                    1573888   ['tf.reshape_6[0][0]']        \n",
      "                                                                                                  \n",
      " identity (Identity)         (1, 1024)                    0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 84257730 (321.42 MB)\n",
      "Trainable params: 84103234 (320.83 MB)\n",
      "Non-trainable params: 154496 (603.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: /home/athena/Documents/GitHub/Dog-NosePrint-Recognition/keras_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/athena/Documents/GitHub/Dog-NosePrint-Recognition/keras_model/assets\n"
     ]
    }
   ],
   "source": [
    "keras_model.save('/home/athena/Documents/GitHub/Dog-NosePrint-Recognition/keras_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 15:38:57.939073: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-23 15:38:57.975108: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-23 15:38:57.975141: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-23 15:38:57.976308: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-23 15:38:57.982109: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-23 15:38:57.982748: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-23 15:38:58.568259: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-07-23 15:38:59.231306: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-23 15:38:59.260784: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "loaded_model = load_model('/home/athena/Documents/GitHub/Dog-NosePrint-Recognition/keras_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -6.6147165, -13.800435 , -12.870659 , ...,  -1.7380959,\n",
       "          9.257687 ,  -7.954967 ]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(transform_image.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpsvn891c4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpsvn891c4/assets\n",
      "2024-07-23 15:39:47.780472: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-07-23 15:39:47.780510: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-07-23 15:39:47.781246: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpsvn891c4\n",
      "2024-07-23 15:39:47.835980: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-07-23 15:39:47.836040: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpsvn891c4\n",
      "2024-07-23 15:39:47.954233: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-07-23 15:39:48.013176: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-07-23 15:39:49.262473: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpsvn891c4\n",
      "2024-07-23 15:39:49.661828: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 1880582 microseconds.\n",
      "2024-07-23 15:39:50.109483: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 171, Total Ops 624, % non-converted = 27.40 %\n",
      " * 171 ARITH ops\n",
      "\n",
      "- arith.constant:  171 occurrences  (f32: 163, i32: 8)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 52)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 160)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 51)\n",
      "  (f32: 1)\n",
      "  (uq_8: 161)\n",
      "  (f32: 6)\n",
      "  (f32: 2)\n",
      "  (f32: 7)\n",
      "2024-07-23 15:40:02.504962: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 31.675 G  ops, equivalently 15.838 G  MACs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(loaded_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model\n",
    "tflite_model_path = '/home/athena/Documents/GitHub/Dog-NosePrint-Recognition/keras_model_quant.tflite'\n",
    "with open(tflite_model_path, 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 256, 256])\n",
      "1/1 [==============================] - 0s 115ms/step\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "# img_path = \"/home/athena/Documents/GitHub/Dog-NosePrint-Recognition/dataset2/classes_with_6imgs/5672/O1CN01fjcDg01yHK0TN1bE3_!!0-mtopupload.jpg\"\n",
    "img_path2 = \"dataset2/classes_with_6imgs/5981/A*3S3LTZgdkc9UCstAt954pwAAAQAAAQ.jpg\"\n",
    "image2 = Image.open(img_path2).convert('RGB')\n",
    "transform_image2 = transform_val(image2).unsqueeze(0)\n",
    "print(transform_image2.shape)\n",
    "# convert it to 1,256,256,3\n",
    "transform_image2 = transform_image2.permute(0, 2, 3, 1)\n",
    "keras_output = keras_model.predict(transform_image2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Output: [[ -6.600711  -13.803787  -12.859123  ...  -1.7405246   9.242826\n",
      "   -7.8949203]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"/home/athena/Documents/GitHub/Dog-NosePrint-Recognition/keras_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Prepare input data as a numpy array.\n",
    "# Replace this with your actual input data. Ensure the shape matches the model's input shape.\n",
    "input_data = transform_image2.numpy()\n",
    "\n",
    "# Set the tensor to point to the input data to be inferred.\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "# Run the inference.\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get the output data.\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "# Print the output.\n",
    "print(\"Inference Output:\", output_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99999756]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the cosine similarity between output_data and np_vector\n",
    "cosine_similarity(output_data, np_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
