{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import shutil\n",
    "# import os\n",
    "\n",
    "# # Load the dataset\n",
    "# df = pd.read_csv('pet_biometric_challenge_2022/train/train_data.csv')\n",
    "\n",
    "# # Count the number of images for each dog ID\n",
    "# image_counts = df['dog ID'].value_counts()\n",
    "\n",
    "# # Filter IDs with 5 or more images\n",
    "# ids_with_enough_images = image_counts[image_counts >= 8].index\n",
    "\n",
    "# # Create directories and copy files\n",
    "# for dog_id in ids_with_enough_images:\n",
    "#     # Create a directory for the dog ID if it doesn't exist\n",
    "#     directory_path = f'./dataset/train/{dog_id}'\n",
    "#     os.makedirs(directory_path, exist_ok=True)\n",
    "    \n",
    "#     # Get all images for this dog ID\n",
    "#     images_to_copy = df[df['dog ID'] == dog_id]['nose print image']\n",
    "    \n",
    "#     # Copy each image\n",
    "#     for image in images_to_copy:\n",
    "#         src_path = f'pet_biometric_challenge_2022/train/images/{image}'  # Adjust this path\n",
    "#         dst_path = f'{directory_path}/{image}'\n",
    "#         shutil.copy(src_path, dst_path)\n",
    "\n",
    "#     print(f'Copied {len(images_to_copy)} images for dog ID {dog_id}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(os.listdir('dataset/train'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet152\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "class PairedDogNoseDataset(Dataset):\n",
    "    def __init__(self, image_folder, transform=None):\n",
    "        self.dataset = ImageFolder(root=image_folder, transform=transform)\n",
    "        self.transform = transform\n",
    "\n",
    "        # Create a dictionary of lists for each class\n",
    "        self.class_to_images = {}\n",
    "        for img, label in self.dataset.imgs:\n",
    "            if label not in self.class_to_images:\n",
    "                self.class_to_images[label] = []\n",
    "            self.class_to_images[label].append(img)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Randomly select whether to get a positive or negative pair\n",
    "        should_get_same_class = random.randint(0, 1) == 0\n",
    "        \n",
    "        first_image, label1 = self.dataset.imgs[index]\n",
    "        if should_get_same_class:\n",
    "            second_image = random.choice(self.class_to_images[label1])\n",
    "            label = 1\n",
    "        else:\n",
    "            different_class = random.choice(list(set(self.dataset.class_to_idx.values()) - {label1}))\n",
    "            second_image = random.choice(self.class_to_images[different_class])\n",
    "            label = 0\n",
    "\n",
    "        img1 = Image.open(first_image)\n",
    "        img2 = Image.open(second_image)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "\n",
    "        return img1, img2, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset.imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your transformations - you can add more augmentations as necessary\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize images to 256x256\n",
    "    transforms.ToTensor(),          # Convert images to Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with mean and std\n",
    "])\n",
    "\n",
    "paired_train_dataset = PairedDogNoseDataset('dataset/train', transform=transform)\n",
    "paired_train_dataloader = DataLoader(paired_train_dataset, batch_size=8, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcFaceLoss(nn.Module):\n",
    "    def __init__(self, s=30.0, m=0.50):\n",
    "        super(ArcFaceLoss, self).__init__()\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "\n",
    "    def forward(self, cosine, labels):\n",
    "        # Add margin\n",
    "        phi = cosine - self.m\n",
    "        # Apply the softmax on the adjusted scores\n",
    "        one_hot = torch.zeros(cosine.size(), device=cosine.device)\n",
    "        one_hot.scatter_(1, labels.view(-1, 1).long(), 1)\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)  # only adjust the angles for correct class\n",
    "        output *= self.s\n",
    "\n",
    "        loss = nn.CrossEntropyLoss()(output, labels)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = nn.functional.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean((1 - label) * torch.pow(euclidean_distance, 2) +\n",
    "                                      label * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "        return loss_contrastive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetBackbone, self).__init__()\n",
    "        # Load a pre-trained ResNet-152 and remove the last GAP and FC\n",
    "        base_model = resnet152(pretrained=True)\n",
    "        self.features = nn.Sequential(*list(base_model.children())[:-2])\n",
    "\n",
    "        # Additional blocks to reduce channel dimensions\n",
    "        self.reduce_channels = nn.Sequential(\n",
    "            nn.Conv2d(2048, 1024, kernel_size=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(1024, 512, kernel_size=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.reduce_channels(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AttentionModule, self).__init__()\n",
    "        self.channel_attention = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(512, 512, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.spatial_attention = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Channel attention\n",
    "        ca = self.channel_attention(x) * x\n",
    "\n",
    "        # Spatial attention\n",
    "        sa = self.spatial_attention(ca) * ca\n",
    "\n",
    "        return sa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.backbone = ResNetBackbone()\n",
    "        self.attention = AttentionModule()\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(512, 1024)  # Output 1024-dimensional embedding\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        out1 = self.backbone(x1)\n",
    "        out1 = self.attention(out1)\n",
    "        out1 = self.pooling(out1)\n",
    "        out1 = out1.view(out1.size(0), -1)\n",
    "        out1 = self.fc(out1)\n",
    "\n",
    "        out2 = self.backbone(x2)\n",
    "        out2 = self.attention(out2)\n",
    "        out2 = self.pooling(out2)\n",
    "        out2 = out2.view(out2.size(0), -1)\n",
    "        out2 = self.fc(out2)\n",
    "\n",
    "        return out1, out2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(predictions, targets, threshold=0.5):\n",
    "    \"\"\" Computes the accuracy based on a threshold.\n",
    "        Predictions below the threshold are considered 'positive' or 'same class'.\n",
    "    \"\"\"\n",
    "    predictions = predictions < threshold\n",
    "    correct = (predictions == targets).float()\n",
    "    accuracy = correct.sum() / len(correct)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.5433, Accuracy: 0.5500\n",
      "Epoch 2/50, Loss: 0.3480, Accuracy: 0.6406\n",
      "Epoch 3/50, Loss: 0.5095, Accuracy: 0.6375\n",
      "Epoch 4/50, Loss: 0.3940, Accuracy: 0.6875\n",
      "Epoch 5/50, Loss: 0.3838, Accuracy: 0.6188\n",
      "Epoch 6/50, Loss: 0.3797, Accuracy: 0.6469\n",
      "Epoch 7/50, Loss: 0.4944, Accuracy: 0.6031\n",
      "Epoch 8/50, Loss: 0.3717, Accuracy: 0.6344\n",
      "Epoch 9/50, Loss: 0.3859, Accuracy: 0.6438\n",
      "Epoch 10/50, Loss: 0.4510, Accuracy: 0.6531\n",
      "Epoch 11/50, Loss: 0.3375, Accuracy: 0.5656\n",
      "Epoch 12/50, Loss: 0.0926, Accuracy: 0.5969\n",
      "Epoch 13/50, Loss: 0.4315, Accuracy: 0.6094\n",
      "Epoch 14/50, Loss: 0.6632, Accuracy: 0.6156\n",
      "Epoch 15/50, Loss: 0.2558, Accuracy: 0.5844\n",
      "Epoch 16/50, Loss: 0.4183, Accuracy: 0.5750\n",
      "Epoch 17/50, Loss: 0.4219, Accuracy: 0.5594\n",
      "Epoch 18/50, Loss: 0.4050, Accuracy: 0.6375\n",
      "Epoch 19/50, Loss: 0.3897, Accuracy: 0.6156\n",
      "Epoch 20/50, Loss: 0.6910, Accuracy: 0.5687\n",
      "Epoch 21/50, Loss: 0.3173, Accuracy: 0.5531\n",
      "Epoch 22/50, Loss: 0.3813, Accuracy: 0.6406\n",
      "Epoch 23/50, Loss: 0.3264, Accuracy: 0.6281\n",
      "Epoch 24/50, Loss: 0.3198, Accuracy: 0.6031\n",
      "Epoch 25/50, Loss: 0.1524, Accuracy: 0.6813\n",
      "Epoch 26/50, Loss: 0.7219, Accuracy: 0.6438\n",
      "Epoch 27/50, Loss: 0.5717, Accuracy: 0.6125\n",
      "Epoch 28/50, Loss: 0.4114, Accuracy: 0.5969\n",
      "Epoch 29/50, Loss: 0.3950, Accuracy: 0.5750\n",
      "Epoch 30/50, Loss: 0.4154, Accuracy: 0.5906\n",
      "Epoch 31/50, Loss: 0.4258, Accuracy: 0.5781\n",
      "Epoch 32/50, Loss: 0.5252, Accuracy: 0.5875\n",
      "Epoch 33/50, Loss: 0.3903, Accuracy: 0.5969\n",
      "Epoch 34/50, Loss: 0.3670, Accuracy: 0.5188\n",
      "Epoch 35/50, Loss: 0.3964, Accuracy: 0.5813\n",
      "Epoch 36/50, Loss: 0.4200, Accuracy: 0.6062\n",
      "Epoch 37/50, Loss: 0.4455, Accuracy: 0.5531\n",
      "Epoch 38/50, Loss: 0.7335, Accuracy: 0.5312\n",
      "Epoch 39/50, Loss: 0.4229, Accuracy: 0.6375\n",
      "Epoch 40/50, Loss: 0.4187, Accuracy: 0.6375\n",
      "Epoch 41/50, Loss: 0.3956, Accuracy: 0.5594\n",
      "Epoch 42/50, Loss: 0.4199, Accuracy: 0.5563\n",
      "Epoch 43/50, Loss: 0.7061, Accuracy: 0.5875\n",
      "Epoch 44/50, Loss: 0.3950, Accuracy: 0.5813\n",
      "Epoch 45/50, Loss: 0.4000, Accuracy: 0.5750\n",
      "Epoch 46/50, Loss: 0.3946, Accuracy: 0.5594\n",
      "Epoch 47/50, Loss: 0.4238, Accuracy: 0.5625\n",
      "Epoch 48/50, Loss: 0.0766, Accuracy: 0.5719\n",
      "Epoch 49/50, Loss: 0.2760, Accuracy: 0.5406\n",
      "Epoch 50/50, Loss: 0.4435, Accuracy: 0.5687\n",
      "Epoch 51/50, Loss: 0.6268, Accuracy: 0.5469\n",
      "Epoch 52/50, Loss: 0.2356, Accuracy: 0.5875\n",
      "Epoch 53/50, Loss: 0.3576, Accuracy: 0.5156\n",
      "Epoch 54/50, Loss: 0.4712, Accuracy: 0.5250\n",
      "Epoch 55/50, Loss: 0.3650, Accuracy: 0.5813\n",
      "Epoch 56/50, Loss: 0.2504, Accuracy: 0.6250\n",
      "Epoch 57/50, Loss: 0.0728, Accuracy: 0.5406\n",
      "Epoch 58/50, Loss: 0.1581, Accuracy: 0.5750\n",
      "Epoch 59/50, Loss: 0.1038, Accuracy: 0.5687\n",
      "Epoch 60/50, Loss: 0.3684, Accuracy: 0.5500\n",
      "Epoch 61/50, Loss: 0.4497, Accuracy: 0.5469\n",
      "Epoch 62/50, Loss: 0.2290, Accuracy: 0.5312\n",
      "Epoch 63/50, Loss: 0.3820, Accuracy: 0.5938\n",
      "Epoch 64/50, Loss: 0.3891, Accuracy: 0.5094\n",
      "Epoch 65/50, Loss: 0.3764, Accuracy: 0.5563\n",
      "Epoch 66/50, Loss: 0.3989, Accuracy: 0.5281\n",
      "Epoch 67/50, Loss: 0.4456, Accuracy: 0.6062\n",
      "Epoch 68/50, Loss: 0.5778, Accuracy: 0.5531\n",
      "Epoch 69/50, Loss: 0.4429, Accuracy: 0.5781\n",
      "Epoch 70/50, Loss: 0.4038, Accuracy: 0.5719\n",
      "Epoch 71/50, Loss: 0.7516, Accuracy: 0.5781\n",
      "Epoch 72/50, Loss: 0.2563, Accuracy: 0.5781\n",
      "Epoch 73/50, Loss: 0.3669, Accuracy: 0.5656\n",
      "Epoch 74/50, Loss: 0.1557, Accuracy: 0.5406\n",
      "Epoch 75/50, Loss: 0.6516, Accuracy: 0.5563\n",
      "Epoch 76/50, Loss: 0.4457, Accuracy: 0.5781\n",
      "Epoch 77/50, Loss: 0.5451, Accuracy: 0.5563\n",
      "Epoch 78/50, Loss: 0.3995, Accuracy: 0.5906\n",
      "Epoch 79/50, Loss: 0.2152, Accuracy: 0.5281\n",
      "Epoch 80/50, Loss: 0.7008, Accuracy: 0.5813\n",
      "Epoch 81/50, Loss: 0.4407, Accuracy: 0.5250\n",
      "Epoch 82/50, Loss: 0.4291, Accuracy: 0.5469\n",
      "Epoch 83/50, Loss: 0.4243, Accuracy: 0.5406\n",
      "Epoch 84/50, Loss: 0.4211, Accuracy: 0.5469\n",
      "Epoch 85/50, Loss: 0.3872, Accuracy: 0.5250\n",
      "Epoch 86/50, Loss: 0.4048, Accuracy: 0.5250\n",
      "Epoch 87/50, Loss: 0.3862, Accuracy: 0.5719\n",
      "Epoch 88/50, Loss: 0.0439, Accuracy: 0.5594\n",
      "Epoch 89/50, Loss: 0.0310, Accuracy: 0.5563\n",
      "Epoch 90/50, Loss: 0.6413, Accuracy: 0.5437\n",
      "Epoch 91/50, Loss: 0.3912, Accuracy: 0.4875\n",
      "Epoch 92/50, Loss: 0.5965, Accuracy: 0.5469\n",
      "Epoch 93/50, Loss: 0.4125, Accuracy: 0.5813\n",
      "Epoch 94/50, Loss: 0.5445, Accuracy: 0.5156\n",
      "Epoch 95/50, Loss: 0.3064, Accuracy: 0.5125\n",
      "Epoch 96/50, Loss: 0.5108, Accuracy: 0.4656\n",
      "Epoch 97/50, Loss: 0.4511, Accuracy: 0.5188\n",
      "Epoch 98/50, Loss: 0.3838, Accuracy: 0.5437\n",
      "Epoch 99/50, Loss: 0.3873, Accuracy: 0.5375\n",
      "Epoch 100/50, Loss: 0.3928, Accuracy: 0.5125\n"
     ]
    }
   ],
   "source": [
    "# Assuming model, optimizers, and loss functions are already defined\n",
    "model = SiameseNetwork().to(device)\n",
    "optimizer_contrastive = optim.Adam(model.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "optimizer_arcface = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "criterion_contrastive = ContrastiveLoss(margin=2.0)\n",
    "criterion_arcface = ArcFaceLoss(s=30, m=0.5)\n",
    "\n",
    "# Scheduler for learning rate decay of the ArcFace optimizer\n",
    "scheduler_arcface = optim.lr_scheduler.LinearLR(optimizer_arcface, start_factor=1.0, end_factor=0, total_iters=200)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):  # Total epochs set as 200\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    for img1, img2, labels in paired_train_dataloader:\n",
    "        img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass: Compute predicted outputs by passing inputs to the model\n",
    "        output1, output2 = model(img1, img2)\n",
    "        euclidean_distance = torch.nn.functional.pairwise_distance(output1, output2)\n",
    "        # Compute Contrastive Loss\n",
    "        loss_contrastive = criterion_contrastive(output1, output2, labels)\n",
    "        \n",
    "        # Calculate the mean embedding for ArcFace Loss (simplified version)\n",
    "        embeddings = (output1 + output2) / 2\n",
    "        loss_arcface = criterion_arcface(embeddings, labels)\n",
    "        \n",
    "        # Combine losses\n",
    "        total_loss = loss_contrastive + loss_arcface\n",
    "        # print(f'Epoch {epoch+1}, Loss: {total_loss.item():.4f}')\n",
    "        \n",
    "        # Compute accuracy\n",
    "        accuracy = compute_accuracy(euclidean_distance, labels, threshold=0.5)\n",
    "        total_accuracy += accuracy.item()\n",
    "\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer_contrastive.zero_grad()\n",
    "        optimizer_arcface.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer_contrastive.step()\n",
    "        optimizer_arcface.step()\n",
    "    \n",
    "    scheduler_arcface.step()  # Update the learning rate\n",
    "    \n",
    "    average_accuracy = total_accuracy / len(paired_train_dataloader)\n",
    "    average_loss = total_loss / len(paired_train_dataloader)\n",
    "    print(f'Epoch {epoch+1}/50, Loss: {average_loss:.4f}, Accuracy: {average_accuracy:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model state dictionary\n",
    "torch.save(model.state_dict(), 'weight.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SiameseNetwork(\n",
       "  (backbone): ResNetBackbone(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (6): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (7): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (6): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (7): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (8): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (9): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (10): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (11): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (12): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (13): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (14): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (15): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (16): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (17): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (18): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (19): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (20): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (21): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (22): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (23): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (24): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (25): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (26): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (27): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (28): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (29): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (30): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (31): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (32): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (33): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (34): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (35): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (reduce_channels): Sequential(\n",
       "      (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (attention): AttentionModule(\n",
       "    (channel_attention): Sequential(\n",
       "      (0): AdaptiveAvgPool2d(output_size=1)\n",
       "      (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): Sigmoid()\n",
       "    )\n",
       "    (spatial_attention): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (fc): Linear(in_features=512, out_features=1024, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model = SiameseNetwork().cuda()\n",
    "model.load_state_dict(torch.load('weight.pth'))\n",
    "model.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "# Change the device to CPU\n",
    "device = torch.device('cpu')\n",
    "model.to(device)\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize the image to 256x256\n",
    "    transforms.ToTensor(),          # Convert the image to a tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_similarity(img_path1, img_path2):\n",
    "    # Load and transform images\n",
    "    img1 = Image.open(img_path1).convert('RGB')\n",
    "    img2 = Image.open(img_path2).convert('RGB')\n",
    "    img1 = transform(img1).unsqueeze(0).to(device) # Add batch dimension and send to GPU\n",
    "    img2 = transform(img2).unsqueeze(0).to(device)  # Add batch dimension and send to GPU\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():  # No need to track gradients\n",
    "        output1, output2 = model(img1, img2)\n",
    "        euclidean_distance = torch.nn.functional.pairwise_distance(output1, output2)\n",
    "\n",
    "    return euclidean_distance.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Euclidean distance between the images is: 0.6077437996864319\n"
     ]
    }
   ],
   "source": [
    "# Paths to the images you want to compare\n",
    "image_path1 = 'dataset/testing/1771/A*d-fSRoB7LOAAAAAAAAAAAAAAAQAAAQ.jpg'\n",
    "image_path2 = 'dataset/testing/1775/A*8dSMQ6vUnmUAAAAAAAAAAAAAAQAAAQ.jpg'\n",
    "\n",
    "# Perform inference\n",
    "distance = infer_similarity(image_path1, image_path2)\n",
    "print(f'The Euclidean distance between the images is: {distance}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar image: dataset/train/1781/0Tolu7cpRQurgl7b87DAOwAAACMAARAD.jpg, Distance: 0.08487781137228012\n"
     ]
    }
   ],
   "source": [
    "def find_most_similar(query_img_path, reference_img_paths):\n",
    "    min_distance = float('inf')\n",
    "    most_similar_img = None\n",
    "\n",
    "    for ref_path in reference_img_paths:\n",
    "        distance = infer_similarity(query_img_path, ref_path)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            most_similar_img = ref_path\n",
    "\n",
    "    return most_similar_img, min_distance\n",
    "\n",
    "# List of reference image paths\n",
    "reference_images = ['dataset/train/1781/0Tolu7cpRQurgl7b87DAOwAAACMAARAD.jpg','dataset/train/1790/A*Kf4tQrPJVrgAAAAAAAAAAAAAAQAAAQ.jpg', 'dataset/train/1771/A*jP8SQ4cdHVDm2wJBthDn0AAAAQAAAQ.jpg', 'dataset/train/1775/A*cSJSR4QTq74AAAAAAAAAAAAAAQAAAQ.jpg', 'dataset/train/1780/A*83ofSqE-8DMAAAAAAAAAAAAAAQAAAQ.jpg']\n",
    "most_similar_image, similarity_score = find_most_similar('dataset/train/1781/miLuamg6Tx-rWnXEs7jOuwAAACMAARAD.jpg', reference_images)\n",
    "print(f'Most similar image: {most_similar_image}, Distance: {similarity_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Similar:  dataset/testing/1774/A*R219QYYP14AAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1774/A*R219QYYP14AAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1774/A*S8piQ4XCPAoAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1774/A*S8piQ4XCPAoAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1774/A*QlABTZmAYIYAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1774/A*QlABTZmAYIYAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1774/A*l6tgR4j42wEAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1774/A*l6tgR4j42wEAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1774/A*a24pSZVP0jIAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1774/A*a24pSZVP0jIAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1774/A*6A8LQ7KTql8AAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1774/A*6A8LQ7KTql8AAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1774/A*_ts1RLi4t6QAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1774/A*_ts1RLi4t6QAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1774/A*2vGQR6TKWsMAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1774/A*2vGQR6TKWsMAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1775/A*cSJSR4QTq74AAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1775/A*cSJSR4QTq74AAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1775/A*LxrVTamXKDcAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1775/A*LxrVTamXKDcAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1775/A*mIswT5Z4vjAAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1775/A*mIswT5Z4vjAAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1775/A*8sRFTYtX8IUAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1775/A*8sRFTYtX8IUAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1775/A*8dSMQ6vUnmUAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1775/A*8dSMQ6vUnmUAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1775/A*Vnv4RqS3jBwAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1775/A*Vnv4RqS3jBwAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1775/A*1EHJS5BugqUAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1775/A*1EHJS5BugqUAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1775/A*4ByBQ6x73bcAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1775/A*4ByBQ6x73bcAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1771/A*jP8SQ4cdHVDm2wJBthDn0AAAAQAAAQ.jpg     ref img:  dataset/testing/1771/A*jP8SQ4cdHVDm2wJBthDn0AAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1771/A*jP8SQ4cdHVDm2wJBthDn0AAAAQAAAQ.jpg     ref img:  dataset/testing/1771/A*jP8SQ4cdHVDHuaVGsWP_IwAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1771/A*LmbuQoxOuDgAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1771/A*LmbuQoxOuDgAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1771/A*d-fSRoB7LOAAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1771/A*d-fSRoB7LOAAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1771/A*jP8SQ4cdHVDm2wJBthDn0AAAAQAAAQ.jpg     ref img:  dataset/testing/1771/A*jP8SQ4cdHVAAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1771/A*uKATSqHOo9AAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1771/A*uKATSqHOo9AAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1771/A*GMS_SJtg75QAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1771/A*GMS_SJtg75QAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1771/A*EHgRTLiRPpcAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1771/A*EHgRTLiRPpcAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1773/A*jLojSo6dQPIAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1773/A*jLojSo6dQPIAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1773/A*WtsTQrt_HhgAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1773/A*WtsTQrt_HhgAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1773/A*HtbgRrGx8jIAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1773/A*HtbgRrGx8jIAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1773/A*j8dsSIfQ7DYAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1773/A*j8dsSIfQ7DYAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1773/A*vMJ-T7z_ByEAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1773/A*vMJ-T7z_ByEAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1773/A*XSTqRI4hcmcAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1773/A*XSTqRI4hcmcAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1773/A*BTHSSoW0nMAAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1773/A*BTHSSoW0nMAAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1773/A*EffrQb4sZEcAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1773/A*EffrQb4sZEcAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1772/A*ZHBCT7uIQ7YAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1772/A*ZHBCT7uIQ7YAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1772/A*I7EGS69kpoAAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1772/A*I7EGS69kpoAAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1772/A*YAbERaY0Us4AAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1772/A*YAbERaY0Us4AAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1772/A*__WEQ73cq1sAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1772/A*__WEQ73cq1sAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1772/A*qn_WR4PpuMUAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1772/A*qn_WR4PpuMUAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1772/A*FaR_RZstqUEAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1772/A*FaR_RZstqUEAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1772/A*ksEYTIF7hHkAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1772/A*ksEYTIF7hHkAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Most Similar:  dataset/testing/1772/A*9ivnRLX_20wAAAAAAAAAAAAAAQAAAQ.jpg     ref img:  dataset/testing/1772/A*9ivnRLX_20wAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "def infer_similarity(img_path1, img_path2, model, transform, device):\n",
    "    # Load and transform images\n",
    "    img1 = Image.open(img_path1).convert('RGB')\n",
    "    img2 = Image.open(img_path2).convert('RGB')\n",
    "    img1 = transform(img1).unsqueeze(0).to(device)\n",
    "    img2 = transform(img2).unsqueeze(0).to(device)\n",
    "    # Perform inference\n",
    "    with torch.no_grad():  # No need to track gradients\n",
    "        output1, output2 = model(img1, img2)\n",
    "        euclidean_distance = torch.nn.functional.pairwise_distance(output1, output2)\n",
    "    return euclidean_distance.item()\n",
    "\n",
    "def find_most_similar(query_img_path, reference_img_paths, model, transform, device):\n",
    "    min_distance = float('inf')\n",
    "    most_similar_img = None\n",
    "\n",
    "    for ref_path in reference_img_paths:\n",
    "        distance = infer_similarity(query_img_path, ref_path, model, transform, device)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            most_similar_img = ref_path\n",
    "\n",
    "    return most_similar_img, min_distance\n",
    "\n",
    "def evaluate_accuracy(dataset_dir, model, transform, device):\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    reference_images = []\n",
    "\n",
    "    # First, collect all image paths\n",
    "    for class_dir in os.listdir(dataset_dir):\n",
    "        class_path = os.path.join(dataset_dir, class_dir)\n",
    "        if os.path.isdir(class_path):\n",
    "            for img_file in os.listdir(class_path):\n",
    "                img_path = os.path.join(class_path, img_file)\n",
    "                reference_images.append(img_path)\n",
    "\n",
    "    # Now evaluate each image against all collected images\n",
    "    for ref_img in reference_images:\n",
    "        most_similar_image, _ = find_most_similar(ref_img, reference_images, model, transform, device)\n",
    "        print(\"Most Similar: \",most_similar_image, \"    ref img: \", ref_img)\n",
    "        if os.path.dirname(most_similar_image) == os.path.dirname(ref_img):\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "\n",
    "    accuracy = correct / (correct + incorrect)\n",
    "    return accuracy\n",
    "\n",
    "# Example usage\n",
    "dataset_dir = 'dataset/testing'\n",
    "accuracy = evaluate_accuracy(dataset_dir, model, transform, device)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dog_nose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
